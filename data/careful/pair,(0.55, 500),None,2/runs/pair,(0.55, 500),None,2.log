>>> t = 0 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 36
<SML_1_0_0>0|Return{oo|cc|aoo|acc|doc|daoc}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
>>> t = 0 ===================================================================================================
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 36
<SML_1_0_0>0|Return{oo|cc|aoo|acc|doc|daoc}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 0 <SML_1_0_0>
nbest = 117
train = [1.440823068560438, 1.4603888180079498, 1.446803063934453, 1.4134552672432266, 1.4795450602278397, 1.475551114874009, 1.4626163344371, 1.4574395194537708, 1.497070293816319, 1.4663395412583078, 1.4556094521381697, 1.473817450705991]
scores = [0.599435038062361, 0.5193684394711393, 0.49159713364946184, 0.3686957789077324, 0.1081549878840431, 0.527360724050421, 0.5794064040829573, 0.800751959411712, 0.29214007455799035, 0.6355777854126359, 0.29620604274917733, 1.473817450705991]
score = 0.4638518256067253
holdout = [[0.45912809023026285, 0.5156007343141783, 0.2326960340361934], [0.4338677780998319, 0.4370114396416114, 0.20372343756232472], [0.4399850585213316, 0.48166513556226465, 0.21365130899560875], [0.4249259641398835, 0.49503547028698436, 0.21057247165573187], [0.39449377888802994, 0.39905509052230514, 0.21994505224090274], [0.44304223005142235, 0.495543909241213, 0.20760804322130272], [0.43756659838984036, 0.47929902049198436, 0.23790731121240954], [0.4203091059958306, 0.484714342718048, 0.218446404442642], [0.43748286676380704, 0.4560705760827903, 0.20172405197169], [0.3948173822012697, 0.4597908175654694, 0.2027819566140682], [0.405794179305284, 0.48306129135706677, 0.21853535480948913], [0.41916411237273243, 0.4758477927985458, 0.20703671563690584]]
>>> t = 1 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 36
<SML_0_1_1>0|#<>#0|Return{oo|cc|aoo|acc|doc|daoc}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 1 <SML_0_1_1>
nbest = 264
train = (1.5975473752550213, 1.6069084819183976, 1.5964017083221549, 1.5835005239965567, 1.6581409183075766, 1.6269375037885758, 1.6344623550031314, 1.6097628640795427, 1.6427076993696315, 1.6221010235627984, 1.615732205648978, 1.6425311816090924)
scores = (0.57136925170492658, 0.43449965242326172, 0.47914970237846077, 0.28398520631495949, 0.072475343336009315, 0.49125089684971274, 0.49264565983632991, 0.78301855217240179, 0.35924206866937186, 0.61275309087228069, 0.289737766211693, 1.6425311816090924)
score = 0.42851365209482406
holdout = ((0.45183108093319818, 0.55024674034969467, 0.13642817416916234), (0.37387976780581927, 0.45165368998368943, 0.10700901736797916), (0.38543755191150442, 0.45886856920854541, 0.11581321947409999), (0.38331278264341573, 0.48088743335597284, 0.15808724201892155), (0.36045720318702579, 0.40574284896813279, 0.15331922161000777), (0.3872839220872672, 0.51138945056648422, 0.12543809348547802), (0.38077309006740201, 0.47129347634902091, 0.14160610357932576), (0.37595973415784661, 0.49631464657374913, 0.13202889068674975), (0.38493612907378705, 0.49651259763254069, 0.13351592668462151), (0.37639651664188262, 0.48901186764652999, 0.12653063902573022), (0.36299740760461852, 0.48959319943774826, 0.15199361480666745), (0.39233812799354417, 0.51377336291395292, 0.11550870815915421))
>>> t = 2 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 54
<SML_1_1_0>0|Return{oo|cc|aoo|acc|doc|daoc}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 2 <SML_1_1_0>
nbest = 202
train = (1.5593663730956127, 1.5693328101967983, 1.5559085079015542, 1.532138125566948, 1.615975604920403, 1.590388903103032, 1.5867417050672017, 1.572137445109151, 1.6077358735311793, 1.5812333971669394, 1.5717572781114384, 1.5955937696821596)
scores = (0.60390824044538605, 0.47063526681222573, 0.51434272593415198, 0.31644458010972154, 0.11276935888046781, 0.52797620707253912, 0.53941856976560132, 0.77065196758534038, 0.33499458294260465, 0.6110138630229669, 0.31802248983809756, 1.5955937696821596)
score = 0.4561743618168975
holdout = ((0.43868792987613781, 0.55068124724580891, 0.16285567947264765), (0.40262176581132592, 0.47246067405594872, 0.14920403820671035), (0.41901764020863236, 0.48310053507445566, 0.13776064428766818), (0.40012942972523219, 0.50753236108325495, 0.18552127966024801), (0.38159797059853307, 0.41408119119792081, 0.17325154023722547), (0.42556178766535419, 0.49788422810832639, 0.144567483255607), (0.41610166954382477, 0.48511371383217866, 0.17819824387612301), (0.41515877035092663, 0.51148281234507142, 0.14067800208777803), (0.400790298739372, 0.49912970297844228, 0.15061991773014644), (0.39224213202874142, 0.49253378508292245, 0.15026711657645378), (0.39137241656456528, 0.50849669858960667, 0.17223204665291181), (0.40844686662251489, 0.50883942679177274, 0.15291803312448227))
>>> t = 3 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 74
<SML_1_0_0>0|Return{oo|cc|aoo|acc|doc|daoc}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 3 <SML_1_0_0>
nbest = 285
train = (1.775212667648131, 1.797086242205749, 1.7814561244616327, 1.7558113811820688, 1.85191720125165, 1.8069955191158278, 1.8025252066291491, 1.7815658845007298, 1.8269691902746568, 1.8068618060521842, 1.794016857125351, 1.820141592465677)
scores = (0.80499969133293836, 0.52576177617893893, 0.62190755733408931, 0.44241540535558366, 0.10705206171262242, 0.58616265933066203, 0.60223829662092832, 0.79620899215797758, 0.36806495265843947, 0.58854382226069268, 0.36166030236431518, 1.820141592465677)
score = 0.5094828588881894
holdout = ((0.47047837837712636, 0.54301625847125568, 0.28040687453448859), (0.45867279419564178, 0.45073186697330425, 0.21620673962025813), (0.45525492950983076, 0.48640511100466999, 0.25512285182794203), (0.45114370035824863, 0.48831771434693633, 0.25766166118283468), (0.43084616633515799, 0.42679358145705021, 0.2731178098854154), (0.46679497434240547, 0.52046800230400458, 0.25365735585799187), (0.46806350837152094, 0.48736370406461371, 0.24755176050701216), (0.44660805604189763, 0.47914088303571983, 0.27395213448141736), (0.4659389090496972, 0.4989720385266298, 0.22533103701372759), (0.44182757787520421, 0.46085293195901245, 0.2533513993965284), (0.4242129644699143, 0.47985527023387792, 0.25850716788067851), (0.46669626159749311, 0.48912601812289175, 0.26341075559186128))
>>> t = 4 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 74
<SML_0_1_1>0|#<>#0|Return{oo|cc|aoo|acc|doc|daoc}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 4 <SML_0_1_1>
nbest = 412
train = (1.7878647343881162, 1.8155662059173903, 1.8013416135063258, 1.7797797906398998, 1.8633878138998745, 1.8203118772842581, 1.8296849583271775, 1.8052222144421666, 1.8432799344294282, 1.8216904791097037, 1.8077014399640041, 1.8462732516534714)
scores = (0.7540453389339159, 0.49190594519850633, 0.60672826762198051, 0.42264040506522904, 0.081145034137100946, 0.58569289945376091, 0.50527990742836226, 0.74889529200551774, 0.42676049193374277, 0.57415048774467192, 0.33194326379801414, 1.8462732516534714)
score = 0.4817412167019556
holdout = ((0.49491430647401308, 0.48305106182754787, 0.20795983330935061), (0.46586093943895518, 0.38018635410062512, 0.17825845966714052), (0.43149715410234141, 0.41981181797114969, 0.20670697069956184), (0.42862425246949604, 0.48405416234706999, 0.18470072857923273), (0.41328842106490721, 0.39924885111241482, 0.2018879001538883), (0.48240598582977462, 0.41796409174439247, 0.18253412679158751), (0.44070547839212787, 0.4179635951477334, 0.21581022466512456), (0.43476563878928137, 0.44609260437903553, 0.2004008170980128), (0.44796341379596782, 0.44887059179262001, 0.17852777110501888), (0.43677874782225112, 0.41577697822218074, 0.19454268472427552), (0.42580102315859547, 0.43148068246615701, 0.20541144995144783), (0.43967450050688894, 0.43970668789867867, 0.19606663306354719))
>>> t = 5 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 111
<SML_1_1_0>0|Return{oo|cc|aoo|acc|doc|daoc}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 5 <SML_1_1_0>
nbest = 375
train = (1.7915367926239274, 1.806074364488655, 1.8036705847615262, 1.7824490324725726, 1.87386077763471, 1.8222270085391079, 1.8242492164936173, 1.8125084766717265, 1.8449512382164786, 1.8284806008043772, 1.8082151629210967, 1.8375560799846593)
scores = (0.77567867454270678, 0.51781288722832386, 0.63255481579760731, 0.43555787440760563, 0.10235202958801545, 0.59977916881754201, 0.57607877959867992, 0.78064462011477742, 0.39260602885025114, 0.60298802625220271, 0.35106979618258632, 1.8375560799846593)
score = 0.5050376505539185
holdout = ((0.47020717867475531, 0.51736752065228597, 0.24372618829102316), (0.44127415953161003, 0.39524184204528412, 0.22467777401794284), (0.43086898404557983, 0.45582863682006181, 0.21966313234010781), (0.42566748490527778, 0.50772968732086943, 0.20955197784938392), (0.41765461066336806, 0.42603034825350439, 0.21930533334369767), (0.4362785530314815, 0.47852678003456489, 0.22334956640875833), (0.44990408280118566, 0.41590466519566233, 0.20873408445982153), (0.43526848506342797, 0.46687763953102118, 0.21532726727557441), (0.44427611676842566, 0.44386124343216243, 0.21165973173947392), (0.42376149291841442, 0.4436899797259295, 0.20118765517591092), (0.41764058066863796, 0.45900967751455496, 0.22776232098444152), (0.46814092926023204, 0.46082024705077168, 0.23539961462312747))
>>> t = 6 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 38
<SML_1_0_0>0|Return{oo|cc|aoo|acc|doc|daoc}&(<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 6 <SML_1_0_0>
nbest = 64
train = (1.4601494004726665, 1.4541793522969084, 1.4389929458027282, 1.454392907131381, 1.4437680177273078, 1.4657054683568935, 1.4507579321392683, 1.4601161820752302, 1.4520228203567829, 1.4604067206593185, 1.444404413484826, 1.4783016781289759)
scores = (0.75778596011610955, 0.16562336957008272, 0.52322262800445107, 0.44526296088608502, 0.082201466163611667, 0.50769752420287251, 0.38340767532341596, 0.29858776928327069, 0.53565759532733082, 0.20117468169044139, 0.31004245987669687, 1.4783016781289759)
score = 0.34469208246118316
holdout = ((0.2092433302949008, 0.33286548495915841, 0.18131434122633849), (0.19934652868993327, 0.3905999768805864, 0.16577754034514988), (0.15325248906383107, 0.32047010319438757, 0.13775293268516983), (0.13630892869788777, 0.34279997118345706, 0.20963970994295339), (0.10794068730738743, 0.32769723789312705, 0.19121490997120136), (0.19171310951786349, 0.3034021537324032, 0.092944838844684782), (0.1438480376352019, 0.29882592863336765, 0.18529398649018139), (0.18519599418375909, 0.35391974570284401, 0.14419114055054502), (0.20273264238028674, 0.33797486185266273, 0.14862712857565658), (0.16156399112464551, 0.37162603331362259, 0.17044100276110083), (0.14589533665830226, 0.33777845809419699, 0.16016506651073223), (0.15539191976909494, 0.35156913614955942, 0.14465502910752817))
>>> t = 7 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 38
<SML_0_1_1>0|#<>#0|Return{oo|cc|aoo|acc|doc|daoc}&(<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc}&(<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 7 <SML_0_1_1>
nbest = 37
train = (1.3195377223261147, 1.3170282109786584, 1.3181218156707297, 1.3096195503277817, 1.2883095083934106, 1.3321389325490793, 1.3208162636309855, 1.314743290695124, 1.3192915898464646, 1.30269773472772, 1.3088195552898385, 1.3149615060781954)
scores = (0.77676697055736743, 0.16383281143165254, 0.50124828446437553, 0.44533127459341448, 0.039403349003855247, 0.50448542301513155, 0.29889832463892535, 0.31032911789334261, 0.49441025426262752, 0.19448181724673261, 0.28680317249097209, 1.3149615060781954)
score = 0.3284797804043174
holdout = ((0.20877347249882142, 0.31659749449586039, 0.19466019109987928), (0.16683632827345118, 0.2929549340110103, 0.20074131545776072), (0.15253549791197313, 0.30452447119683612, 0.20506793235987839), (0.18771391353807762, 0.28714435439840846, 0.17042654507608715), (0.14411166786941995, 0.29281101705206092, 0.17887781371183462), (0.22027225166325101, 0.31183152342909992, 0.14552169905726592), (0.14193254219993554, 0.27866719739946533, 0.18146637584267725), (0.14836402175727809, 0.28296919885885397, 0.15929047316918116), (0.15890812452552988, 0.29100578685514455, 0.16346281543890245), (0.14982025296908311, 0.31057476490340102, 0.17978457309381976), (0.14789939784973205, 0.29807146553526892, 0.16235213107687679), (0.17444784915505934, 0.30051322642418316, 0.17094527786908481))
>>> t = 8 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 57
<SML_1_1_0>0|Return{oo|cc|aoo|acc|doc|daoc}&(<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc}&(<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 8 <SML_1_1_0>
nbest = 43
train = (1.3977091574423846, 1.3697624064642149, 1.3826513682566572, 1.3733243433952191, 1.3779381995540489, 1.3955507358712695, 1.3742237096787784, 1.3820050802287844, 1.3828722431361449, 1.3827324797202456, 1.3695169144076589, 1.3933818962495448)
scores = (0.81276761453454105, 0.18774060879507651, 0.54674692855473928, 0.46497565367465871, 0.087881399084714248, 0.49477782740191945, 0.32747116606396931, 0.34070267500391743, 0.51087855707489016, 0.21445707118886337, 0.30931780739837061, 1.3933818962495448)
score = 0.3564780104780863
holdout = ((0.20512138254004064, 0.3954793583324816, 0.20959464026119912), (0.19586403506769637, 0.34133183058260186, 0.20630698467332428), (0.18406821223111799, 0.3671629683378978, 0.24009466336564705), (0.18340504356961987, 0.33713445981803747, 0.17519622777152963), (0.11141575406197907, 0.34564684406707041, 0.19232326198303823), (0.23919918127956713, 0.36432378113433572, 0.16515526191325297), (0.1575747181777728, 0.31372330553973632, 0.2093367794650175), (0.17554599825672693, 0.380809284846788, 0.19545373294208546), (0.16452521782025376, 0.32064298567988736, 0.19922652773785191), (0.1512101668007784, 0.32360255712816677, 0.20275316701122473), (0.17002337418911337, 0.32166058284554488, 0.23338978324442036), (0.20025610072017574, 0.35734885191385757, 0.16209510420761039))
>>> t = 9 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 54
<SML_1_0_0>0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 9 <SML_1_0_0>
nbest = 289
train = (1.6704677776407746, 1.6931698301309108, 1.6758520392346596, 1.6552127602020914, 1.7666122971446598, 1.7029417769220829, 1.7074495185722831, 1.6837973208963044, 1.7301049859150213, 1.7003772152301162, 1.6915467577235821, 1.7203350411092693)
scores = (0.57672642863817647, 0.55453014734460548, 0.51957810817907646, 0.38542137573969798, 0.13415501541828201, 0.55655900008357795, 0.57953907733753562, 0.76693921509171403, 0.33649540548960077, 0.58180168200966897, 0.28513737441499792, 1.7203350411092693)
score = 0.4680108365246505
holdout = ((0.47367807506634624, 0.53068736462701038, 0.21471108505733408), (0.44356513561216898, 0.47829978923675881, 0.18996396334230004), (0.4660286545432703, 0.5046415045411653, 0.17070771100228507), (0.47475049159439781, 0.52467592250815565, 0.2078847927387199), (0.42932435715568129, 0.47259385000077891, 0.18883593648370176), (0.45328932610576866, 0.52091125515776016, 0.19245583810498018), (0.45759137343161838, 0.49897010052797247, 0.20317523218246364), (0.45052665962233945, 0.50699062302837328, 0.21822738698442742), (0.45426500184239588, 0.50146154285304467, 0.18028446549947852), (0.42592817507383396, 0.50870816377930783, 0.18772783263185078), (0.43861501321291418, 0.4969672441838453, 0.21007417194152209), (0.45124911744519186, 0.49133937862205607, 0.20069652117380066))
>>> t = 10 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 54
<SML_0_1_1>0|#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 10 <SML_0_1_1>
nbest = 499
train = (1.7648416568652456, 1.7871247297815609, 1.7756511894358451, 1.7533297102011576, 1.8660541651440747, 1.7888726405040583, 1.7997766500455221, 1.7814305172065632, 1.8201391251079087, 1.7996159913457184, 1.7845663996555834, 1.8129036347770231)
scores = (0.5467189493559399, 0.43273573964545048, 0.43415952927580886, 0.29620249983926983, 0.15648918975680673, 0.51090428266450572, 0.47397501218502119, 0.76398930138569299, 0.35752935266767522, 0.63408361203514507, 0.28306991135778076, 1.8129036347770231)
score = 0.43425464263795516
holdout = ((0.45833703599301651, 0.54364169217914515, 0.12620078958312539), (0.42545697152088585, 0.48619504561792676, 0.10409643915252097), (0.46068589665593584, 0.45457155040879083, 0.10788050174316242), (0.41429729851471209, 0.49028429946074364, 0.14290951521569509), (0.43563873371700029, 0.4390747175255863, 0.13861944830749862), (0.43571117114722008, 0.52591088057279434, 0.099920260158484403), (0.42297468739759353, 0.50397144969475027, 0.15647527423074731), (0.44599093691936492, 0.48785533950174509, 0.12839787386688672), (0.44418804429692788, 0.49114439949136407, 0.12590938389185125), (0.41019448353384491, 0.44774134238923652, 0.096460673451762), (0.42126316136902608, 0.49282252757617512, 0.15555404218358179), (0.44943697192514892, 0.49566086428894435, 0.14068814896946))
>>> t = 11 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 81
<SML_1_1_0>0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 11 <SML_1_1_0>
nbest = 135
train = (1.5032511759055671, 1.5086143667659511, 1.494951415739006, 1.4643232407764653, 1.5552344074507245, 1.5207446552210739, 1.5162898193713261, 1.5050446780386404, 1.549196985463877, 1.5146315914817339, 1.5063634481183463, 1.5289806518782179)
scores = (0.60671133147753142, 0.45626428814618669, 0.51741792250802698, 0.34086426238547413, 0.11237334934669499, 0.53944100706000997, 0.53992668451685177, 0.75136266966355514, 0.33949347036950084, 0.62543833765975509, 0.28311988404035177, 1.5289806518782179)
score = 0.45237168754473245
holdout = ((0.48555658724020762, 0.56151312653150742, 0.19557772851612232), (0.42517236070031994, 0.47380596534980018, 0.15301588413481479), (0.45382938041775456, 0.50718323044317215, 0.15941364215015966), (0.44289848755941758, 0.54838319550777426, 0.18759905390907636), (0.42751186066045072, 0.46833360763591769, 0.16354411460246776), (0.46847089788029944, 0.53132535001291159, 0.1874365888002715), (0.42624607274347315, 0.47956257902875649, 0.18836384321039179), (0.45689961125061063, 0.47272531029771719, 0.19009150471818875), (0.44610819489036624, 0.49551798893446286, 0.16177096726537499), (0.44783422831685465, 0.50272008904365373, 0.16675595058582696), (0.42457189217982705, 0.51273388752471416, 0.17932590222757128), (0.46126096747037887, 0.5166817060336254, 0.16624192524257303))
>>> t = 12 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 104
<SML_1_0_0>0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 12 <SML_1_0_0>
nbest = 468
train = (1.883166466928105, 1.9060623387430162, 1.89210324699074, 1.8753324571362633, 1.9854430340903186, 1.9075877552047982, 1.913506556412127, 1.898355401011705, 1.9362936854341291, 1.9163528240634795, 1.8974352627588149, 1.9313173838293685)
scores = (0.76011264323494909, 0.52767347936572651, 0.6472765920818343, 0.46881462046158806, 0.13668522869412431, 0.60109652081642118, 0.62290073133717139, 0.82188140645260288, 0.375686300919651, 0.58964958514267507, 0.349322573696632, 1.9313173838293685)
score = 0.5179251583026033
holdout = ((0.5082521855246932, 0.51262688315371796, 0.24465209830717785), (0.46468840633193537, 0.44345400298377069, 0.20790020535395407), (0.47488840809147265, 0.47761080548216217, 0.24054887815085452), (0.47378543873138479, 0.48902557132862445, 0.23268215457467048), (0.46989682466634647, 0.45211746837990124, 0.2348373643640205), (0.49802835498926551, 0.50076306676388072, 0.24442172308433732), (0.50647956466759192, 0.47167071917902914, 0.23841971215257288), (0.47614976336746129, 0.46258189112160242, 0.2586476584981463), (0.48271042891969335, 0.48124263252327693, 0.21908072083235403), (0.45021508201879473, 0.48039514118196031, 0.22205759424999513), (0.45497348140301352, 0.47508616606822485, 0.23282208491830322), (0.46336240980111593, 0.4624406643825652, 0.24071034355238483))
>>> t = 13 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 104
<SML_0_1_1>0|#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 13 <SML_0_1_1>
nbest = 431
train = (1.8154750177037398, 1.8346158938762831, 1.8292052380990629, 1.8080778184017545, 1.9051030088393159, 1.8401106385556814, 1.8514712981103381, 1.8283895840131685, 1.8776756181456729, 1.8516588248575745, 1.8341617481688157, 1.8700129676237305)
scores = (0.73801539283252693, 0.46481398198763063, 0.6009903874636664, 0.46033993454060651, 0.13025745065230229, 0.5897944467255043, 0.47064583032678092, 0.78988704901916906, 0.39957591729607034, 0.60503677545412193, 0.31494250524435707, 1.8700129676237305)
score = 0.48622612083170874
holdout = ((0.50493055072006354, 0.50986136076914201, 0.21308129431129927), (0.46488612792543338, 0.41689389664985477, 0.18012084084655208), (0.48067109262391894, 0.44430567825913048, 0.17852739645580926), (0.47353029350651787, 0.49554031861853537, 0.19844718742805495), (0.46962735125643529, 0.40953903193851826, 0.1955882687669655), (0.47034327770783529, 0.44612376147205479, 0.15463048336750501), (0.47761826845785271, 0.46742032794011035, 0.1932177172394989), (0.48283816890476239, 0.46966463232331007, 0.18442817627924205), (0.48658638773954088, 0.45326715893736202, 0.18201329255078708), (0.45739836562892355, 0.43814100231347397, 0.1813364843106563), (0.46562248742488471, 0.46068837469607604, 0.20161694936791941), (0.47000632095034989, 0.44522094358195136, 0.19808497178897752))
>>> t = 14 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 156
<SML_1_1_0>0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 14 <SML_1_1_0>
nbest = 471
train = (1.8639819254124135, 1.8864634834234901, 1.8777940535685222, 1.8553386063229054, 1.9604394522189252, 1.8846363974707125, 1.8944347218709274, 1.8812582734481584, 1.9170946115397538, 1.8997302523356367, 1.878943426448014, 1.9103000951828035)
scores = (0.74672467866636971, 0.49504772767280908, 0.62407799631173666, 0.4759412995167408, 0.14413575262610304, 0.59932341719968363, 0.57678786735709897, 0.77015719627552603, 0.39439118485772545, 0.6251461201609434, 0.34622619351756728, 1.9103000951828035)
score = 0.5100422128474572
holdout = ((0.50314701311130872, 0.52521140834779967, 0.20384393477109403), (0.45180904222078194, 0.43124856739029899, 0.19230998446739858), (0.46551037501694492, 0.4720736554494776, 0.19702364033031683), (0.46377995237540404, 0.51910447563789219, 0.19948662009998352), (0.446209691365754, 0.44834173178701603, 0.20113572483511954), (0.5039132073919671, 0.48602929380797588, 0.19641602454884746), (0.46520429122133961, 0.43615063346592142, 0.21273467203931096), (0.49295385250826046, 0.4691858596234772, 0.19586353060322981), (0.49026467907781651, 0.44674137020704319, 0.19639806488952441), (0.44092373293688564, 0.44867280490774153, 0.1816000657223317), (0.47687095326922613, 0.47440257908053851, 0.2123495202385017), (0.49146490472242321, 0.48623376389648532, 0.21370103355618006))
>>> t = 15 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 50
<SML_1_0_0>0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 15 <SML_1_0_0>
nbest = 130
train = (1.527400232981551, 1.5297302906477674, 1.5276382280784866, 1.5060411944593657, 1.5563315924292294, 1.5179307848736794, 1.5356522647120123, 1.530246144224169, 1.5354008620285176, 1.5423268208083525, 1.5092530315924426, 1.5501113955050825)
scores = (0.73277529144464815, 0.18354751351522461, 0.62411951191913095, 0.48358446131980848, 0.1767656952004755, 0.46943418410575238, 0.45509427207721981, 0.34612357682946343, 0.46691418669774504, 0.18437722924547392, 0.36149946164605323, 1.5501113955050825)
score = 0.37397061021717554
holdout = ((0.17303438702937263, 0.26592150161315287, 0.096734204181307057), (0.10935240397613991, 0.27635211631087264, 0.180874282472864), (0.12849268036728148, 0.27166229254041485, 0.21462843423612818), (0.15123826784822333, 0.27813528432152151, 0.18287591458292565), (0.13290555642870375, 0.284480493380804, 0.16055443358176441), (0.17813759120670672, 0.31309094931704717, 0.162330890742554), (0.1670393355745303, 0.21746278863482604, 0.17444590212913261), (0.16310379328575794, 0.25890705523086777, 0.1856305945192526), (0.19148866796871042, 0.27340985493424746, 0.16589144824063412), (0.18141087792936689, 0.35054953690278429, 0.12892644422081059), (0.1850048269829539, 0.34094773056764055, 0.18313618514716315), (0.1584431222355222, 0.28128596422778646, 0.13396364156008383))
>>> t = 16 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 50
<SML_0_1_1>0|#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 16 <SML_0_1_1>
nbest = 80
train = (1.4313778492081046, 1.4574581632243186, 1.4416474835407902, 1.4401919997245471, 1.461949682713418, 1.4594030067085724, 1.4392667831408277, 1.4589666489419115, 1.448449007925567, 1.4440210799739162, 1.4191165991309871, 1.4598446289020539)
scores = (0.81628621087195485, 0.19658645996048812, 0.53275651094657395, 0.48564032839559185, 0.12266716206724858, 0.47090639462834216, 0.26319678137715175, 0.32140598173499063, 0.49000321480052839, 0.23282767930555306, 0.24704968579555678, 1.4598446289020539)
score = 0.34735644113597486
holdout = ((0.18967939829875363, 0.25526744833059495, 0.22244339781958958), (0.15199132307004601, 0.31162430069400754, 0.25542913003731393), (0.1152320905898256, 0.2799406099936349, 0.26764993010453231), (0.18223476599022703, 0.28003658124127578, 0.19933515289935408), (0.095101134480929328, 0.28966934130670885, 0.21423549825794463), (0.21714331334436873, 0.28487124943271502, 0.19841944438164785), (0.13659994598099875, 0.25645245743220174, 0.2204458571273534), (0.16638802775468314, 0.30313144936730596, 0.20541845376885282), (0.18860091520699043, 0.23503687345794566, 0.19688619131115048), (0.097926244508102805, 0.28377301352412149, 0.18726310050640285), (0.17952381604451448, 0.27123061754826, 0.29327031040465262), (0.16561911365925752, 0.22465762993805558, 0.2023530490425054))
>>> t = 17 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 75
<SML_1_1_0>0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp1dd}&(<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 17 <SML_1_1_0>
nbest = 111
train = (1.4906660929320981, 1.4939014228201961, 1.507500889465295, 1.4854060059953844, 1.5255576367556507, 1.4930828889538958, 1.5088547105674803, 1.5152718028671368, 1.5151822048454369, 1.5149750257333552, 1.4946498417541199, 1.5174044658034287)
scores = (0.74617975501271683, 0.17899767742964756, 0.61569854182944617, 0.40004045900708735, 0.15064173076341963, 0.46245745651659048, 0.35267874976507718, 0.42075135753544035, 0.50415508705892886, 0.25701424134370382, 0.28579613605182208, 1.5174044658034287)
score = 0.3646397182319105
holdout = ((0.16060055087984793, 0.28179699601578878, 0.15892989912617683), (0.1189256218440751, 0.25507312163542717, 0.25518425689666374), (0.12703917907917009, 0.23608232805598314, 0.23219104887078784), (0.19113675170166308, 0.26619276728543539, 0.17921404707598984), (0.15276167438514687, 0.22433534216357179, 0.22226378294323151), (0.25591733318784438, 0.29020799735964797, 0.15659930796194929), (0.1804161579185326, 0.2067422489894955, 0.17375217146013153), (0.18308102749532815, 0.21836644900012323, 0.18346752573499703), (0.20751570197613134, 0.26373530662053585, 0.25331504879570521), (0.10906605838901619, 0.24985348339730673, 0.1850552621887053), (0.18761208642369248, 0.29907822955581953, 0.22076236651134679), (0.18171878853733639, 0.26775870578048211, 0.18632627775318114))
>>> t = 18 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 36
<SML_1_0_0>0|Return{oo|cc|aoo|acc|doc|daoc|vp5dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 18 <SML_1_0_0>
nbest = 117
train = [1.440823068560438, 1.4603888180079498, 1.446803063934453, 1.4134552672432266, 1.4795450602278397, 1.475551114874009, 1.4626163344371, 1.4574395194537708, 1.497070293816319, 1.4663395412583078, 1.4556094521381697, 1.473817450705991]
scores = [0.599435038062361, 0.5193684394711393, 0.49159713364946184, 0.3686957789077324, 0.1081549878840431, 0.527360724050421, 0.5794064040829573, 0.800751959411712, 0.29214007455799035, 0.6355777854126359, 0.29620604274917733, 1.473817450705991]
score = 0.4638518256067253
holdout = [[0.45912809023026285, 0.5156007343141783, 0.2326960340361934], [0.4338677780998319, 0.4370114396416114, 0.20372343756232472], [0.4399850585213316, 0.48166513556226465, 0.21365130899560875], [0.4249259641398835, 0.49503547028698436, 0.21057247165573187], [0.39449377888802994, 0.39905509052230514, 0.21994505224090274], [0.44304223005142235, 0.495543909241213, 0.20760804322130272], [0.43756659838984036, 0.47929902049198436, 0.23790731121240954], [0.4203091059958306, 0.484714342718048, 0.218446404442642], [0.43748286676380704, 0.4560705760827903, 0.20172405197169], [0.3948173822012697, 0.4597908175654694, 0.2027819566140682], [0.405794179305284, 0.48306129135706677, 0.21853535480948913], [0.41916411237273243, 0.4758477927985458, 0.20703671563690584]]
>>> t = 19 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 36
<SML_0_1_1>0|#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp5dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp5dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 19 <SML_0_1_1>
nbest = 264
train = (1.5975473752550213, 1.6069084819183976, 1.5964017083221549, 1.5835005239965567, 1.6581409183075766, 1.6269375037885758, 1.6344623550031314, 1.6097628640795427, 1.6427076993696315, 1.6221010235627984, 1.615732205648978, 1.6425311816090924)
scores = (0.57136925170492658, 0.43449965242326172, 0.47914970237846077, 0.28398520631495949, 0.072475343336009315, 0.49125089684971274, 0.49264565983632991, 0.78301855217240179, 0.35924206866937186, 0.61275309087228069, 0.289737766211693, 1.6425311816090924)
score = 0.42851365209482406
holdout = ((0.45183108093319818, 0.55024674034969467, 0.13642817416916234), (0.37387976780581927, 0.45165368998368943, 0.10700901736797916), (0.38543755191150442, 0.45886856920854541, 0.11581321947409999), (0.38331278264341573, 0.48088743335597284, 0.15808724201892155), (0.36045720318702579, 0.40574284896813279, 0.15331922161000777), (0.3872839220872672, 0.51138945056648422, 0.12543809348547802), (0.38077309006740201, 0.47129347634902091, 0.14160610357932576), (0.37595973415784661, 0.49631464657374913, 0.13202889068674975), (0.38493612907378705, 0.49651259763254069, 0.13351592668462151), (0.37639651664188262, 0.48901186764652999, 0.12653063902573022), (0.36299740760461852, 0.48959319943774826, 0.15199361480666745), (0.39233812799354417, 0.51377336291395292, 0.11550870815915421))
>>> t = 20 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 54
<SML_1_1_0>0|Return{oo|cc|aoo|acc|doc|daoc|vp5dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp5dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      ))#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 20 <SML_1_1_0>
nbest = 202
train = (1.5593663730956127, 1.5693328101967983, 1.5559085079015542, 1.532138125566948, 1.615975604920403, 1.590388903103032, 1.5867417050672017, 1.572137445109151, 1.6077358735311793, 1.5812333971669394, 1.5717572781114384, 1.5955937696821596)
scores = (0.60390824044538605, 0.47063526681222573, 0.51434272593415198, 0.31644458010972154, 0.11276935888046781, 0.52797620707253912, 0.53941856976560132, 0.77065196758534038, 0.33499458294260465, 0.6110138630229669, 0.31802248983809756, 1.5955937696821596)
score = 0.4561743618168975
holdout = ((0.43868792987613781, 0.55068124724580891, 0.16285567947264765), (0.40262176581132592, 0.47246067405594872, 0.14920403820671035), (0.41901764020863236, 0.48310053507445566, 0.13776064428766818), (0.40012942972523219, 0.50753236108325495, 0.18552127966024801), (0.38159797059853307, 0.41408119119792081, 0.17325154023722547), (0.42556178766535419, 0.49788422810832639, 0.144567483255607), (0.41610166954382477, 0.48511371383217866, 0.17819824387612301), (0.41515877035092663, 0.51148281234507142, 0.14067800208777803), (0.400790298739372, 0.49912970297844228, 0.15061991773014644), (0.39224213202874142, 0.49253378508292245, 0.15026711657645378), (0.39137241656456528, 0.50849669858960667, 0.17223204665291181), (0.40844686662251489, 0.50883942679177274, 0.15291803312448227))
>>> t = 21 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 74
<SML_1_0_0>0|Return{oo|cc|aoo|acc|doc|daoc|vp5dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 21 <SML_1_0_0>
nbest = 285
train = (1.775212667648131, 1.797086242205749, 1.7814561244616327, 1.7558113811820688, 1.85191720125165, 1.8069955191158278, 1.8025252066291491, 1.7815658845007298, 1.8269691902746568, 1.8068618060521842, 1.794016857125351, 1.820141592465677)
scores = (0.80499969133293836, 0.52576177617893893, 0.62190755733408931, 0.44241540535558366, 0.10705206171262242, 0.58616265933066203, 0.60223829662092832, 0.79620899215797758, 0.36806495265843947, 0.58854382226069268, 0.36166030236431518, 1.820141592465677)
score = 0.5094828588881894
holdout = ((0.47047837837712636, 0.54301625847125568, 0.28040687453448859), (0.45867279419564178, 0.45073186697330425, 0.21620673962025813), (0.45525492950983076, 0.48640511100466999, 0.25512285182794203), (0.45114370035824863, 0.48831771434693633, 0.25766166118283468), (0.43084616633515799, 0.42679358145705021, 0.2731178098854154), (0.46679497434240547, 0.52046800230400458, 0.25365735585799187), (0.46806350837152094, 0.48736370406461371, 0.24755176050701216), (0.44660805604189763, 0.47914088303571983, 0.27395213448141736), (0.4659389090496972, 0.4989720385266298, 0.22533103701372759), (0.44182757787520421, 0.46085293195901245, 0.2533513993965284), (0.4242129644699143, 0.47985527023387792, 0.25850716788067851), (0.46669626159749311, 0.48912601812289175, 0.26341075559186128))
>>> t = 22 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 74
<SML_0_1_1>0|#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp5dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp5dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 22 <SML_0_1_1>
nbest = 412
train = (1.7878647343881162, 1.8155662059173903, 1.8013416135063258, 1.7797797906398998, 1.8633878138998745, 1.8203118772842581, 1.8296849583271775, 1.8052222144421666, 1.8432799344294282, 1.8216904791097037, 1.8077014399640041, 1.8462732516534714)
scores = (0.7540453389339159, 0.49190594519850633, 0.60672826762198051, 0.42264040506522904, 0.081145034137100946, 0.58569289945376091, 0.50527990742836226, 0.74889529200551774, 0.42676049193374277, 0.57415048774467192, 0.33194326379801414, 1.8462732516534714)
score = 0.4817412167019556
holdout = ((0.49491430647401308, 0.48305106182754787, 0.20795983330935061), (0.46586093943895518, 0.38018635410062512, 0.17825845966714052), (0.43149715410234141, 0.41981181797114969, 0.20670697069956184), (0.42862425246949604, 0.48405416234706999, 0.18470072857923273), (0.41328842106490721, 0.39924885111241482, 0.2018879001538883), (0.48240598582977462, 0.41796409174439247, 0.18253412679158751), (0.44070547839212787, 0.4179635951477334, 0.21581022466512456), (0.43476563878928137, 0.44609260437903553, 0.2004008170980128), (0.44796341379596782, 0.44887059179262001, 0.17852777110501888), (0.43677874782225112, 0.41577697822218074, 0.19454268472427552), (0.42580102315859547, 0.43148068246615701, 0.20541144995144783), (0.43967450050688894, 0.43970668789867867, 0.19606663306354719))
>>> t = 23 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 111
<SML_1_1_0>0|Return{oo|cc|aoo|acc|doc|daoc|vp5dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|Return{oo|cc|aoo|acc|doc|daoc|vp5dd}&(<Five>
    <>~Market&(
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|doo|vp1dd|vp5dd|Volatility)
            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]
          }
      )|<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 23 <SML_1_1_0>
nbest = 375
train = (1.7915367926239274, 1.806074364488655, 1.8036705847615262, 1.7824490324725726, 1.87386077763471, 1.8222270085391079, 1.8242492164936173, 1.8125084766717265, 1.8449512382164786, 1.8284806008043772, 1.8082151629210967, 1.8375560799846593)
scores = (0.77567867454270678, 0.51781288722832386, 0.63255481579760731, 0.43555787440760563, 0.10235202958801545, 0.59977916881754201, 0.57607877959867992, 0.78064462011477742, 0.39260602885025114, 0.60298802625220271, 0.35106979618258632, 1.8375560799846593)
score = 0.5050376505539185
holdout = ((0.47020717867475531, 0.51736752065228597, 0.24372618829102316), (0.44127415953161003, 0.39524184204528412, 0.22467777401794284), (0.43086898404557983, 0.45582863682006181, 0.21966313234010781), (0.42566748490527778, 0.50772968732086943, 0.20955197784938392), (0.41765461066336806, 0.42603034825350439, 0.21930533334369767), (0.4362785530314815, 0.47852678003456489, 0.22334956640875833), (0.44990408280118566, 0.41590466519566233, 0.20873408445982153), (0.43526848506342797, 0.46687763953102118, 0.21532726727557441), (0.44427611676842566, 0.44386124343216243, 0.21165973173947392), (0.42376149291841442, 0.4436899797259295, 0.20118765517591092), (0.41764058066863796, 0.45900967751455496, 0.22776232098444152), (0.46814092926023204, 0.46082024705077168, 0.23539961462312747))
>>> t = 24 ===================================================================================================
(pair) putting together [len=557297*2]... (pair) done
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 38
<SML_1_0_0>0|Return{oo|cc|aoo|acc|doc|daoc|vp5dd}&(<Short>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|dcc|doc|daoc|vp1dd)
            & index[0,1,2, 0:1,1:2,0:2]
          }
      ))#<>#0|#<>#0|#<>#0
len(samps) = 12
[[2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096, 'num_iterations': 500}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 10, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 24 <SML_1_0_0>
nbest = 64
train = (1.4601494004726665, 1.4541793522969084, 1.4389929458027282, 1.454392907131381, 1.4437680177273078, 1.4657054683568935, 1.4507579321392683, 1.4601161820752302, 1.4520228203567829, 1.4604067206593185, 1.444404413484826, 1.4783016781289759)
scores = (0.75778596011610955, 0.16562336957008272, 0.52322262800445107, 0.44526296088608502, 0.082201466163611667, 0.50769752420287251, 0.38340767532341596, 0.29858776928327069, 0.53565759532733082, 0.20117468169044139, 0.31004245987669687, 1.4783016781289759)
score = 0.34469208246118316
holdout = ((0.2092433302949008, 0.33286548495915841, 0.18131434122633849), (0.19934652868993327, 0.3905999768805864, 0.16577754034514988), (0.15325248906383107, 0.32047010319438757, 0.13775293268516983), (0.13630892869788777, 0.34279997118345706, 0.20963970994295339), (0.10794068730738743, 0.32769723789312705, 0.19121490997120136), (0.19171310951786349, 0.3034021537324032, 0.092944838844684782), (0.1438480376352019, 0.29882592863336765, 0.18529398649018139), (0.18519599418375909, 0.35391974570284401, 0.14419114055054502), (0.20273264238028674, 0.33797486185266273, 0.14862712857565658), (0.16156399112464551, 0.37162603331362259, 0.17044100276110083), (0.14589533665830226, 0.33777845809419699, 0.16016506651073223), (0.15539191976909494, 0.35156913614955942, 0.14465502910752817))