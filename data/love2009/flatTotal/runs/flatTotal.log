>>> t = 0 ===================================================================================================
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 72
<IKGHomoThree>
    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|daoc)
            & index[0]
          }
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo)
            & [3:,6:,9:,12:,15:,18:,6:3,9:6,12:9,15:12,18:15,21:18,9:3,12:6,            15:9,18:12,21:15,12:3,15:6,18:9,21:12,15:3,18:6,21:9,18:3,21:6,21:3]
          }
        | (
            <>Return{(oo{.&[1:]}|aoo[1:])}
            & (
                <> ~Drawdown&~Drawup&~Since{Min}&~Since{Max}
                | Drawdown[1:, 5:,10:]
                | Since{Max&index[0]}
                | Since{Min&index[0,10]}
              )
            & Since[21:,62:,125:,250:]
          )
      )
    
len(samps) = 14
[[2009.0, 2009.25], [2009.5, 2009.75], [2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 100, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
.
<<<RESULTS>>>: walk 0 <IKGHomoThree>
nbest = 821
train = (2.0605624005488261, 1.6007653015969523, 1.6192192318332199, 1.6039116212436262, 1.6366166054814828, 1.5946414506850242, 1.5787938896364841, 1.6229109403012816, 1.6078704557266539, 1.6254855558293317, 1.6608693705809006, 1.6527153941737467, 1.6339179952902447, 1.63984609596985)
scores = (0.86656665329631133, 0.91130009640717446, 0.61013598603818409, 0.54624219408259789, 0.76146581663434221, 0.51259017141264529, 0.94764705958639961, 0.6081705962066386, 0.7846499645278987, 0.86742157238603945, 0.53136974587561203, 0.65369676392768838, 0.40216833047458717, 1.63984609596985)
score = 0.6698376584017167
holdout = ((0.57015464986408548, 0.51325159696271716, 0.39593861451581397), (0.55859790648266017, 0.57213019439442736, 0.35683803252267732), (0.53775755309993012, 0.58922193851008975, 0.38747701272329071), (0.53193714459931718, 0.60319185149719101, 0.39282431655648165), (0.54364593401587447, 0.59030142743415681, 0.38925024266165537), (0.52882573663699906, 0.68356402275398931, 0.42213147845915905), (0.50764390945889781, 0.61849158622828815, 0.41513331808722431), (0.54238581521441687, 0.56664755664622535, 0.38230657982599525), (0.50311348139634193, 0.59630324469233109, 0.39802159808808224), (0.58647658953388693, 0.63926302593243645, 0.37604653254649167), (0.54619192981035691, 0.58907940230408207, 0.38895091219886385), (0.49833992945813343, 0.61113894728691753, 0.39918446054156509), (0.53365329531211803, 0.61145290606813141, 0.41407786283113102), (0.53690753829207938, 0.60862359691858992, 0.39979136798989023))
>>>  k = 1 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 50.0, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 1 <IKGHomoThree>
nbest = 362
train = (2.0496950105364471, 1.568312644052493, 1.5897082209730586, 1.5766378867190973, 1.6066263390075912, 1.5670883688379964, 1.5556851007423924, 1.5877581362003734, 1.5803164587065628, 1.599134657517238, 1.6273624607012269, 1.6297548963056532, 1.5964206609155636, 1.6053971079429548)
scores = (0.89110614269574695, 0.87091578214244503, 0.62153808037827429, 0.54622248655811978, 0.75613304163076611, 0.50791851333478888, 0.96754640115501533, 0.61800119297835798, 0.79381190990696127, 0.87933348513370679, 0.51593821901717352, 0.65743251934866309, 0.41019743500146899, 1.6053971079429548)
score = 0.6741319738241767
holdout = ((0.56590104535516794, 0.50812409046766449, 0.38348939209517813), (0.55011506294260237, 0.56739079267682224, 0.35546354084969189), (0.54340071801996959, 0.5999045816405375, 0.38216698186799591), (0.5366402886841577, 0.5916481072966393, 0.40043716467175811), (0.53510704895126759, 0.56774486214925224, 0.38286165294514701), (0.53941157571154552, 0.68712206918745034, 0.41486234094934826), (0.49784354081659604, 0.63088421350123758, 0.41542717511777133), (0.5684630055898966, 0.54570969070543518, 0.38451000734376778), (0.52346331439338034, 0.58040870907372577, 0.38981002508269663), (0.59144159795102469, 0.6355495336338185, 0.37093532334529539), (0.55375526624514604, 0.57427315678830071, 0.37776687274241488), (0.49024687181236637, 0.57979901347769602, 0.39709821183751448), (0.55009076755669373, 0.62427692778862875, 0.39764783008700855), (0.54166461626277984, 0.59614100802118708, 0.39969002009640098))
>>>  k = 2 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 2 <IKGHomoThree>
nbest = 821
train = (2.0605624005488261, 1.6007653015969523, 1.6192192318332199, 1.6039116212436262, 1.6366166054814828, 1.5946414506850242, 1.5787938896364841, 1.6229109403012816, 1.6078704557266539, 1.6254855558293317, 1.6608693705809006, 1.6527153941737467, 1.6339179952902447, 1.63984609596985)
scores = (0.86656665329631133, 0.91130009640717446, 0.61013598603818409, 0.54624219408259789, 0.76146581663434221, 0.51259017141264529, 0.94764705958639961, 0.6081705962066386, 0.7846499645278987, 0.86742157238603945, 0.53136974587561203, 0.65369676392768838, 0.40216833047458717, 1.63984609596985)
score = 0.6698376584017167
holdout = ((0.57015464986408548, 0.51325159696271716, 0.39593861451581397), (0.55859790648266017, 0.57213019439442736, 0.35683803252267732), (0.53775755309993012, 0.58922193851008975, 0.38747701272329071), (0.53193714459931718, 0.60319185149719101, 0.39282431655648165), (0.54364593401587447, 0.59030142743415681, 0.38925024266165537), (0.52882573663699906, 0.68356402275398931, 0.42213147845915905), (0.50764390945889781, 0.61849158622828815, 0.41513331808722431), (0.54238581521441687, 0.56664755664622535, 0.38230657982599525), (0.50311348139634193, 0.59630324469233109, 0.39802159808808224), (0.58647658953388693, 0.63926302593243645, 0.37604653254649167), (0.54619192981035691, 0.58907940230408207, 0.38895091219886385), (0.49833992945813343, 0.61113894728691753, 0.39918446054156509), (0.53365329531211803, 0.61145290606813141, 0.41407786283113102), (0.53690753829207938, 0.60862359691858992, 0.39979136798989023))
>>>  k = 3 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 50.0, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 3 <IKGHomoThree>
nbest = 362
train = (2.0496950105364471, 1.568312644052493, 1.5897082209730586, 1.5766378867190973, 1.6066263390075912, 1.5670883688379964, 1.5556851007423924, 1.5877581362003734, 1.5803164587065628, 1.599134657517238, 1.6273624607012269, 1.6297548963056532, 1.5964206609155636, 1.6053971079429548)
scores = (0.89110614269574695, 0.87091578214244503, 0.62153808037827429, 0.54622248655811978, 0.75613304163076611, 0.50791851333478888, 0.96754640115501533, 0.61800119297835798, 0.79381190990696127, 0.87933348513370679, 0.51593821901717352, 0.65743251934866309, 0.41019743500146899, 1.6053971079429548)
score = 0.6741319738241767
holdout = ((0.56590104535516794, 0.50812409046766449, 0.38348939209517813), (0.55011506294260237, 0.56739079267682224, 0.35546354084969189), (0.54340071801996959, 0.5999045816405375, 0.38216698186799591), (0.5366402886841577, 0.5916481072966393, 0.40043716467175811), (0.53510704895126759, 0.56774486214925224, 0.38286165294514701), (0.53941157571154552, 0.68712206918745034, 0.41486234094934826), (0.49784354081659604, 0.63088421350123758, 0.41542717511777133), (0.5684630055898966, 0.54570969070543518, 0.38451000734376778), (0.52346331439338034, 0.58040870907372577, 0.38981002508269663), (0.59144159795102469, 0.6355495336338185, 0.37093532334529539), (0.55375526624514604, 0.57427315678830071, 0.37776687274241488), (0.49024687181236637, 0.57979901347769602, 0.39709821183751448), (0.55009076755669373, 0.62427692778862875, 0.39764783008700855), (0.54166461626277984, 0.59614100802118708, 0.39969002009640098))
>>> t = 1 ===================================================================================================
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 89
<s21>    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(vp1dd)
            & index[0,2, 0:1]
          }
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(doo|vp5dd|Volatility)
            & [5:,15:,10:5,15:10,20:15,15:5,20:5]
          }
        | (
            <>Return{(oo{.&[1:]}|aoo[1:]|oo{.&[10:]})}
            & (
                <> ~Drawdown&~Drawup&~Since{Min}&~Since{Max}
                | Drawdown[1:,10:,20:]
                | Since{Max&index[0,10]}
                | Since{Min&index[0,20]}
              )
            & Since[21:, 125:, 250:]
          )
      )
    | Market{.&
        <>(~Weight)
        & (Return| Volatility)
        & [20:,60:]
      }
    |
        | FracRec[21:,125:,250:]
    |
len(samps) = 14
[[2009.0, 2009.25], [2009.5, 2009.75], [2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 4 <s21>
nbest = 42
train = (1.134489650891684, 1.0485950917569424, 1.0489660407483676, 1.0490863205990522, 1.0727490718107333, 1.0347906165063747, 1.0323436457564132, 1.064245028898257, 1.0372470654747117, 1.0488205311894456, 1.0582082503957722, 1.0425250998164275, 1.0505216992255093, 1.0506004228164196)
scores = (0.44626255527457154, 0.56067239556613391, 0.54556174432348858, 0.64753432063153971, 0.81331576040214359, 0.42956125482991514, 1.0361113345326776, 0.5195907522439922, 0.81955372253329728, 0.89920390485988211, 0.53249608349292421, 0.67821763912308686, 0.36617864445687942, 1.0506004228164196)
score = 0.6064264068927238
holdout = ((0.45893624395706739, 0.58223633853057966, 0.3380927790604627), (0.44279862665830622, 0.46878264508135536, 0.34051688468101587), (0.48449410519081626, 0.50907543149862644, 0.34406435965899079), (0.45680264153594907, 0.66462684400518046, 0.33113821937374566), (0.42400231810141276, 0.54335721521256131, 0.32414181164296729), (0.45710786410554455, 0.55551293726389039, 0.33402442335372395), (0.42655018386916793, 0.49474599866875008, 0.34527098813924267), (0.42593012416186604, 0.49018834445265663, 0.36703867017570246), (0.43941863876885456, 0.61246219496169196, 0.35102222930765292), (0.4626212126810571, 0.50643331738381958, 0.31446747773340761), (0.43321978485807283, 0.50078110640513063, 0.31150187162839554), (0.39734748335264303, 0.4775737319430654, 0.30428211685274587), (0.41058840541867614, 0.56089286455291942, 0.33536790314820636), (0.41983701351715585, 0.52637310806863447, 0.32410580301860586))
>>>  k = 1 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 50.0, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 5 <s21>
nbest = 33
train = (1.2385827065655031, 1.1165209664356037, 1.1152820452129433, 1.1183266341410738, 1.1422321657972467, 1.1034274633156627, 1.0984185813361609, 1.1289264823071041, 1.1156885425770591, 1.1264079769588708, 1.1380295207839664, 1.1157596209162948, 1.1106297426038669, 1.1179665663345262)
scores = (0.45497710186958701, 0.52602068135591795, 0.54824322794512359, 0.62665800946813033, 0.83415156701863924, 0.3748856500796226, 1.0652779364964811, 0.49217894469882162, 0.77323792094924049, 0.90693862233848721, 0.51780239665990457, 0.69825158708778523, 0.3656741558851076, 1.1179665663345262)
score = 0.5930545199174337
holdout = ((0.43681785756559716, 0.49903456830923337, 0.34842421952246433), (0.43480454139061708, 0.42824337277267538, 0.34072391595096896), (0.47720498871129091, 0.52559593556714956, 0.38450066295554997), (0.46465580914732735, 0.65781997863587871, 0.3326815425416515), (0.42427451667402766, 0.51090899176511684, 0.3170364695684415), (0.43636747260679787, 0.52844973143560892, 0.36074830831499871), (0.45851936016970962, 0.45818234433205202, 0.35824851849495393), (0.38197760236673239, 0.47943667821566283, 0.37292923607757861), (0.42777195696838716, 0.52084758763077776, 0.36353428498260171), (0.45699897549837409, 0.49875904187672609, 0.32595250661606162), (0.42585493969894, 0.4159260180040148, 0.34487104948167652), (0.39355335642450273, 0.43487635161476867, 0.33586854408805961), (0.42326166264198267, 0.48706251340131862, 0.35674058739952064), (0.44782677725421693, 0.47263798375851079, 0.36335891043354634))
>>>  k = 2 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 6 <s21>
nbest = 42
train = (1.134489650891684, 1.0485950917569424, 1.0489660407483676, 1.0490863205990522, 1.0727490718107333, 1.0347906165063747, 1.0323436457564132, 1.064245028898257, 1.0372470654747117, 1.0488205311894456, 1.0582082503957722, 1.0425250998164275, 1.0505216992255093, 1.0506004228164196)
scores = (0.44626255527457154, 0.56067239556613391, 0.54556174432348858, 0.64753432063153971, 0.81331576040214359, 0.42956125482991514, 1.0361113345326776, 0.5195907522439922, 0.81955372253329728, 0.89920390485988211, 0.53249608349292421, 0.67821763912308686, 0.36617864445687942, 1.0506004228164196)
score = 0.6064264068927238
holdout = ((0.45893624395706739, 0.58223633853057966, 0.3380927790604627), (0.44279862665830622, 0.46878264508135536, 0.34051688468101587), (0.48449410519081626, 0.50907543149862644, 0.34406435965899079), (0.45680264153594907, 0.66462684400518046, 0.33113821937374566), (0.42400231810141276, 0.54335721521256131, 0.32414181164296729), (0.45710786410554455, 0.55551293726389039, 0.33402442335372395), (0.42655018386916793, 0.49474599866875008, 0.34527098813924267), (0.42593012416186604, 0.49018834445265663, 0.36703867017570246), (0.43941863876885456, 0.61246219496169196, 0.35102222930765292), (0.4626212126810571, 0.50643331738381958, 0.31446747773340761), (0.43321978485807283, 0.50078110640513063, 0.31150187162839554), (0.39734748335264303, 0.4775737319430654, 0.30428211685274587), (0.41058840541867614, 0.56089286455291942, 0.33536790314820636), (0.41983701351715585, 0.52637310806863447, 0.32410580301860586))
>>>  k = 3 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 7 <s21>
nbest = 42
train = (1.134489650891684, 1.0485950917569424, 1.0489660407483676, 1.0490863205990522, 1.0727490718107333, 1.0347906165063747, 1.0323436457564132, 1.064245028898257, 1.0372470654747117, 1.0488205311894456, 1.0582082503957722, 1.0425250998164275, 1.0505216992255093, 1.0506004228164196)
scores = (0.44626255527457154, 0.56067239556613391, 0.54556174432348858, 0.64753432063153971, 0.81331576040214359, 0.42956125482991514, 1.0361113345326776, 0.5195907522439922, 0.81955372253329728, 0.89920390485988211, 0.53249608349292421, 0.67821763912308686, 0.36617864445687942, 1.0506004228164196)
score = 0.6064264068927238
holdout = ((0.45893624395706739, 0.58223633853057966, 0.3380927790604627), (0.44279862665830622, 0.46878264508135536, 0.34051688468101587), (0.48449410519081626, 0.50907543149862644, 0.34406435965899079), (0.45680264153594907, 0.66462684400518046, 0.33113821937374566), (0.42400231810141276, 0.54335721521256131, 0.32414181164296729), (0.45710786410554455, 0.55551293726389039, 0.33402442335372395), (0.42655018386916793, 0.49474599866875008, 0.34527098813924267), (0.42593012416186604, 0.49018834445265663, 0.36703867017570246), (0.43941863876885456, 0.61246219496169196, 0.35102222930765292), (0.4626212126810571, 0.50643331738381958, 0.31446747773340761), (0.43321978485807283, 0.50078110640513063, 0.31150187162839554), (0.39734748335264303, 0.4775737319430654, 0.30428211685274587), (0.41058840541867614, 0.56089286455291942, 0.33536790314820636), (0.41983701351715585, 0.52637310806863447, 0.32410580301860586))
>>> t = 2 ===================================================================================================
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 127
<s10>    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|dcc)
            & index[0,1,2, 0:1,1:2]
          }
        | (
            <>Return{(oo{.&[1:]}|oo{.&[10:]}|doo[10:])}
            & (
                <> ~Drawdown&~Drawup&~Since{Min}&~Since{Max}
                | Drawdown[1:, 5:,10:, 10:5]
                | Since{Max&index[0]}
                | Since{Min&index[0,5]}
              )
            & Since[21:, 125:, 250:]
          )
        | (
            <>Return{dd} & VP[1:, 5:, 10:]
            & (
                <> ~Drawdown&~Drawup&~Since{Min}&~Since{Max}
                | Since{Max & index[5]}
                | Drawup[20:10]
                | Since{Min & index[20]}
              )
            & Since[21:, 125:, 250:]
          )
        | (
            <> Volatility[ 60:]
            | Volatility[10:]
            & (
                | Since{Max & index[20]}
                | Since{Min & index[20]}
              )
            & Since[21:, 125:, 250:]
          )
      )
    |
        Time{long| short}
len(samps) = 14
[[2009.0, 2009.25], [2009.5, 2009.75], [2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 8 <s10>
nbest = 165
train = (1.484879733153464, 1.2884214274782309, 1.3268675120184683, 1.3007441593271856, 1.3164057524010644, 1.3195218795116486, 1.2765819005264527, 1.2999837518137591, 1.2913467970150645, 1.3291368903760972, 1.3482910814436264, 1.3259245660505985, 1.3256359684288139, 1.3019298797734538)
scores = (0.63495374418113493, 0.67370390843194028, 0.53200206838203978, 0.45170771982358399, 0.65751922112286332, 0.49842401372541628, 0.92309081975431029, 0.62163941772013254, 0.92095643264442306, 0.87497978796118026, 0.54536716931717921, 0.61598538580797257, 0.34961441923704845, 1.3019298797734538)
score = 0.5969341262181418
holdout = ((0.65112337800456788, 0.40939244625907956, 0.46214240311579874), (0.66752993504612423, 0.5034357532383289, 0.4614890623275415), (0.62920023197000774, 0.47249184332717858, 0.47242906107767146), (0.74981613209797848, 0.53202951870216608, 0.33943852979619665), (0.6528775301036529, 0.54011772508576572, 0.36662231725626454), (0.62510876832976292, 0.57882791170959003, 0.45922201830799497), (0.62469795477868117, 0.65157741826676285, 0.44403575766291548), (0.66137665218578912, 0.52446386178158166, 0.43559307139524955), (0.61223204823158561, 0.46469276214888011, 0.44800384583704372), (0.58622478710628356, 0.57550652782788758, 0.42789614094896827), (0.62940996057704313, 0.52090593443827882, 0.42933947114768456), (0.52837531907534241, 0.57984655330099855, 0.46077812972408905), (0.58538322056423109, 0.55951189835686777, 0.46390084456805614), (0.6242123541736776, 0.53222517548120762, 0.44556077672244965))
>>>  k = 1 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 50.0, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 9 <s10>
nbest = 89
train = (1.5092672505386742, 1.2735835745235879, 1.3073632579197469, 1.2847777141475911, 1.3105991324796995, 1.2961478058396929, 1.2596040478076636, 1.2825838772362521, 1.2732383593632832, 1.3101182787998302, 1.3088319148964154, 1.3092010345236167, 1.3161446379313828, 1.2998371099924064)
scores = (0.5981620933181373, 0.62058181403864976, 0.55826778864502546, 0.46962109131789187, 0.66113768485760738, 0.53706340948163267, 0.89118803053654516, 0.59245190249863333, 0.95484017026270351, 0.86638106082486865, 0.53836163696033945, 0.6262762017859369, 0.38491678844627619, 1.2998371099924064)
score = 0.5935502988821737
holdout = ((0.68199275765933298, 0.37202107526442313, 0.45956356241229523), (0.65073164698967878, 0.47557456557919064, 0.45555531381400705), (0.62896819529335823, 0.4641425211086499, 0.4383034978623585), (0.72744172775311988, 0.51506258970692764, 0.29920809914739221), (0.63173710466521726, 0.53664520734929, 0.35723658884813325), (0.58019819954212715, 0.56854714737770595, 0.44939060565798583), (0.63421903339433239, 0.67012273470450334, 0.45181355143063623), (0.66802685218670332, 0.5282913086933585, 0.43400174546190651), (0.61442330083336905, 0.44792672254529453, 0.42829538330819172), (0.63858406543536517, 0.49786501749979584, 0.43040369861423616), (0.63387644068099758, 0.48208512176730756, 0.42565057018440672), (0.54191753049439328, 0.53161408874527827, 0.44156310080325267), (0.60969966877681858, 0.50865738790459292, 0.43191001894080672), (0.63106138462127337, 0.52162886185736879, 0.43877437510959122))
>>>  k = 2 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 10 <s10>
nbest = 165
train = (1.484879733153464, 1.2884214274782309, 1.3268675120184683, 1.3007441593271856, 1.3164057524010644, 1.3195218795116486, 1.2765819005264527, 1.2999837518137591, 1.2913467970150645, 1.3291368903760972, 1.3482910814436264, 1.3259245660505985, 1.3256359684288139, 1.3019298797734538)
scores = (0.63495374418113493, 0.67370390843194028, 0.53200206838203978, 0.45170771982358399, 0.65751922112286332, 0.49842401372541628, 0.92309081975431029, 0.62163941772013254, 0.92095643264442306, 0.87497978796118026, 0.54536716931717921, 0.61598538580797257, 0.34961441923704845, 1.3019298797734538)
score = 0.5969341262181418
holdout = ((0.65112337800456788, 0.40939244625907956, 0.46214240311579874), (0.66752993504612423, 0.5034357532383289, 0.4614890623275415), (0.62920023197000774, 0.47249184332717858, 0.47242906107767146), (0.74981613209797848, 0.53202951870216608, 0.33943852979619665), (0.6528775301036529, 0.54011772508576572, 0.36662231725626454), (0.62510876832976292, 0.57882791170959003, 0.45922201830799497), (0.62469795477868117, 0.65157741826676285, 0.44403575766291548), (0.66137665218578912, 0.52446386178158166, 0.43559307139524955), (0.61223204823158561, 0.46469276214888011, 0.44800384583704372), (0.58622478710628356, 0.57550652782788758, 0.42789614094896827), (0.62940996057704313, 0.52090593443827882, 0.42933947114768456), (0.52837531907534241, 0.57984655330099855, 0.46077812972408905), (0.58538322056423109, 0.55951189835686777, 0.46390084456805614), (0.6242123541736776, 0.53222517548120762, 0.44556077672244965))
>>>  k = 3 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 11 <s10>
nbest = 165
train = (1.484879733153464, 1.2884214274782309, 1.3268675120184683, 1.3007441593271856, 1.3164057524010644, 1.3195218795116486, 1.2765819005264527, 1.2999837518137591, 1.2913467970150645, 1.3291368903760972, 1.3482910814436264, 1.3259245660505985, 1.3256359684288139, 1.3019298797734538)
scores = (0.63495374418113493, 0.67370390843194028, 0.53200206838203978, 0.45170771982358399, 0.65751922112286332, 0.49842401372541628, 0.92309081975431029, 0.62163941772013254, 0.92095643264442306, 0.87497978796118026, 0.54536716931717921, 0.61598538580797257, 0.34961441923704845, 1.3019298797734538)
score = 0.5969341262181418
holdout = ((0.65112337800456788, 0.40939244625907956, 0.46214240311579874), (0.66752993504612423, 0.5034357532383289, 0.4614890623275415), (0.62920023197000774, 0.47249184332717858, 0.47242906107767146), (0.74981613209797848, 0.53202951870216608, 0.33943852979619665), (0.6528775301036529, 0.54011772508576572, 0.36662231725626454), (0.62510876832976292, 0.57882791170959003, 0.45922201830799497), (0.62469795477868117, 0.65157741826676285, 0.44403575766291548), (0.66137665218578912, 0.52446386178158166, 0.43559307139524955), (0.61223204823158561, 0.46469276214888011, 0.44800384583704372), (0.58622478710628356, 0.57550652782788758, 0.42789614094896827), (0.62940996057704313, 0.52090593443827882, 0.42933947114768456), (0.52837531907534241, 0.57984655330099855, 0.46077812972408905), (0.58538322056423109, 0.55951189835686777, 0.46390084456805614), (0.6242123541736776, 0.53222517548120762, 0.44556077672244965))
>>> t = 3 ===================================================================================================
setup_training %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
len(feats) = 64
<s00>    <>~Market & (
        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&
            <>(oo|cc|aoo|acc|doo|vp1dd)
            & index[0,1,2, 0:1,0:2]
          }
        | Return{.&pure&~index} & ~Since & Return{.&
            <>(oo|aoo|vp1dd)
            & [5:,10:,15:,15:10,20:15,15:5,20:10]
          }
        | (
            <>Return{(oo{.&[1:]})}
            & (
                | Drawdown[10:,20:]
                | Since{Max&index[10,20]}
                | Drawup[1:]
                | Since{Min&index[0,5]}
              )
            & Since[ 62:, 250:]
          )
        | (
            <> Volatility[ 60:]
            | Volatility[ 20:]
            & (
                | Since{Max & index[0,5]}
                | Drawup[ 10:5,20:10]
                | Since{Min & index[20]}
              )
            & Since[ 62:, 250:]
          )
      )
    |
        <>Return{pure&~dd} & VP[10:]
    |
len(samps) = 14
[[2009.0, 2009.25], [2009.5, 2009.75], [2010.0, 2010.25], [2010.5, 2010.75], [2011.0, 2011.25], [2011.5, 2011.75], [2012.0, 2012.25], [2012.5, 2012.75], [2013.0, 2013.25], [2013.5, 2013.75], [2014.0, 2014.25], [2014.5, 2014.75], [2015.0, 2015.25], []]
>>>  k = 0 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 12 <s00>
nbest = 710
train = (2.0755616314703955, 1.6884714699942132, 1.7030863329957699, 1.6788149145200544, 1.6966838706253795, 1.7108824369808877, 1.6410846289102647, 1.7002682026409079, 1.6751427740326768, 1.6906836754459584, 1.7319373352041059, 1.7379231058502909, 1.7021505680410454, 1.711519091968785)
scores = (0.57444994143268358, 0.79709410768245537, 0.58532802930494843, 0.51378036573741659, 0.73741918458488265, 0.40170636035928181, 0.96154567456925244, 0.61701935113650364, 0.82838232701335912, 0.83914207018785203, 0.53492276649507842, 0.67429559092659563, 0.43415030838587371, 1.711519091968785)
score = 0.6204475163979839
holdout = ((0.63869724364864267, 0.69407091014788735, 0.387534639115723), (0.58465937973348125, 0.73626219050601538, 0.34307245793051133), (0.60189835731874564, 0.72650556767895191, 0.37645909189657989), (0.62104435544326941, 0.74883681092304255, 0.37408706240358708), (0.57241936129411675, 0.69418050010203902, 0.38364501876858331), (0.58014695442907938, 0.79004799227854161, 0.39168182903276477), (0.54111945433158326, 0.70099660679493303, 0.37699833446454661), (0.61089877393218472, 0.7139890789452028, 0.36757483149500092), (0.56423390389845862, 0.73285278006047838, 0.38006723585870283), (0.61742256379551408, 0.76245802499706383, 0.37909857262838176), (0.59131406831321598, 0.73298294822596533, 0.36917786741500336), (0.53321562116154175, 0.72168009892411822, 0.364985066333747), (0.5685244774337912, 0.72838610765027956, 0.40185491628129333), (0.59153962948512639, 0.7292304054803147, 0.36957899451963316))
>>>  k = 1 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 50.0, 'lambda_l1': 0, 'lambda_l2': 0}
>>> training...
<<<RESULTS>>>: walk 13 <s00>
nbest = 323
train = (1.99456501777928, 1.6357823534157487, 1.6477916064402396, 1.6372363722852437, 1.6491083577063341, 1.6478470491164132, 1.5892520854868573, 1.6419256514407712, 1.6233037089429303, 1.6486433155708371, 1.6721251121762559, 1.6821392867641141, 1.6520831425341487, 1.6565858018583557)
scores = (0.62215627771222515, 0.77790345349420342, 0.60969057470574894, 0.54204093754646809, 0.7454419876691748, 0.43872993044234593, 0.9513917583237429, 0.60937351439319198, 0.83315701710680867, 0.83940101691556701, 0.53746466741487142, 0.65391606238876498, 0.43429172516205627, 1.6565858018583557)
score = 0.6328098336115441
holdout = ((0.65520949714834575, 0.68216191902488232, 0.36611806305880573), (0.60360078551443663, 0.71572219656531588, 0.33484345583294384), (0.61696196328377895, 0.72299193790688465, 0.35479732533048469), (0.61156391047350589, 0.74242346568812745, 0.36660374811689511), (0.58548295384576676, 0.73029960959130169, 0.36915610968659407), (0.5946062638518711, 0.81823972003273204, 0.38973976883587191), (0.58122928782774175, 0.71843213751747026, 0.37157423808481765), (0.60020514815704007, 0.73785543054679548, 0.36714511560806784), (0.57503515997790733, 0.73114078879094357, 0.38440724978694568), (0.64604979549384134, 0.77486769913868736, 0.351930568739661), (0.59294533649279113, 0.71056004794707883, 0.35037959536328184), (0.54307342786287416, 0.7001432766077349, 0.36541493826980126), (0.57583415536942628, 0.73234806009683662, 0.38823046111739745), (0.60457111883870562, 0.74886405636384146, 0.35682447603835193))
>>>  k = 2 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 14 <s00>
nbest = 710
train = (2.0755616314703955, 1.6884714699942132, 1.7030863329957699, 1.6788149145200544, 1.6966838706253795, 1.7108824369808877, 1.6410846289102647, 1.7002682026409079, 1.6751427740326768, 1.6906836754459584, 1.7319373352041059, 1.7379231058502909, 1.7021505680410454, 1.711519091968785)
scores = (0.57444994143268358, 0.79709410768245537, 0.58532802930494843, 0.51378036573741659, 0.73741918458488265, 0.40170636035928181, 0.96154567456925244, 0.61701935113650364, 0.82838232701335912, 0.83914207018785203, 0.53492276649507842, 0.67429559092659563, 0.43415030838587371, 1.711519091968785)
score = 0.6204475163979839
holdout = ((0.63869724364864267, 0.69407091014788735, 0.387534639115723), (0.58465937973348125, 0.73626219050601538, 0.34307245793051133), (0.60189835731874564, 0.72650556767895191, 0.37645909189657989), (0.62104435544326941, 0.74883681092304255, 0.37408706240358708), (0.57241936129411675, 0.69418050010203902, 0.38364501876858331), (0.58014695442907938, 0.79004799227854161, 0.39168182903276477), (0.54111945433158326, 0.70099660679493303, 0.37699833446454661), (0.61089877393218472, 0.7139890789452028, 0.36757483149500092), (0.56423390389845862, 0.73285278006047838, 0.38006723585870283), (0.61742256379551408, 0.76245802499706383, 0.37909857262838176), (0.59131406831321598, 0.73298294822596533, 0.36917786741500336), (0.53321562116154175, 0.72168009892411822, 0.364985066333747), (0.5685244774337912, 0.72838610765027956, 0.40185491628129333), (0.59153962948512639, 0.7292304054803147, 0.36957899451963316))
>>>  k = 3 ---------------------------------------------------------------------------------------------------
{'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 4096}
{'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 50.0, 'lambda_l1': 0, 'lambda_l2': 0}
<<<RESULTS>>>: walk 15 <s00>
nbest = 323
train = (1.99456501777928, 1.6357823534157487, 1.6477916064402396, 1.6372363722852437, 1.6491083577063341, 1.6478470491164132, 1.5892520854868573, 1.6419256514407712, 1.6233037089429303, 1.6486433155708371, 1.6721251121762559, 1.6821392867641141, 1.6520831425341487, 1.6565858018583557)
scores = (0.62215627771222515, 0.77790345349420342, 0.60969057470574894, 0.54204093754646809, 0.7454419876691748, 0.43872993044234593, 0.9513917583237429, 0.60937351439319198, 0.83315701710680867, 0.83940101691556701, 0.53746466741487142, 0.65391606238876498, 0.43429172516205627, 1.6565858018583557)
score = 0.6328098336115441
holdout = ((0.65520949714834575, 0.68216191902488232, 0.36611806305880573), (0.60360078551443663, 0.71572219656531588, 0.33484345583294384), (0.61696196328377895, 0.72299193790688465, 0.35479732533048469), (0.61156391047350589, 0.74242346568812745, 0.36660374811689511), (0.58548295384576676, 0.73029960959130169, 0.36915610968659407), (0.5946062638518711, 0.81823972003273204, 0.38973976883587191), (0.58122928782774175, 0.71843213751747026, 0.37157423808481765), (0.60020514815704007, 0.73785543054679548, 0.36714511560806784), (0.57503515997790733, 0.73114078879094357, 0.38440724978694568), (0.64604979549384134, 0.77486769913868736, 0.351930568739661), (0.59294533649279113, 0.71056004794707883, 0.35037959536328184), (0.54307342786287416, 0.7001432766077349, 0.36541493826980126), (0.57583415536942628, 0.73234806009683662, 0.38823046111739745), (0.60457111883870562, 0.74886405636384146, 0.35682447603835193))