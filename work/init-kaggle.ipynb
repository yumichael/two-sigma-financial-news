{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# definitely not production code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common import *\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "debug = O()\n",
    "%matplotlib inline\n",
    "canvas(12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ho_time = pd.Timestamp('2015-07-01',tz='UTC')\n",
    "\n",
    "def fake(*,M,N):\n",
    "    M_, N_ = M, N\n",
    "    for time, M in M_.groupby('time'):\n",
    "        if time<ho_time:\n",
    "            continue\n",
    "        M['quarter'] = M.time.dt.year+(M.time.dt.quarter-1)/4\n",
    "        P = M[excluded_columns]\n",
    "        M = M.drop(columns=['returnsOpenNextMktres10','quarter'])\n",
    "        P['confidenceValue'] = 0.\n",
    "        yield M, None, P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #################################################### START HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "M = pd.read_pickle('../data/given/M.pkl')\n",
    "#N = pd.read_pickle(top_dir+'data/given/N1.pkl')\n",
    "test = pd.read_pickle('../data/given/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class __env__():\n",
    "    _submitted = []\n",
    "    # -1 = begin, 0 = just yielded, 1 = just predicted, -2 = finished, -3 = finished and submission file written too\n",
    "    _states = [-1]\n",
    "    \n",
    "    class KaggleEnvError(Exception):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_training_data():\n",
    "        return M, None\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_prediction_days():\n",
    "        env = __class__\n",
    "        \n",
    "        class iter_get_prediction_days():\n",
    "            def __iter__(self):\n",
    "                if env._states[-1] != -1:\n",
    "                    raise env.KaggleEnvError('can only call get_prediction_days once!')\n",
    "                \n",
    "                env._days_iter = test.__iter__()\n",
    "                return self\n",
    "            \n",
    "            def __next__(self):\n",
    "                if env._states[-1] == 0:\n",
    "                    raise env.KaggleEnvError('can only yield next day after the previous day was submitted')\n",
    "                elif env._states[-1] not in [-1, 1, -2, -3]:\n",
    "                    raise env.KaggleEnvError(\n",
    "                        'environment internal error [bad state {} for __next__]'.format(env._states[-1]))\n",
    "                \n",
    "                try:\n",
    "                    ret = env._days_iter.__next__()\n",
    "                except StopIteration:\n",
    "                    if env._states[-1] not in [-2, -3]:\n",
    "                        env._states.append(-2)\n",
    "                    raise\n",
    "                \n",
    "                env._states.append(0)\n",
    "                return ret\n",
    "        \n",
    "        return iter_get_prediction_days()\n",
    "            \n",
    "    @staticmethod\n",
    "    def predict(p):\n",
    "        env = __class__\n",
    "        if env._states[-1] == 1:\n",
    "            raise env.KaggleEnvError('must get next prediction day before submitting a prediction again')\n",
    "        elif env._states[-1] == -1:\n",
    "            raise env.KaggleEnvError('must get next prediction day before submitting a prediction')\n",
    "        elif env._states[-1] in [-2, -3]:\n",
    "            raise env.KaggleEnvError('cannot submit prediction, every prediction has already been submitted')\n",
    "        elif env._states[-1] != 0:\n",
    "            raise env.KaggleEnvError('environment internal error [bad state {}]'.format(env._states[-1]))\n",
    "        env._submitted.append(p)\n",
    "        env._states.append(1)\n",
    "        \n",
    "    @staticmethod\n",
    "    def write_submission_file():\n",
    "        env = __class__\n",
    "        if env._states[-1] not in [-2, -3]:\n",
    "            raise env.KaggleEnvError('must be finished predicting before writing submission file')\n",
    "            \n",
    "        template = pd.concat((day[2] for day in test), axis=0)\n",
    "        try:\n",
    "            submission = pd.concat((sub for sub in env._submitted), axis=0)\n",
    "            assert (template.shape==submission.shape), 'submissions have malformed shape'\n",
    "            assert (template.index==submission.index).all(), 'submissions have malformed index'\n",
    "            assert (template.columns==submission.columns).all(), 'submissions have malformed columns'\n",
    "            assert (template.assetCode==submission.assetCode).all(), 'submissions have malformed assetCode column'\n",
    "        except Exception as e:\n",
    "            raise env.KaggleEnvError(e)\n",
    "        \n",
    "        env._submission = submission\n",
    "        if env._states[-1] != -3:\n",
    "            env._states.append(-3)\n",
    "        print('''Your submission file has been saved. Once you `Commit` your Kernel and it finishes running, '''+\n",
    "                '''you can submit the file to the competition from the Kernel Viewer `Output` tab.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++ production additions ++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random, math, functools, itertools, os, gc\n",
    "from collections import Counter, namedtuple\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import altair as alt\n",
    "#from altair import *\n",
    "#sns.set()\n",
    "plt.style.use(['classic', 'seaborn', 'seaborn-colorblind'])\n",
    "\n",
    "def canvas(width, height):\n",
    "    dpi = 96\n",
    "    from pylab import rcParams\n",
    "    rcParams['figure.figsize'] = width, height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `utility.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from importlib import reload\n",
    "from functools import wraps, reduce\n",
    "\n",
    "class Cache(dict):\n",
    "    __slots__ = ('function',)\n",
    "\n",
    "    def __init__(self, function):\n",
    "        self.function = function\n",
    "    \n",
    "    def __getitem__(self, args):\n",
    "        if not isinstance(args, tuple):\n",
    "            args = (args,)\n",
    "        if args not in self:\n",
    "            super().__setitem__(args, self.function(*args))\n",
    "        return super().__getitem__(args)\n",
    "\n",
    "    def __setitem__(self, *args, **kwargs):\n",
    "        raise TypeError(\"Cannot set value to Cache object\")\n",
    "\n",
    "\n",
    "def memoized(function):\n",
    "    '''Use as decorator\n",
    "    DOES NOT SUPPORT kwargs for function! Will ignore all kwargs.\n",
    "    '''\n",
    "    cache = Cache(function)\n",
    "    @wraps(function)\n",
    "    def memoized(*args):\n",
    "        return cache[args]\n",
    "    memoized.cache = cache\n",
    "    return memoized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `object.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def _mydict_init_items_(*args, **kwargs):\n",
    "    items = ()\n",
    "    if len(args) == 3:\n",
    "        space = args[2]\n",
    "        for k in list(space.keys()):\n",
    "            if str.startswith(k, '__') and str.endswith(k, '__'):\n",
    "                del space[k]\n",
    "        items = space.items()\n",
    "    elif args and isinstance(args[0], collections.Mapping):\n",
    "        items = args[0].items()\n",
    "    elif args and isinstance(args[0], collections.Iterable):\n",
    "        items = args[0]\n",
    "    if kwargs:\n",
    "        items = chain(items, kwargs.items())\n",
    "    return items\n",
    "\n",
    "def _mydict_pretty_factory_(start='{', end='}', relater=': ', delimiter=',',\n",
    "                            key_action=lambda p, k: p.pretty(k), base=None):\n",
    "    def _repr_pretty_(obj, p, cycle):\n",
    "        nonlocal start, end, relater, delimiter, key_action, base\n",
    "        typ = type(obj)\n",
    "\n",
    "        beginning = typ.__name__ + '(' + start\n",
    "        ending = end + \")\"\n",
    "\n",
    "        if typ is not base and typ.__repr__ != base.__repr__:\n",
    "            # If the subclass provides its own repr, use it instead.\n",
    "            return p.text(typ.__repr__(obj))\n",
    "\n",
    "        if cycle:\n",
    "            return p.text(beginning + '...' + ending)\n",
    "        p.begin_group(1, beginning)\n",
    "        keys = typ.keys(obj)\n",
    "        # if dict isn't large enough to be truncated,\n",
    "        #   sort keys before displaying\n",
    "        if not (p.max_seq_length and len(obj) >= p.max_seq_length):\n",
    "            try:\n",
    "                keys = sorted(keys)\n",
    "            except Exception:\n",
    "                # Sometimes the keys don't sort.\n",
    "                pass\n",
    "        for idx, key in p._enumerate(keys):\n",
    "            if idx:\n",
    "                p.text(delimiter)\n",
    "                p.breakable()\n",
    "            key_action(p, key)\n",
    "            p.text(relater)\n",
    "            p.pretty(obj[key])\n",
    "        p.end_group(1, ending)\n",
    "    return _repr_pretty_\n",
    "\n",
    "def add_mydict_pprinter(*args, **kwargs):\n",
    "    def decorator(cls):\n",
    "        kwds = dict(kwargs)\n",
    "        kwds['base'] = cls\n",
    "        cls._repr_pretty_ = _mydict_pretty_factory_(*args, **kwds)\n",
    "        return cls\n",
    "    return decorator\n",
    "\n",
    "\n",
    "class DefaultSlots(type):\n",
    "    def __new__(meta, name, bases, attrs):\n",
    "        if '__slots__' not in attrs:\n",
    "            attrs['__slots__'] = ()\n",
    "        return super().__new__(meta, name, bases, attrs)\n",
    "\n",
    "@add_mydict_pprinter()\n",
    "class DictObject(dict, metaclass=DefaultSlots):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        data = ((k if not isinstance(k, str) else k, v)\n",
    "                for k, v in _mydict_init_items_(*args, **kwargs))\n",
    "        super().__init__(data)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"{}({})\".format(type(self).__name__, super().__repr__())\n",
    "\n",
    "    \n",
    "    def __getattribute__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            errstr = \"'{}' object has no attribute '{}'\"\n",
    "            raise AttributeError(errstr.format(type(self).__name__, name))\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "\n",
    "    def __delattr__(self, name):\n",
    "        try:\n",
    "            del self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "@add_mydict_pprinter('', '', '=', ',', lambda p, k: p.text(k))\n",
    "class Namespace(DictObject):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        items = _mydict_init_items_(*args, **kwargs)\n",
    "        data = ((k, v) for k, v in items if isinstance(k, str))\n",
    "        super(__class__, type(self)).__init__(self, data)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if not isinstance(name, str):\n",
    "            errstr = \"{} is not a valid attribute name identifier\"\n",
    "            raise ValueError(errstr.format(name))\n",
    "        self[name] = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        attach = __class__.__repr__\n",
    "        is_orig = False\n",
    "        if not hasattr(attach, '_seen'):\n",
    "            is_orig = True\n",
    "            attach._seen = {}\n",
    "        elif id(self) in attach._seen:\n",
    "            return type(self).__name__ + \"(...)\"\n",
    "        attach._seen[id(self)] = self\n",
    "        try:\n",
    "            it = type(self).items(self)\n",
    "            body = ', '.join(\"{}={}\".format(a, repr(v)) for a, v in it)\n",
    "            return \"{}({})\".format(type(self).__name__, body)\n",
    "        finally:\n",
    "            del attach._seen[id(self)]\n",
    "            if is_orig:\n",
    "                del attach._seen\n",
    "\n",
    "    def mycopy(self, copied={}):\n",
    "        is_orig = not copied\n",
    "        selfc = copied[id(self)] = type(self)()\n",
    "        for key, obj in type(self).items(self):\n",
    "            if isinstance(obj, __class__):\n",
    "                if id(obj) in copied:\n",
    "                    selfc[key] = copied[id(obj)]\n",
    "                else:\n",
    "                    selfc[key] = type(obj).mycopy(obj, copied=copied)\n",
    "            else:\n",
    "                selfc[key] = obj\n",
    "        if is_orig:\n",
    "            copied.clear()\n",
    "        return selfc\n",
    "    \n",
    "    py = lambda o: {str(k): v for k, v in dict.items(o)}\n",
    "\n",
    "def copy(obj):\n",
    "    assert(isinstance(obj, Namespace))\n",
    "    return type(obj).mycopy(obj)\n",
    "\n",
    "########################################################################\n",
    "O = Namespace\n",
    "Namespace.__name__ = '<>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `combos.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from common import *\n",
    "import itertools\n",
    "import functools\n",
    "import math\n",
    "import operator\n",
    "\n",
    "\n",
    "def binom(n, k):\n",
    "    k = min(k, n - k)\n",
    "    return functools.reduce(lambda a, b: a * (n - b) // (b + 1), range(k), 1)\n",
    "\n",
    "\n",
    "@memoized\n",
    "def consecutive_1s(n):\n",
    "    s = n * (n + 1) // 2\n",
    "    c = np.zeros([s, n], dtype=np.int8)\n",
    "    t = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n + 1):\n",
    "            for k in range(i, j):\n",
    "                c[t, k] = 1\n",
    "            t += 1\n",
    "    return c\n",
    "\n",
    "\n",
    "@memoized\n",
    "def one_minus_one(n):\n",
    "    s = n * (n - 1) // 2\n",
    "    c = np.zeros([s, n], dtype=np.int8)\n",
    "    t = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            c[t, i] = 1\n",
    "            c[t, j] = -1\n",
    "            t += 1\n",
    "    return c\n",
    "\n",
    "\n",
    "@memoized\n",
    "def one_minus_one_skip_by_k(n, k):\n",
    "    m = math.ceil(n / k)\n",
    "    s = m * (m - 1) // 2\n",
    "    c = np.zeros([s, n], dtype=np.int8)\n",
    "    t = 0\n",
    "    for i in range(0,n,k):\n",
    "        for j in range(i + k, n, k):\n",
    "            c[t, i] = 1\n",
    "            c[t, j] = -1\n",
    "            t += 1\n",
    "    return c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@memoized\n",
    "def int_coefficients_mod_sign(n, m, duplicates=True):\n",
    "    guys = []\n",
    "    path = [0]\n",
    "    while True:\n",
    "        while True:\n",
    "            if not path:\n",
    "                return np.stack(guys, axis=0) if guys else np.ndarray([0, n], dtype=np.int8)\n",
    "            path[-1] += 1\n",
    "            if path[-1] == 0:\n",
    "                path[-1] += 1\n",
    "            if path[-1] > m:\n",
    "                path.pop()\n",
    "                continue\n",
    "            if len(path) == n:\n",
    "                break\n",
    "            path.append(-m - 1)\n",
    "        if duplicates or functools.reduce(math.gcd, path) == 1:\n",
    "            guys.append(np.asarray(path, dtype=np.int8))\n",
    "\n",
    "\n",
    "@memoized\n",
    "def up_to_m_int_coefficients_mod_sign(n, m, h, duplicates=True):\n",
    "    guys = []\n",
    "    ident = np.eye(n, dtype=np.int8)\n",
    "    for k in range(1, m + 1):\n",
    "        for x_list in itertools.combinations(ident, k):\n",
    "            for sc in int_coefficients_mod_sign(k, h, duplicates):\n",
    "                guy = sum(x * b for b, x in zip(sc, x_list))\n",
    "                guys.append(guy)\n",
    "    return np.stack(guys, axis=0).astype(np.int8, copy=False)\n",
    "\n",
    "\n",
    "@memoized\n",
    "def consecutive_k_1s(m,k):\n",
    "    assert m%k==0, 'consecutive_k_1s argument m must be divisible by argument k'\n",
    "    n = m // k\n",
    "    s = n * (n + 1) // 2\n",
    "    c = np.zeros([s, k*n], dtype=np.int8)\n",
    "    t = 0\n",
    "    for i in range(0,k*n,k):\n",
    "        for j in range(i + k, k*n + 1, k):\n",
    "            for l in range(i, j):\n",
    "                c[t, l] = 1\n",
    "            t += 1\n",
    "    return c\n",
    "\n",
    "\n",
    "class name(metaclass=O):\n",
    "    def index(c):\n",
    "        assert len(c) < 16\n",
    "        pos, neg = [], []\n",
    "        for i, a in enumerate(c):\n",
    "            assert isinstance(a, np.integer) or isinstance(a, int)\n",
    "            if a != 0:\n",
    "                arr = pos if a > 0 else neg\n",
    "                arr += [i] * abs(a)\n",
    "        strpos = ''.join(hex(i)[2:] for i in pos)\n",
    "        strneg = ''.join(hex(i)[2:] for i in neg)\n",
    "        if not neg:\n",
    "            return strpos\n",
    "        else:\n",
    "            return strpos+'/'+strneg\n",
    "    def consec(c):\n",
    "        assert c.any() and (c!=np.shift(c,-1))[:-1].sum()<=2 # c switches from 0 to something then to 0, or switch less\n",
    "        nonzero = c.nonzero()[0]\n",
    "        i, j = nonzero[0], nonzero[-1]\n",
    "        return '({}..{})^{}'.format(i,j,c[i])\n",
    "\n",
    "\n",
    "def union(*cbs):\n",
    "    assert all(cb.shape[1] == cbs[0].shape[1] for cb in cbs)\n",
    "    seen, the = set(), []\n",
    "    for cb in cbs:\n",
    "        for c in cb:\n",
    "            if tuple(c) not in seen:\n",
    "                the.append(c)\n",
    "                seen.update([tuple(c), tuple(-c)])\n",
    "    return np.stack(the)\n",
    "    \n",
    "    \n",
    "class combos(metaclass=O):\n",
    "    name = name\n",
    "    union = union\n",
    "    c1co = consecutive_1s #(n)\n",
    "    ckco = consecutive_k_1s #(n)\n",
    "    \n",
    "    mintco = lambda n, m, h: up_to_m_int_coefficients_mod_sign(n, m, h, False) #(n, m=<max num nonzer coefficients>, <max abs value of coefficients>)\n",
    "    mintcox = lambda n, m, h: up_to_m_int_coefficients_mod_sign(n, m, h, True) #(n, m=<max num nonzer coefficients>, <max abs value of coefficients>)\n",
    "    omo = one_minus_one\n",
    "    omok = one_minus_one_skip_by_k\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `helper.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift(a, shift, axis=None):\n",
    "    '''Params - a: np.ndarray\n",
    "                shift: integer, + means entries moved to greater indices, - means entries moved to smaller indices\n",
    "                axis: one integer\n",
    "    Equivalent to pd.DataFrame.shift\n",
    "    '''\n",
    "    if axis is None:\n",
    "        assert len(a.shape)==1, \"Only an array of single dimension can be shifted without specifying axis\"\n",
    "        axis = 0\n",
    "    assert isinstance(axis, int)\n",
    "    if not shift:\n",
    "        return a\n",
    "    padding = (shift,0) if shift>0 else (0,-shift)\n",
    "    slicing = slice(None,-shift) if shift>0 else slice(-shift,None)\n",
    "    n = len(a.shape)\n",
    "    axis = n+axis if axis<0 else axis\n",
    "    ret = np.pad(a, ((0,0),)*axis+(padding,)+((0,0),)*(n-axis-1), mode='constant', constant_values=(np.nan,)*n)\n",
    "    ret = ret[(slice(None),)*axis + (slicing,) + (slice(None),)*(n-axis-1)]\n",
    "    return ret\n",
    "np.shift = shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_progress(i, dot=1, numdot=10):\n",
    "    print('.' if i // dot % numdot else i, end='', flush=True) if i % dot == 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### misc administrative definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = [None]*500 # \"LightGBM models (Booster)\" # will be populated after an initial F has been constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_lgb_models(*,F):\n",
    "    global ls, ld, lm\n",
    "    for i, (s, d) in enumerate(zip(ls, ld)):\n",
    "        if s is None:\n",
    "            break\n",
    "        fSelection = globals()[d.f]\n",
    "        F_ = F[fSelection]\n",
    "        info = dict(\n",
    "            feature_name = list(F_.columns),\n",
    "            categorical_feature = list(F_.dtypes[F_.dtypes==np.int64].index),\n",
    "            free_raw_data = False,\n",
    "        )\n",
    "        data = lgb.Dataset(F_, **info)\n",
    "        bst = lgb.Booster(None, data) # you need some data (even if it's not used (or shouldn't be used)) to initialize :(\n",
    "        bst = bst.model_from_string(s)\n",
    "        assert fSelection==bst.feature_name()\n",
    "        lm[i] = bst\n",
    "        \n",
    "def predict_with_lgb(i):\n",
    "    def predict(*,F):\n",
    "        return lm[i].predict(F[globals()[ld[i].f]])\n",
    "    return predict\n",
    "\n",
    "def predict(*,F):\n",
    "    return predict_with_lgb(2)*.6 + predict_with_lgb(3)*.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## %%%%%%%%%%% requirements check for main prediction code: %%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok go\n"
     ]
    }
   ],
   "source": [
    "__env__\n",
    "O\n",
    "gc\n",
    "canvas\n",
    "print(\"ok go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================== MAIN PREDICTION CODE ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "debug = O()\n",
    "%matplotlib inline\n",
    "canvas(12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N = __env__.get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IdAssign:\n",
    "    def __init__(self, init):\n",
    "        self.map = {x: i for i,x in enumerate(init)}\n",
    "    def __call__(self, key):\n",
    "        if key not in self.map:\n",
    "            self.map[key] = len(self.map)\n",
    "        return self.map[key]\n",
    "    def __len__(self):\n",
    "        return self.map.__len__()\n",
    "\n",
    "assetCodeSeries = pd.Series(M.assetCode.unique())\n",
    "assetCodeIdMap = IdAssign(assetCodeSeries)\n",
    "\n",
    "assetNameSeries = pd.Series(M.assetName.unique())\n",
    "assetNameIdMap = IdAssign(assetNameSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "returns_columns = {\n",
    "    'returnsClosePrevRaw1':'cc', 'returnsOpenPrevRaw1':'oo',\n",
    "    'returnsClosePrevMktres1':'cc0', 'returnsOpenPrevMktres1':'oo0',\n",
    "    'returnsClosePrevRaw10':'cc_10','returnsOpenPrevRaw10':'oo_10',\n",
    "    'returnsClosePrevMktres10':'cc0_10','returnsOpenPrevMktres10':'oo0_10'\n",
    "}\n",
    "columns_for_U = set(returns_columns.values()) | set(['open', 'close', 'volume'])\n",
    "possibly_excluded_columns = [\n",
    "    'time','assetCode','assetName','universe','returnsOpenNextMktres10','quarter'\n",
    "]\n",
    "column_filter = lambda c: c not in possibly_excluded_columns\n",
    "enumeration_columns = ['assetCodeId', 'assetNameId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_start_time = pd.Timestamp('2009-01-01',tz='UTC')\n",
    "shortterm = 21\n",
    "longterm = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_basic_features(*,M):\n",
    "    M['assetCodeId'] = M.assetCode.map(assetCodeIdMap).astype(int)\n",
    "    M['assetNameId'] = M.assetName.map(assetNameIdMap).astype(int)\n",
    "    for orig_col, new_col in returns_columns.items():\n",
    "        M[new_col] = np.log(M[orig_col]+1)\n",
    "        del M[orig_col]\n",
    "    # time features\n",
    "    M['dayOfYear'] = M.time.dt.dayofyear\n",
    "    M['dayOfWeek'] = M.time.dt.dayofweek\n",
    "\n",
    "    \n",
    "def add_shortterm_price_features(*,U,u):\n",
    "    ################################################################ no NaNs here:\n",
    "    U['(oo-oo0)_'] = U.oo_ - U.oo0_\n",
    "    for ww in ['oo','oo0','(oo-oo0)']:\n",
    "        window = np.flip(U[ww+'_'],axis=0)[:20]\n",
    "        for c in combos.ckco(20,5):\n",
    "            name = '{}{{{}}}'.format(ww+'_', combos.name.consec(c))\n",
    "            u[name] = c@window\n",
    "    ################################################################# can be NaNs:\n",
    "    U['(oo-oo0)*'] = U.oo - U.oo0\n",
    "    U['(cc-cc0)*'] = U.cc - U.cc0\n",
    "    for ww in ['(oo-oo0)','(cc-cc0)']:\n",
    "        window = np.flip(U[ww+'*'],axis=0)[:3]\n",
    "        for c in combos.union(combos.omo(3),combos.mintco(3,1,1)):\n",
    "            name = '{}{{{}}}'.format(ww, combos.name.index(c))\n",
    "            if name[-3]=='{0}':\n",
    "                name = name[:-3]\n",
    "            u[name] = c@window\n",
    "    ################################################################# can be NaNs:\n",
    "    log_open, log_close = np.log(U.open), np.log(U.close) # can be NaNs here\n",
    "    U['af'] = log_open - np.shift(log_close,1,axis=0)\n",
    "    U['it'] = log_close - log_open\n",
    "    u['af{1}'] = U.af[-2]\n",
    "    u['it{1}'] = U.it[-2]\n",
    "    \n",
    "    near0 = np.stack([U.it[-1],U.af[-1],U.it[-2],U.oo0[-1],U.cc0[-1]], axis=0) # can be NaNs\n",
    "    near1 = np.stack([U.it[-2],U.af[-2],U.it[-3],U.oo0[-2],U.cc0[-2]], axis=0) # can be NaNs\n",
    "    for c in combos.omo(5):\n",
    "        name = '(it,af,it{{1}},oo0,cc0){{{}}}'.format(combos.name.index(c))\n",
    "        u[name] = c@near0\n",
    "        name = '(it{{1}},af{{1}},it{{2}},oo0{{1}},cc0{{1}}){{{}}}'.format(combos.name.index(c))\n",
    "        u[name] = c@near1\n",
    "    ################################################################### NaNsがあるけど……:\n",
    "    log_volume = np.log(U.volume)\n",
    "    u['volumeRatioMeanBack2'] = log_volume[-1] - np.log(U.volume[-3:-1].mean(axis=0))\n",
    "    u['volumeRatioMeanBack2{1}'] = log_volume[-2] - np.log(U.volume[-4:-2].mean(axis=0))\n",
    "    u['volumeRatioMean5'] = log_volume[-1] - np.log(U.volume[-5:].mean(axis=0))\n",
    "    u['volumeRatioMean10'] = log_volume[-1] - np.log(U.volume[-10:].mean(axis=0))\n",
    "    u['volumeRatioMean10{5}'] = log_volume[-6] - np.log(U.volume[-15:-5].mean(axis=0))\n",
    "    u['volumeRatioMean5ByMean20'] = np.log(U.volume[-5:].mean(axis=0)) - np.log(U.volume[-20:].mean(axis=0))\n",
    "            \n",
    "    \n",
    "def add_longterm_price_features(*,U,u,horizons=[21,62,125,250]):\n",
    "    ################################################################# no NaNs\n",
    "    u['oo0_20'] = U.oo0_10_[-11::10].sum(axis=0)\n",
    "    u['oo0_60'] = U.oo0_10_[-61::10].sum(axis=0)\n",
    "    u['oo0_120'] = U.oo0_10_[-121::10].sum(axis=0)\n",
    "    u['oo0_250'] = U.oo0_10_[-251::10].sum(axis=0)\n",
    "    \n",
    "    u['oo_20'] = U.oo_10_[-11::10].sum(axis=0)\n",
    "    u['oo_60'] = U.oo_10_[-61::10].sum(axis=0)\n",
    "    u['oo_120'] = U.oo_10_[-121::10].sum(axis=0)\n",
    "    u['oo_250'] = U.oo_10_[-251::10].sum(axis=0)\n",
    "    \n",
    "    u['(oo-oo0)_10'] = U.oo_10[-1] - U.oo0_10[-1]\n",
    "    u['(oo-oo0)_20'] = U.oo_10_[-11::10].sum(axis=0) - U.oo0_10_[-11::10].sum(axis=0)\n",
    "    u['(oo-oo0)_60'] = U.oo_10_[-61::10].sum(axis=0) - U.oo0_10_[-61::10].sum(axis=0)\n",
    "    u['(oo-oo0)_120'] = U.oo_10_[-121::10].sum(axis=0) - U.oo0_10_[-121::10].sum(axis=0)\n",
    "    u['(oo-oo0)_250'] = U.oo_10_[-251::10].sum(axis=0) - U.oo0_10_[-251::10].sum(axis=0)\n",
    "    #################################################################### no NaNs\n",
    "    for ww in ['oo','oo0']:\n",
    "        for h in horizons:\n",
    "            strh = str(h)\n",
    "            since = U[ww+'Since'+strh] = U[ww+'_'][-h:].cumsum(axis=0)\n",
    "                   \n",
    "            maxSince = U[ww+'MaxSince'+strh] = np.maximum.accumulate(since, axis=0)\n",
    "            drawdownSince = U[ww+'DrawdownSince'+strh] = maxSince - since\n",
    "            u[ww+'MaxDrawdown5Since'+strh] = drawdownSince[-5:].max(axis=0)\n",
    "            u[ww+'MaxDrawdown10Since'+strh] = drawdownSince[-10:].max(axis=0)\n",
    "            #u[ww+'MaxDrawdown20Since'+strh] = drawdownSince[-20:].max(axis=0)\n",
    "            u[ww+'MaxDrawdown(10-5)Since'+strh] = drawdownSince[-10:-5].max(axis=0)\n",
    "            u[ww+'MaxDrawdown(20-10)Since'+strh] = drawdownSince[-20:-10].max(axis=0)\n",
    "            u[ww+'Prev5MaxSince'+strh] = maxSince[-6]\n",
    "            u[ww+'Prev10MaxSince'+strh] = maxSince[-11]\n",
    "            #u[ww+'Prev20MaxSince'+strh] = maxSince[-21]\n",
    "            \n",
    "            minSince = U[ww+'MinSince'+strh] = np.minimum.accumulate(since, axis=0)\n",
    "            drawupSince = U[ww+'DrawupSince'+strh] = since - minSince\n",
    "            maxDrawup5Since = U[ww+'MaxDrawup5Since'+strh] = drawupSince[-5:].max(axis=0)[np.newaxis,:]\n",
    "            maxDrawup10Since = U[ww+'MaxDrawup10Since'+strh] = drawupSince[-10:].max(axis=0)[np.newaxis,:]\n",
    "            #maxDrawup20Since = U[ww+'MaxDrawup20Since'+strh] = drawupSince[-20:].max(axis=0)[np.newaxis,:]\n",
    "            maxDrawup10_5Since = U[ww+'MaxDrawup(10-5)Since'+strh] = drawupSince[-10:-5].max(axis=0)[np.newaxis,:]\n",
    "            maxDrawup20_10Since = U[ww+'MaxDrawup(20-10)Since'+strh] = drawupSince[-20:-10].max(axis=0)[np.newaxis,:]\n",
    "            u[ww+'Prev5MinSince'+strh] = minSince[-6]\n",
    "            u[ww+'Prev10MinSince'+strh] = minSince[-11]\n",
    "            #u[ww+'Prev20MinSince'+strh] = minSince[-21]\n",
    "            \n",
    "\n",
    "def add_postprocessing_features(*,F):\n",
    "    #F['assetCodeIdWTFlogabs'] = F.assetCodeId.map(str).map(hash).pipe(np.abs).pipe(np.log)\n",
    "    #F['assetCodeIdWTFsin2'] = F.assetCodeId.map(str).map(hash).pipe(np.sin).pipe(lambda x: x * x)\n",
    "    F['assetCodeIdWTFFlogabs'] = F.assetCodeId.map(str).map(hash).map(str).map(hash).pipe(np.abs).pipe(np.log)\n",
    "    F['assetCodeIdWTFFsin2'] = F.assetCodeId.map(str).map(hash).map(str).map(hash).pipe(np.sin).pipe(lambda x: x * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_single_A_U_u(*,M):\n",
    "    '''M needs to assetCodeId indexed'''\n",
    "    A = pd.DataFrame(index=pd.Series(range(len(assetCodeIdMap)),name='assetCodeId')).join(M)\n",
    "    #^ A = join onto standard assetCode row-index\n",
    "    V = O(**{c:A[c] for c in columns_for_U})\n",
    "    U = O(**{c:A[c].values[np.newaxis,:] for c in columns_for_U},\n",
    "          **{c+'_':np.nan_to_num(A[c].values[np.newaxis,:]) for c in columns_for_U})\n",
    "    return A, U, O()\n",
    "\n",
    "def make_U(*,M):\n",
    "    Us = [make_single_A_U_u(M=m)[1] for _,m in M.groupby('time')]\n",
    "    U = O(**{c:np.concatenate([U[c] for U in Us],axis=0) for c in Us[0]})\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minit = M[M.time<=M.time.unique()[longterm]]\n",
    "set_basic_features(M=Minit)\n",
    "Uinit = make_U(M=Minit)\n",
    "uinit = O()\n",
    "debug.U0_keys = set(dict.keys(Uinit))\n",
    "add_shortterm_price_features(U=Uinit,u=uinit)\n",
    "add_longterm_price_features(U=Uinit,u=uinit)\n",
    "\n",
    "Mcolumns = Minit.columns\n",
    "Ucolumns = [c for c in Uinit if c not in Mcolumns and c[-1] not in '*_']\n",
    "ucolumns = [c for c in uinit if c not in Mcolumns and c[-1] not in '*_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_features_templates(MNP_iter, *, U_):\n",
    "    U_, term = U_\n",
    "    for M, N, P in MNP_iter:\n",
    "        orig_index = M.index\n",
    "        set_basic_features(M=M) # adds \"long\" features and deletes non-log price features\n",
    "        M.set_index('assetCodeId', inplace=True)\n",
    "        A, U, u = make_single_A_U_u(M=M)\n",
    "        assert debug.U0_keys==set(dict.keys(U))\n",
    "        # expand rows in old U_ if new assetCodeIds were seen\n",
    "        akey = next(iter(U))\n",
    "        diff = U[akey].shape[1] - U_[akey].shape[1]\n",
    "        if diff > 0:\n",
    "            for key in U_:\n",
    "                if key[-1] != '_': # normal features\n",
    "                    U_[key] = np.pad(U_[key], pad_width=((0,0),(0,diff)), mode='constant', constant_values=np.nan)\n",
    "                else: # NaN-filled-with-0 features\n",
    "                    U_[key] = np.pad(U_[key], pad_width=((0,0),(0,diff)), mode='constant', constant_values=0)\n",
    "        # join new row vectors in U to the old tables in U_\n",
    "        for key in U:\n",
    "            U_[key] = np.concatenate([U_[key],U[key]], axis=0)\n",
    "            if len(U_[key])>term:\n",
    "                U_[key] = U_[key][-term:]\n",
    "        # add features to U_ and U__\n",
    "        gc.collect()\n",
    "        add_shortterm_price_features(U=U_,u=u)\n",
    "        gc.collect()\n",
    "        add_longterm_price_features(U=U_,u=u)\n",
    "        gc.collect()\n",
    "        assert len(set(U_)&set(u))==0\n",
    "        # take out the bottom row of the feature tables to feed out as our feature construction iterator\n",
    "        _dict = {c: U_[c][-1] for c in Ucolumns}\n",
    "        _dict.update({c: u[c] for c in ucolumns})\n",
    "        # piece everything together\n",
    "        columns = Ucolumns + ucolumns\n",
    "        F = pd.DataFrame([_dict[c] for c in columns], index=columns, columns=A.index).T\n",
    "        F = M.join(F)\n",
    "        assert 'assetCodeId' not in F.columns\n",
    "        F.reset_index(inplace=True)\n",
    "        F.index = orig_index\n",
    "        for c in enumeration_columns:\n",
    "            assert np.issubdtype(F[c].dtype, np.integer)\n",
    "        add_postprocessing_features(F=F)\n",
    "        yield F, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_MNP_train(*,M,N):\n",
    "    M_, N_ = M, N\n",
    "    for time, M in M_.groupby('time'):\n",
    "        if time<train_start_time:\n",
    "            continue\n",
    "        M['quarter'] = M.time.dt.year+(M.time.dt.quarter-1)/4\n",
    "        P = M[possibly_excluded_columns]\n",
    "        M = M.drop(columns=['returnsOpenNextMktres10','quarter'])\n",
    "        yield M, None, P\n",
    "        \n",
    "Mstart = M[M.time<train_start_time]\n",
    "set_basic_features(M=Mstart)\n",
    "U_ = make_U(M=Mstart)\n",
    "u_ = O()\n",
    "add_shortterm_price_features(U=U_,u=u_)\n",
    "add_longterm_price_features(U=U_,u=u_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.........100.........200"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def make_train():\n",
    "    feat_iter = iter_features_templates(iter_MNP_train(M=M,N=None), U_=(U_,longterm))\n",
    "    train = [[print_progress(i,10),(F,P)][-1] for i,(F,P) in enumerate(feat_iter)]\n",
    "    F = pd.concat([FP[0] for FP in train], axis=0)\n",
    "    P = pd.concat([FP[1] for FP in train], axis=0)\n",
    "    F.index = P.index\n",
    "    return F,P\n",
    "F,P = make_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ~ ~ ~ ~ ~ saving/loading for local testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle((F,P), big_data+'saves/train_1shouldsame.pkl')\n",
    "#FF,PP = pd.read_pickle(big_data+'saves/train_1logfirst.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F,P = FF,PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training some particular model! /////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "ho = P.quarter>=2015.5\n",
    "ho.name = None\n",
    "tr, cv = next(GroupShuffleSplit(n_splits=1, test_size=.5, random_state=44).split(F[~ho], P[~ho], groups=P[~ho].quarter))\n",
    "_dummy = pd.Series(range(len(P)),index=P.index)\n",
    "tr, cv = _dummy.isin(tr), _dummy.isin(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P['target'] = P.returnsOpenNextMktres10>0\n",
    "P['upDown'] = (P.target*2-1)\n",
    "P['upDown1'] = P.upDown*P.universe.astype(int)\n",
    "P['absVal'] = np.abs(P.returnsOpenNextMktres10)\n",
    "P['absVal1'] = P.absVal*P.universe\n",
    "P['weight'] = P.absVal#.qtl()\n",
    "P['weight1'] = P.weight*P.universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature sets definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fThefault\n"
     ]
    }
   ],
   "source": [
    "fThefault = [\"volume\",\"close\",\"open\",\"assetCodeId\",\"assetNameId\",\"cc\",\"oo\",\"cc0\",\"oo0\",\"cc_10\",\"oo_10\",\"cc0_10\",\"oo0_10\",\"dayOfYear\",\"dayOfWeek\",\"af\",\"it\",\"ooSince21\",\"ooMaxSince21\",\"ooDrawdownSince21\",\"ooMinSince21\",\"ooDrawupSince21\",\"ooMaxDrawup5Since21\",\"ooMaxDrawup10Since21\",\"ooMaxDrawup(10-5)Since21\",\"ooMaxDrawup(20-10)Since21\",\"ooSince62\",\"ooMaxSince62\",\"ooDrawdownSince62\",\"ooMinSince62\",\"ooDrawupSince62\",\"ooMaxDrawup5Since62\",\"ooMaxDrawup10Since62\",\"ooMaxDrawup(10-5)Since62\",\"ooMaxDrawup(20-10)Since62\",\"ooSince125\",\"ooMaxSince125\",\"ooDrawdownSince125\",\"ooMinSince125\",\"ooDrawupSince125\",\"ooMaxDrawup5Since125\",\"ooMaxDrawup10Since125\",\"ooMaxDrawup(10-5)Since125\",\"ooMaxDrawup(20-10)Since125\",\"ooSince250\",\"ooMaxSince250\",\"ooDrawdownSince250\",\"ooMinSince250\",\"ooDrawupSince250\",\"ooMaxDrawup5Since250\",\"ooMaxDrawup10Since250\",\"ooMaxDrawup(10-5)Since250\",\"ooMaxDrawup(20-10)Since250\",\"oo0Since21\",\"oo0MaxSince21\",\"oo0DrawdownSince21\",\"oo0MinSince21\",\"oo0DrawupSince21\",\"oo0MaxDrawup5Since21\",\"oo0MaxDrawup10Since21\",\"oo0MaxDrawup(10-5)Since21\",\"oo0MaxDrawup(20-10)Since21\",\"oo0Since62\",\"oo0MaxSince62\",\"oo0DrawdownSince62\",\"oo0MinSince62\",\"oo0DrawupSince62\",\"oo0MaxDrawup5Since62\",\"oo0MaxDrawup10Since62\",\"oo0MaxDrawup(10-5)Since62\",\"oo0MaxDrawup(20-10)Since62\",\"oo0Since125\",\"oo0MaxSince125\",\"oo0DrawdownSince125\",\"oo0MinSince125\",\"oo0DrawupSince125\",\"oo0MaxDrawup5Since125\",\"oo0MaxDrawup10Since125\",\"oo0MaxDrawup(10-5)Since125\",\"oo0MaxDrawup(20-10)Since125\",\"oo0Since250\",\"oo0MaxSince250\",\"oo0DrawdownSince250\",\"oo0MinSince250\",\"oo0DrawupSince250\",\"oo0MaxDrawup5Since250\",\"oo0MaxDrawup10Since250\",\"oo0MaxDrawup(10-5)Since250\",\"oo0MaxDrawup(20-10)Since250\",\"oo_{(0..4)^1}\",\"oo_{(0..9)^1}\",\"oo_{(0..14)^1}\",\"oo_{(0..19)^1}\",\"oo_{(5..9)^1}\",\"oo_{(5..14)^1}\",\"oo_{(5..19)^1}\",\"oo_{(10..14)^1}\",\"oo_{(10..19)^1}\",\"oo_{(15..19)^1}\",\"oo0_{(0..4)^1}\",\"oo0_{(0..9)^1}\",\"oo0_{(0..14)^1}\",\"oo0_{(0..19)^1}\",\"oo0_{(5..9)^1}\",\"oo0_{(5..14)^1}\",\"oo0_{(5..19)^1}\",\"oo0_{(10..14)^1}\",\"oo0_{(10..19)^1}\",\"oo0_{(15..19)^1}\",\"(oo-oo0)_{(0..4)^1}\",\"(oo-oo0)_{(0..9)^1}\",\"(oo-oo0)_{(0..14)^1}\",\"(oo-oo0)_{(0..19)^1}\",\"(oo-oo0)_{(5..9)^1}\",\"(oo-oo0)_{(5..14)^1}\",\"(oo-oo0)_{(5..19)^1}\",\"(oo-oo0)_{(10..14)^1}\",\"(oo-oo0)_{(10..19)^1}\",\"(oo-oo0)_{(15..19)^1}\",\"(oo-oo0){0/1}\",\"(oo-oo0){0/2}\",\"(oo-oo0){1/2}\",\"(oo-oo0){0}\",\"(oo-oo0){1}\",\"(oo-oo0){2}\",\"(cc-cc0){0/1}\",\"(cc-cc0){0/2}\",\"(cc-cc0){1/2}\",\"(cc-cc0){0}\",\"(cc-cc0){1}\",\"(cc-cc0){2}\",\"af{1}\",\"it{1}\",\"(it,af,it{1},oo0,cc0){0/1}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){0/1}\",\"(it,af,it{1},oo0,cc0){0/2}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){0/2}\",\"(it,af,it{1},oo0,cc0){0/3}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){0/3}\",\"(it,af,it{1},oo0,cc0){0/4}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){0/4}\",\"(it,af,it{1},oo0,cc0){1/2}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){1/2}\",\"(it,af,it{1},oo0,cc0){1/3}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){1/3}\",\"(it,af,it{1},oo0,cc0){1/4}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){1/4}\",\"(it,af,it{1},oo0,cc0){2/3}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){2/3}\",\"(it,af,it{1},oo0,cc0){2/4}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){2/4}\",\"(it,af,it{1},oo0,cc0){3/4}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){3/4}\",\"volumeRatioMeanBack2\",\"volumeRatioMeanBack2{1}\",\"volumeRatioMean5\",\"volumeRatioMean10\",\"volumeRatioMean10{5}\",\"volumeRatioMean5ByMean20\",\"oo0_20\",\"oo0_60\",\"oo0_120\",\"oo0_250\",\"ooMaxDrawdown5Since21\",\"ooMaxDrawdown10Since21\",\"ooMaxDrawdown(10-5)Since21\",\"ooMaxDrawdown(20-10)Since21\",\"ooPrev5MaxSince21\",\"ooPrev10MaxSince21\",\"ooPrev5MinSince21\",\"ooPrev10MinSince21\",\"ooMaxDrawdown5Since62\",\"ooMaxDrawdown10Since62\",\"ooMaxDrawdown(10-5)Since62\",\"ooMaxDrawdown(20-10)Since62\",\"ooPrev5MaxSince62\",\"ooPrev10MaxSince62\",\"ooPrev5MinSince62\",\"ooPrev10MinSince62\",\"ooMaxDrawdown5Since125\",\"ooMaxDrawdown10Since125\",\"ooMaxDrawdown(10-5)Since125\",\"ooMaxDrawdown(20-10)Since125\",\"ooPrev5MaxSince125\",\"ooPrev10MaxSince125\",\"ooPrev5MinSince125\",\"ooPrev10MinSince125\",\"ooMaxDrawdown5Since250\",\"ooMaxDrawdown10Since250\",\"ooMaxDrawdown(10-5)Since250\",\"ooMaxDrawdown(20-10)Since250\",\"ooPrev5MaxSince250\",\"ooPrev10MaxSince250\",\"ooPrev5MinSince250\",\"ooPrev10MinSince250\",\"oo0MaxDrawdown5Since21\",\"oo0MaxDrawdown10Since21\",\"oo0MaxDrawdown(10-5)Since21\",\"oo0MaxDrawdown(20-10)Since21\",\"oo0Prev5MaxSince21\",\"oo0Prev10MaxSince21\",\"oo0Prev5MinSince21\",\"oo0Prev10MinSince21\",\"oo0MaxDrawdown5Since62\",\"oo0MaxDrawdown10Since62\",\"oo0MaxDrawdown(10-5)Since62\",\"oo0MaxDrawdown(20-10)Since62\",\"oo0Prev5MaxSince62\",\"oo0Prev10MaxSince62\",\"oo0Prev5MinSince62\",\"oo0Prev10MinSince62\",\"oo0MaxDrawdown5Since125\",\"oo0MaxDrawdown10Since125\",\"oo0MaxDrawdown(10-5)Since125\",\"oo0MaxDrawdown(20-10)Since125\",\"oo0Prev5MaxSince125\",\"oo0Prev10MaxSince125\",\"oo0Prev5MinSince125\",\"oo0Prev10MinSince125\",\"oo0MaxDrawdown5Since250\",\"oo0MaxDrawdown10Since250\",\"oo0MaxDrawdown(10-5)Since250\",\"oo0MaxDrawdown(20-10)Since250\",\"oo0Prev5MaxSince250\",\"oo0Prev10MaxSince250\",\"oo0Prev5MinSince250\",\"oo0Prev10MinSince250\"]\n",
    "print('fThefault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fNewfault\n"
     ]
    }
   ],
   "source": [
    "fNewfault = [\"volume\",\"close\",\"open\",\"assetCodeId\",\"assetNameId\",\"cc\",\"oo\",\"cc0\",\"oo0\",\"cc_10\",\"oo_10\",\"cc0_10\",\"oo0_10\",\"dayOfYear\",\"dayOfWeek\",\"ooSince21\",\"ooMaxSince21\",\"ooDrawdownSince21\",\"ooMaxDrawdown5Since21\",\"ooMaxDrawdown10Since21\",\"ooPrev10MaxSince21\",\"ooMinSince21\",\"ooPrev10MinSince21\",\"ooSince62\",\"ooMaxSince62\",\"ooDrawdownSince62\",\"ooMaxDrawdown5Since62\",\"ooMaxDrawdown10Since62\",\"ooPrev10MaxSince62\",\"ooMinSince62\",\"ooPrev10MinSince62\",\"ooSince125\",\"ooMaxSince125\",\"ooDrawdownSince125\",\"ooMaxDrawdown5Since125\",\"ooMaxDrawdown10Since125\",\"ooPrev10MaxSince125\",\"ooMinSince125\",\"ooPrev10MinSince125\",\"ooSince250\",\"ooMaxSince250\",\"ooDrawdownSince250\",\"ooMaxDrawdown5Since250\",\"ooMaxDrawdown10Since250\",\"ooPrev10MaxSince250\",\"ooMinSince250\",\"ooPrev10MinSince250\",\"oo0Since21\",\"oo0MaxSince21\",\"oo0DrawdownSince21\",\"oo0MaxDrawdown5Since21\",\"oo0MaxDrawdown10Since21\",\"oo0Prev10MaxSince21\",\"oo0MinSince21\",\"oo0Prev10MinSince21\",\"oo0Since62\",\"oo0MaxSince62\",\"oo0DrawdownSince62\",\"oo0MaxDrawdown5Since62\",\"oo0MaxDrawdown10Since62\",\"oo0Prev10MaxSince62\",\"oo0MinSince62\",\"oo0Prev10MinSince62\",\"oo0Since125\",\"oo0MaxSince125\",\"oo0DrawdownSince125\",\"oo0MaxDrawdown5Since125\",\"oo0MaxDrawdown10Since125\",\"oo0Prev10MaxSince125\",\"oo0MinSince125\",\"oo0Prev10MinSince125\",\"oo0Since250\",\"oo0MaxSince250\",\"oo0DrawdownSince250\",\"oo0MaxDrawdown5Since250\",\"oo0MaxDrawdown10Since250\",\"oo0Prev10MaxSince250\",\"oo0MinSince250\",\"oo0Prev10MinSince250\",\"oo_{(0..4)^1}\",\"oo_{(0..9)^1}\",\"oo_{(0..14)^1}\",\"oo_{(0..19)^1}\",\"oo_{(5..9)^1}\",\"oo_{(5..14)^1}\",\"oo_{(5..19)^1}\",\"oo_{(10..14)^1}\",\"oo_{(10..19)^1}\",\"oo_{(15..19)^1}\",\"oo0_{(0..4)^1}\",\"oo0_{(0..9)^1}\",\"oo0_{(0..14)^1}\",\"oo0_{(0..19)^1}\",\"oo0_{(5..9)^1}\",\"oo0_{(5..14)^1}\",\"oo0_{(5..19)^1}\",\"oo0_{(10..14)^1}\",\"oo0_{(10..19)^1}\",\"oo0_{(15..19)^1}\",\"(it,af,it{1},oo0,cc0){3/4}\"]\n",
    "print('fNewfault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fTime fAsset fPriceAbsolute\n"
     ]
    }
   ],
   "source": [
    "fTime = 'dayOfYear dayOfWeek'.split()\n",
    "fAsset = 'assetCodeId assetNameId'.split()\n",
    "fPriceAbsolute = 'close open'.split()\n",
    "print('fTime fAsset fPriceAbsolute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_relative combinations...\n"
     ]
    }
   ],
   "source": [
    "def select_relative(f):\n",
    "    return f not in set(fTime+fAsset+fPriceAbsolute)\n",
    "\n",
    "fThefaultRelative = list(filter(select_relative, fThefault))\n",
    "\n",
    "fHack0 = ['assetCodeIdWTFFlogabs', 'assetCodeIdWTFFsin2']\n",
    "fNewfaultRelativeHack0 = list(filter(select_relative, fNewfault)) + fHack0\n",
    "\n",
    "print('select_relative combinations...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### choose our feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fSelection = fNewfaultRelativeHack0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the lgb data structure and train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_ = F[fSelection+['assetCodeIdWTFFlogabs','assetCodeIdWTFFsin2']]\n",
    "\n",
    "lgb_data_info = dict(\n",
    "    feature_name = list(F_.columns),\n",
    "    categorical_feature = list(F_.dtypes[F_.dtypes==np.int64].index),\n",
    "    free_raw_data = False,\n",
    ")\n",
    "L.tr = lgb.Dataset(F_[tr], P.target[tr], weight=P.weight1[tr], **lgb_data_info)\n",
    "L.cv = lgb.Dataset(F_[cv], P.target[cv], reference=L.tr, weight=P.weight1[cv], **lgb_data_info)\n",
    "L.ho = lgb.Dataset(F_[ho], P.target[ho], weight=P.weight1[ho], **lgb_data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L.tr.timeFactor = P.time[tr].factorize()[0]\n",
    "L.cv.timeFactor = P.time[cv].factorize()[0]\n",
    "L.tr.value = (P.upDown1*P.absVal1)[tr]\n",
    "L.cv.value = (P.upDown1*P.absVal1)[cv]\n",
    "L.tr.i = 0\n",
    "L.cv.i = 0\n",
    "\n",
    "def lgb_kaggle_metric(preds, valid_data):\n",
    "    df_time = valid_data.timeFactor\n",
    "    #labels = valid_data.get_label()\n",
    "    values = valid_data.value\n",
    "    #assert len(labels) == len(df_time)\n",
    "\n",
    "    preds = preds*2-1\n",
    "    #labels = labels*2-1\n",
    "    x_t = preds * values\n",
    "    \n",
    "    # Here we take advantage of the fact that `labels` (used to calculate `x_t`)\n",
    "    # is a pd.Series and call `group_by`\n",
    "    x_t_sum = x_t.groupby(df_time).sum()\n",
    "    score = x_t_sum.mean() / x_t_sum.std()\n",
    "\n",
    "    valid_data.i += lgb_kaggle_metric.hack\n",
    "    return 'kaggle', score+valid_data.i, True\n",
    "lgb_kaggle_metric.hack = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b3bc5820f14a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mevals_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m lgb_model = lgb.train(lgb_params, L.tr, valid_sets=[L.tr,L.cv], valid_names=['tr','cv'],\n\u001b[0m\u001b[1;32m     38\u001b[0m               feval=lgb_kaggle_metric, evals_result=evals_result, verbose_eval=10)\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lgb' is not defined"
     ]
    }
   ],
   "source": [
    "lgb_params = dict(\n",
    "    #task = 'train',\n",
    "    objective = 'binary',\n",
    "    \n",
    "    num_iterations = 500,\n",
    "    early_stopping_round = 50,\n",
    "    \n",
    "    learning_rate = .05, #.02, #0.05,\n",
    "    num_leaves = 1<<12, #1<<16, #1<<12,\n",
    "    max_depth = 12, #16, #12,\n",
    "    min_data_in_leaf = 150, #120, #200(rd26)/120(rd17), #150,\n",
    "    min_sum_hessian_in_leaf = 50, #0, #50,\n",
    "    #bagging_fraction = 1,\n",
    "    #bagging_freq = 0,\n",
    "    #feature_fraction = 1,\n",
    "    lambda_l1 = .01, #.0, #0.01,\n",
    "    lambda_l2 = .01, #.0, #0.01,\n",
    "    min_gain_to_split = 0,\n",
    "    \n",
    "    #min_data_per_group = 100,\n",
    "    #max_cat_threshold = 32,\n",
    "    #cat_l2 = 10.0,\n",
    "    #cat_smooth = 10.0,\n",
    "    #max_cat_to_onehot = 4,\n",
    "    \n",
    "    #max_bin = 255,\n",
    "    \n",
    "    metric = 'None',\n",
    "    \n",
    "    seed = 44, # Change for better luck! :)\n",
    "    bagging_seed = 45,\n",
    "    feature_fraction_seed = 46,\n",
    "    #data_random_seed = 1,\n",
    ")\n",
    "\n",
    "evals_result = {}\n",
    "bst = lgb.train(lgb_params, L.tr, valid_sets=[L.tr,L.cv], valid_names=['tr','cv'],\n",
    "              feval=lgb_kaggle_metric, evals_result=evals_result, verbose_eval=10)\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame(evals_result['cv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ds, metrics in evals_result.items():\n",
    "    for m_name, m_list in metrics.items():\n",
    "        if m_name=='kaggle':\n",
    "            for i,m in enumerate(m_list):\n",
    "                m_list[i] = m % (lgb_kaggle_metric.hack or 1e6)\n",
    "        else:\n",
    "            for i,m in enumerate(m_list):\n",
    "                m_list[i] *= -1\n",
    "                \n",
    "canvas(12,6)\n",
    "fig, (ax0, ax1) = plt.subplots(1,2)\n",
    "#ax = lgb.plot_metric(evals_result, metric='binary_logloss', ax=ax0);\n",
    "ax = lgb.plot_metric(evals_result, metric='kaggle', ax=ax1);\n",
    "canvas(12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P['guess'] = bst.predict(F_)*2-1\n",
    "P.guess = P.guess*(np.abs(P.guess)>=0.0)\n",
    "\n",
    "P['trade'] = P.guess*P.upDown1*P.absVal1\n",
    "\n",
    "daily = P[cv].groupby('time').trade.sum()\n",
    "print(daily.mean()/daily.std(ddof=0))\n",
    "plt.hist(daily, bins=80);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~@~@~@~@~@~@~@~@~@~@~ local analysis of performance ~@~@~@~@~@~@~@~@~@~@~@~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +-+-+-+-+-+-+-+-+-+-+-+-+-+-+- Prediction and submission +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define our prdiction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(F):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the rest of the administrative pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this cell defines some variables necessary for initial start of the feature processing loop\n",
    "Mstart = M[M.time>=M.time.unique()[-longterm]]\n",
    "add_basic_features(M=Mstart)\n",
    "U_ = make_U(M=Mstart)\n",
    "u_ = O()\n",
    "add_shortterm_price_features(U=U_,u=u_)\n",
    "add_longterm_price_features(U=U_,u=u_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 172 iterations\n",
      "Finished loading model, total used 185 iterations\n",
      "0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........300.........310.........320.........330.........340.........350.........360.........370........."
     ]
    }
   ],
   "source": [
    "def do_submission_loop():\n",
    "    feat_iter = iter_features_templates(__env__.get_prediction_days(), U_=(U_,longterm))\n",
    "    for i, (f, p) in enumerate(feat_iter):\n",
    "        if i==0:\n",
    "            initialize_lgb_models(F=f)\n",
    "        print_progress(i)\n",
    "        p.confidenceValue = predict(F=f)\n",
    "        __env__.predict(p)\n",
    "do_submission_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved. Once you `Commit` your Kernel and it finishes running, you can submit the file to the competition from the Kernel Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "__env__.write_submission_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ LOCAL TESTING ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.concat([day[0][['time','assetCode','returnsOpenPrevMktres10']] for day in test], axis=0)\n",
    "X.reset_index(drop=True, inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Z = pd.concat([day[2] for day in test], axis=0)\n",
    "#Z.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all this cell just to make the target column\n",
    "\n",
    "times = X.time.unique()\n",
    "times10 = np.shift(times, -10)\n",
    "times10map = dict(zip(times,times10))\n",
    "\n",
    "Y = X.copy()\n",
    "Y.time = X.time.map(times10map)\n",
    "next10index = Y[~Y.time.isna()].set_index(['time','assetCode']).index\n",
    "\n",
    "_ans = X.set_index(['time','assetCode']).loc[next10index].returnsOpenPrevMktres10.values\n",
    "_ans = np.pad(_ans, pad_width=(0,len(X)-len(_ans)), mode='constant', constant_values=0.)\n",
    "X['answer'] = _ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['guess'] = __env__._submission.confidenceValue.values * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['universe'] = (~X.answer.isna()) & (np.abs(X.answer) < 2)\n",
    "\n",
    "#X.answer = Z.returnsOpenNextMktres10.values\n",
    "#X.universe = Z.universe.values\n",
    "\n",
    "X['target'] = X.answer > 0\n",
    "X['upDown'] = X.target * 2 - 1\n",
    "X['upDown1'] = X.upDown * X.universe.astype(int)\n",
    "X['absVal'] = np.abs(X.answer)\n",
    "X['absVal1'] = X.absVal * X.universe\n",
    "X['weight'] = X.absVal#.qtl()\n",
    "X['weight1'] = X.weight * X.universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['trade'] = X.guess*X.upDown1*X.absVal1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6281170388939231\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAALBCAYAAABbbWcNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ed904c198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lb = X.time < '2018-09-01'\n",
    "daily = X[lb].groupby('time').trade.sum()\n",
    "print(daily.mean()/daily.std(ddof=0))\n",
    "plt.hist(daily, bins=80);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------- SCRATCH ----------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
