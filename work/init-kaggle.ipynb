{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# definitely not production code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from common import *\n",
    "# from pandas.api.types import CategoricalDtype\n",
    "# import warnings \n",
    "# warnings.filterwarnings('ignore')\n",
    "# debug = O()\n",
    "# %matplotlib inline\n",
    "# canvas(12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ho_time = pd.Timestamp('2015-07-01',tz='UTC')\n",
    "\n",
    "# def fake(*,M,N):\n",
    "#     M_, N_ = M, N\n",
    "#     for time, M in M_.groupby('time'):\n",
    "#         if time<ho_time:\n",
    "#             continue\n",
    "#         M['quarter'] = M.time.dt.year+(M.time.dt.quarter-1)/4\n",
    "#         P = M[excluded_columns]\n",
    "#         M = M.drop(columns=['returnsOpenNextMktres10','quarter'])\n",
    "#         P['confidenceValue'] = 0.\n",
    "#         yield M, None, P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #################################################### START HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "M = pd.read_pickle('../data/given/M.pkl')\n",
    "N = pd.read_pickle('../data/given/N.pkl')\n",
    "test = pd.read_pickle('../data/given/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class __env__():\n",
    "    _submitted = []\n",
    "    # -1 = begin, 0 = just yielded, 1 = just predicted, -2 = finished, -3 = finished and submission file written too\n",
    "    _states = [-1]\n",
    "    \n",
    "    class KaggleEnvError(Exception):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_training_data():\n",
    "        return M, N\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_prediction_days():\n",
    "        env = __class__\n",
    "        \n",
    "        class iter_get_prediction_days():\n",
    "            def __iter__(self):\n",
    "                if env._states[-1] != -1:\n",
    "                    raise env.KaggleEnvError('can only call get_prediction_days once!')\n",
    "                \n",
    "                env._days_iter = test.__iter__()\n",
    "                return self\n",
    "            \n",
    "            def __next__(self):\n",
    "                if env._states[-1] == 0:\n",
    "                    raise env.KaggleEnvError('can only yield next day after the previous day was submitted')\n",
    "                elif env._states[-1] not in [-1, 1, -2, -3]:\n",
    "                    raise env.KaggleEnvError(\n",
    "                        'environment internal error [bad state {} for __next__]'.format(env._states[-1]))\n",
    "                \n",
    "                try:\n",
    "                    ret = env._days_iter.__next__()\n",
    "                except StopIteration:\n",
    "                    if env._states[-1] not in [-2, -3]:\n",
    "                        env._states.append(-2)\n",
    "                    raise\n",
    "                \n",
    "                env._states.append(0)\n",
    "                return ret\n",
    "        \n",
    "        return iter_get_prediction_days()\n",
    "            \n",
    "    @staticmethod\n",
    "    def predict(p):\n",
    "        env = __class__\n",
    "        if env._states[-1] == 1:\n",
    "            raise env.KaggleEnvError('must get next prediction day before submitting a prediction again')\n",
    "        elif env._states[-1] == -1:\n",
    "            raise env.KaggleEnvError('must get next prediction day before submitting a prediction')\n",
    "        elif env._states[-1] in [-2, -3]:\n",
    "            raise env.KaggleEnvError('cannot submit prediction, every prediction has already been submitted')\n",
    "        elif env._states[-1] != 0:\n",
    "            raise env.KaggleEnvError('environment internal error [bad state {}]'.format(env._states[-1]))\n",
    "        env._submitted.append(p)\n",
    "        env._states.append(1)\n",
    "        \n",
    "    @staticmethod\n",
    "    def write_submission_file():\n",
    "        env = __class__\n",
    "        if env._states[-1] not in [-2, -3]:\n",
    "            raise env.KaggleEnvError('must be finished predicting before writing submission file')\n",
    "            \n",
    "        template = pd.concat((day[2] for day in test), axis=0)\n",
    "        try:\n",
    "            submission = pd.concat((sub for sub in env._submitted), axis=0)\n",
    "            assert (template.shape==submission.shape), 'submissions have malformed shape'\n",
    "            assert (template.index==submission.index).all(), 'submissions have malformed index'\n",
    "            assert (template.columns==submission.columns).all(), 'submissions have malformed columns'\n",
    "            assert (template.assetCode==submission.assetCode).all(), 'submissions have malformed assetCode column'\n",
    "        except Exception as e:\n",
    "            raise env.KaggleEnvError(e)\n",
    "        \n",
    "        env._submission = submission\n",
    "        if env._states[-1] != -3:\n",
    "            env._states.append(-3)\n",
    "        print('''Your submission file has been saved. Once you `Commit` your Kernel and it finishes running, '''+\n",
    "                '''you can submit the file to the competition from the Kernel Viewer `Output` tab.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++ production additions ++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random, math, functools, itertools, os, gc\n",
    "from collections import Counter, namedtuple\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import altair as alt\n",
    "#from altair import *\n",
    "#sns.set()\n",
    "plt.style.use(['classic', 'seaborn', 'seaborn-colorblind'])\n",
    "\n",
    "def canvas(width, height):\n",
    "    dpi = 96\n",
    "    from pylab import rcParams\n",
    "    rcParams['figure.figsize'] = width, height\n",
    "    \n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `utility.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from importlib import reload\n",
    "from functools import wraps, reduce\n",
    "\n",
    "class Cache(dict):\n",
    "    __slots__ = ('function',)\n",
    "\n",
    "    def __init__(self, function):\n",
    "        self.function = function\n",
    "    \n",
    "    def __getitem__(self, args):\n",
    "        if not isinstance(args, tuple):\n",
    "            args = (args,)\n",
    "        if args not in self:\n",
    "            super().__setitem__(args, self.function(*args))\n",
    "        return super().__getitem__(args)\n",
    "\n",
    "    def __setitem__(self, *args, **kwargs):\n",
    "        raise TypeError(\"Cannot set value to Cache object\")\n",
    "\n",
    "\n",
    "def memoized(function):\n",
    "    '''Use as decorator\n",
    "    DOES NOT SUPPORT kwargs for function! Will ignore all kwargs.\n",
    "    '''\n",
    "    cache = Cache(function)\n",
    "    @wraps(function)\n",
    "    def memoized(*args):\n",
    "        return cache[args]\n",
    "    memoized.cache = cache\n",
    "    return memoized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `object.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def _mydict_init_items_(*args, **kwargs):\n",
    "    items = ()\n",
    "    if len(args) == 3:\n",
    "        space = args[2]\n",
    "        for k in list(space.keys()):\n",
    "            if str.startswith(k, '__') and str.endswith(k, '__'):\n",
    "                del space[k]\n",
    "        items = space.items()\n",
    "    elif args and isinstance(args[0], collections.Mapping):\n",
    "        items = args[0].items()\n",
    "    elif args and isinstance(args[0], collections.Iterable):\n",
    "        items = args[0]\n",
    "    if kwargs:\n",
    "        items = chain(items, kwargs.items())\n",
    "    return items\n",
    "\n",
    "def _mydict_pretty_factory_(start='{', end='}', relater=': ', delimiter=',',\n",
    "                            key_action=lambda p, k: p.pretty(k), base=None):\n",
    "    def _repr_pretty_(obj, p, cycle):\n",
    "        nonlocal start, end, relater, delimiter, key_action, base\n",
    "        typ = type(obj)\n",
    "\n",
    "        beginning = typ.__name__ + '(' + start\n",
    "        ending = end + \")\"\n",
    "\n",
    "        if typ is not base and typ.__repr__ != base.__repr__:\n",
    "            # If the subclass provides its own repr, use it instead.\n",
    "            return p.text(typ.__repr__(obj))\n",
    "\n",
    "        if cycle:\n",
    "            return p.text(beginning + '...' + ending)\n",
    "        p.begin_group(1, beginning)\n",
    "        keys = typ.keys(obj)\n",
    "        # if dict isn't large enough to be truncated,\n",
    "        #   sort keys before displaying\n",
    "        if not (p.max_seq_length and len(obj) >= p.max_seq_length):\n",
    "            try:\n",
    "                keys = sorted(keys)\n",
    "            except Exception:\n",
    "                # Sometimes the keys don't sort.\n",
    "                pass\n",
    "        for idx, key in p._enumerate(keys):\n",
    "            if idx:\n",
    "                p.text(delimiter)\n",
    "                p.breakable()\n",
    "            key_action(p, key)\n",
    "            p.text(relater)\n",
    "            p.pretty(obj[key])\n",
    "        p.end_group(1, ending)\n",
    "    return _repr_pretty_\n",
    "\n",
    "def add_mydict_pprinter(*args, **kwargs):\n",
    "    def decorator(cls):\n",
    "        kwds = dict(kwargs)\n",
    "        kwds['base'] = cls\n",
    "        cls._repr_pretty_ = _mydict_pretty_factory_(*args, **kwds)\n",
    "        return cls\n",
    "    return decorator\n",
    "\n",
    "\n",
    "class DefaultSlots(type):\n",
    "    def __new__(meta, name, bases, attrs):\n",
    "        if '__slots__' not in attrs:\n",
    "            attrs['__slots__'] = ()\n",
    "        return super().__new__(meta, name, bases, attrs)\n",
    "\n",
    "@add_mydict_pprinter()\n",
    "class DictObject(dict, metaclass=DefaultSlots):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        data = ((k if not isinstance(k, str) else k, v)\n",
    "                for k, v in _mydict_init_items_(*args, **kwargs))\n",
    "        super().__init__(data)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"{}({})\".format(type(self).__name__, super().__repr__())\n",
    "\n",
    "    \n",
    "    def __getattribute__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            errstr = \"'{}' object has no attribute '{}'\"\n",
    "            raise AttributeError(errstr.format(type(self).__name__, name))\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "\n",
    "    def __delattr__(self, name):\n",
    "        try:\n",
    "            del self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "@add_mydict_pprinter('', '', '=', ',', lambda p, k: p.text(k))\n",
    "class Namespace(DictObject):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        items = _mydict_init_items_(*args, **kwargs)\n",
    "        data = ((k, v) for k, v in items if isinstance(k, str))\n",
    "        super(__class__, type(self)).__init__(self, data)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if not isinstance(name, str):\n",
    "            errstr = \"{} is not a valid attribute name identifier\"\n",
    "            raise ValueError(errstr.format(name))\n",
    "        self[name] = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        attach = __class__.__repr__\n",
    "        is_orig = False\n",
    "        if not hasattr(attach, '_seen'):\n",
    "            is_orig = True\n",
    "            attach._seen = {}\n",
    "        elif id(self) in attach._seen:\n",
    "            return type(self).__name__ + \"(...)\"\n",
    "        attach._seen[id(self)] = self\n",
    "        try:\n",
    "            it = type(self).items(self)\n",
    "            body = ', '.join(\"{}={}\".format(a, repr(v)) for a, v in it)\n",
    "            return \"{}({})\".format(type(self).__name__, body)\n",
    "        finally:\n",
    "            del attach._seen[id(self)]\n",
    "            if is_orig:\n",
    "                del attach._seen\n",
    "\n",
    "    def mycopy(self, copied={}):\n",
    "        is_orig = not copied\n",
    "        selfc = copied[id(self)] = type(self)()\n",
    "        for key, obj in type(self).items(self):\n",
    "            if isinstance(obj, __class__):\n",
    "                if id(obj) in copied:\n",
    "                    selfc[key] = copied[id(obj)]\n",
    "                else:\n",
    "                    selfc[key] = type(obj).mycopy(obj, copied=copied)\n",
    "            else:\n",
    "                selfc[key] = obj\n",
    "        if is_orig:\n",
    "            copied.clear()\n",
    "        return selfc\n",
    "    \n",
    "    py = lambda o: {str(k): v for k, v in dict.items(o)}\n",
    "\n",
    "def copy(obj):\n",
    "    assert(isinstance(obj, Namespace))\n",
    "    return type(obj).mycopy(obj)\n",
    "\n",
    "########################################################################\n",
    "O = Namespace\n",
    "Namespace.__name__ = '<>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `combos.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from common import *\n",
    "import itertools\n",
    "import functools\n",
    "import math\n",
    "import operator\n",
    "\n",
    "\n",
    "def binom(n, k):\n",
    "    k = min(k, n - k)\n",
    "    return functools.reduce(lambda a, b: a * (n - b) // (b + 1), range(k), 1)\n",
    "\n",
    "\n",
    "@memoized\n",
    "def consecutive_1s(n):\n",
    "    s = n * (n + 1) // 2\n",
    "    c = np.zeros([s, n], dtype=np.int8)\n",
    "    t = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n + 1):\n",
    "            for k in range(i, j):\n",
    "                c[t, k] = 1\n",
    "            t += 1\n",
    "    return c\n",
    "\n",
    "\n",
    "@memoized\n",
    "def one_minus_one(n):\n",
    "    s = n * (n - 1) // 2\n",
    "    c = np.zeros([s, n], dtype=np.int8)\n",
    "    t = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            c[t, i] = 1\n",
    "            c[t, j] = -1\n",
    "            t += 1\n",
    "    return c\n",
    "\n",
    "\n",
    "@memoized\n",
    "def one_minus_one_skip_by_k(n, k):\n",
    "    m = math.ceil(n / k)\n",
    "    s = m * (m - 1) // 2\n",
    "    c = np.zeros([s, n], dtype=np.int8)\n",
    "    t = 0\n",
    "    for i in range(0,n,k):\n",
    "        for j in range(i + k, n, k):\n",
    "            c[t, i] = 1\n",
    "            c[t, j] = -1\n",
    "            t += 1\n",
    "    return c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@memoized\n",
    "def int_coefficients_mod_sign(n, m, duplicates=True):\n",
    "    guys = []\n",
    "    path = [0]\n",
    "    while True:\n",
    "        while True:\n",
    "            if not path:\n",
    "                return np.stack(guys, axis=0) if guys else np.ndarray([0, n], dtype=np.int8)\n",
    "            path[-1] += 1\n",
    "            if path[-1] == 0:\n",
    "                path[-1] += 1\n",
    "            if path[-1] > m:\n",
    "                path.pop()\n",
    "                continue\n",
    "            if len(path) == n:\n",
    "                break\n",
    "            path.append(-m - 1)\n",
    "        if duplicates or functools.reduce(math.gcd, path) == 1:\n",
    "            guys.append(np.asarray(path, dtype=np.int8))\n",
    "\n",
    "\n",
    "@memoized\n",
    "def up_to_m_int_coefficients_mod_sign(n, m, h, duplicates=True):\n",
    "    guys = []\n",
    "    ident = np.eye(n, dtype=np.int8)\n",
    "    for k in range(1, m + 1):\n",
    "        for x_list in itertools.combinations(ident, k):\n",
    "            for sc in int_coefficients_mod_sign(k, h, duplicates):\n",
    "                guy = sum(x * b for b, x in zip(sc, x_list))\n",
    "                guys.append(guy)\n",
    "    return np.stack(guys, axis=0).astype(np.int8, copy=False)\n",
    "\n",
    "\n",
    "@memoized\n",
    "def consecutive_k_1s(m,k):\n",
    "    assert m%k==0, 'consecutive_k_1s argument m must be divisible by argument k'\n",
    "    n = m // k\n",
    "    s = n * (n + 1) // 2\n",
    "    c = np.zeros([s, k*n], dtype=np.int8)\n",
    "    t = 0\n",
    "    for i in range(0,k*n,k):\n",
    "        for j in range(i + k, k*n + 1, k):\n",
    "            for l in range(i, j):\n",
    "                c[t, l] = 1\n",
    "            t += 1\n",
    "    return c\n",
    "\n",
    "\n",
    "class name(metaclass=O):\n",
    "    def index(c):\n",
    "        assert len(c) < 16\n",
    "        pos, neg = [], []\n",
    "        for i, a in enumerate(c):\n",
    "            assert isinstance(a, np.integer) or isinstance(a, int)\n",
    "            if a != 0:\n",
    "                arr = pos if a > 0 else neg\n",
    "                arr += [i] * abs(a)\n",
    "        strpos = ''.join(hex(i)[2:] for i in pos)\n",
    "        strneg = ''.join(hex(i)[2:] for i in neg)\n",
    "        if not neg:\n",
    "            return strpos\n",
    "        else:\n",
    "            return strpos+'/'+strneg\n",
    "    def consec(c):\n",
    "        assert c.any() and (c!=np.shift(c,-1))[:-1].sum()<=2 # c switches from 0 to something then to 0, or switch less\n",
    "        nonzero = c.nonzero()[0]\n",
    "        i, j = nonzero[0], nonzero[-1]\n",
    "        return '({}..{})^{}'.format(i,j,c[i])\n",
    "\n",
    "\n",
    "def union(*cbs):\n",
    "    assert all(cb.shape[1] == cbs[0].shape[1] for cb in cbs)\n",
    "    seen, the = set(), []\n",
    "    for cb in cbs:\n",
    "        for c in cb:\n",
    "            if tuple(c) not in seen:\n",
    "                the.append(c)\n",
    "                seen.update([tuple(c), tuple(-c)])\n",
    "    return np.stack(the)\n",
    "    \n",
    "    \n",
    "class combos(metaclass=O):\n",
    "    name = name\n",
    "    union = union\n",
    "    c1co = consecutive_1s #(n)\n",
    "    ckco = consecutive_k_1s #(n)\n",
    "    \n",
    "    mintco = lambda n, m, h: up_to_m_int_coefficients_mod_sign(n, m, h, False) #(n, m=<max num nonzer coefficients>, <max abs value of coefficients>)\n",
    "    mintcox = lambda n, m, h: up_to_m_int_coefficients_mod_sign(n, m, h, True) #(n, m=<max num nonzer coefficients>, <max abs value of coefficients>)\n",
    "    omo = one_minus_one\n",
    "    omok = one_minus_one_skip_by_k\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `helper.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lens(*it):\n",
    "    return tuple(len(x) for x in it)\n",
    "def shapes(*arrs):\n",
    "    return tuple(x.shape for x in arrs)\n",
    "def sums(*it):\n",
    "    return tuple(sum(x) for x in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift(a, shift, axis=None):\n",
    "    '''Params - a: np.ndarray\n",
    "                shift: integer, + means entries moved to greater indices, - means entries moved to smaller indices\n",
    "                axis: one integer\n",
    "    Equivalent to pd.DataFrame.shift\n",
    "    '''\n",
    "    if axis is None:\n",
    "        assert len(a.shape)==1, \"Only an array of single dimension can be shifted without specifying axis\"\n",
    "        axis = 0\n",
    "    assert isinstance(axis, int)\n",
    "    if not shift:\n",
    "        return a\n",
    "    padding = (shift,0) if shift>0 else (0,-shift)\n",
    "    slicing = slice(None,-shift) if shift>0 else slice(-shift,None)\n",
    "    n = len(a.shape)\n",
    "    axis = n+axis if axis<0 else axis\n",
    "    ret = np.pad(a, ((0,0),)*axis+(padding,)+((0,0),)*(n-axis-1), mode='constant', constant_values=(np.nan,)*n)\n",
    "    ret = ret[(slice(None),)*axis + (slicing,) + (slice(None),)*(n-axis-1)]\n",
    "    return ret\n",
    "np.shift = shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_progress(i, dot=1, numdot=10):\n",
    "    print('.' if i // dot % numdot else i, end='', flush=True) if i % dot == 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## %%%%%%%%%%% requirements check for main prediction code: %%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok go\n"
     ]
    }
   ],
   "source": [
    "__env__\n",
    "O\n",
    "gc\n",
    "canvas\n",
    "print(\"ok go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================== MAIN PREDICTION CODE ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "debug = O()\n",
    "%matplotlib inline\n",
    "canvas(12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M, N = __env__.get_training_data()\n",
    "del N; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IdAssign:\n",
    "    def __init__(self, init):\n",
    "        self.map = {x: i for i,x in enumerate(init)}\n",
    "    def __call__(self, key):\n",
    "        if key not in self.map:\n",
    "            self.map[key] = len(self.map)\n",
    "        return self.map[key]\n",
    "    def __len__(self):\n",
    "        return self.map.__len__()\n",
    "\n",
    "assetCodeSeries = pd.Series(M.assetCode.unique())\n",
    "assetCodeIdMap = IdAssign(assetCodeSeries)\n",
    "\n",
    "assetNameSeries = pd.Series(M.assetName.unique())\n",
    "assetNameIdMap = IdAssign(assetNameSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stringify_columns = lambda f: '[\"'+'\",\"'.join(c for c in f)+'\"]'\n",
    "\n",
    "returns_columns = {\n",
    "    'returnsClosePrevRaw1':'cc', 'returnsOpenPrevRaw1':'oo',\n",
    "    'returnsClosePrevMktres1':'cc0', 'returnsOpenPrevMktres1':'oo0',\n",
    "    'returnsClosePrevRaw10':'cc_10','returnsOpenPrevRaw10':'oo_10',\n",
    "    'returnsClosePrevMktres10':'cc0_10','returnsOpenPrevMktres10':'oo0_10'\n",
    "}\n",
    "columns_for_U = set(returns_columns.values()) | set(['open', 'close', 'volume'])\n",
    "excluded_columns = [\n",
    "    'time','assetCode','assetName','universe','returnsOpenNextMktres10','quarter'\n",
    "]\n",
    "exclusion_filter = lambda c: c not in excluded_columns\n",
    "enumeration_columns = ['assetCodeId', 'assetNameId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_start_time = pd.Timestamp('2009-01-01',tz='UTC')\n",
    "shortterm = 21\n",
    "longterm = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_basic_features(*,M):\n",
    "    M['assetCodeId'] = M.assetCode.map(assetCodeIdMap).astype(int)\n",
    "    M['assetNameId'] = M.assetName.map(assetNameIdMap).astype(int)\n",
    "    for orig_col, new_col in returns_columns.items():\n",
    "        M[new_col] = np.log(M[orig_col]+1)\n",
    "        del M[orig_col]\n",
    "    # time features\n",
    "    M['dayOfYear'] = M.time.dt.dayofyear.astype(float)\n",
    "    M['dayOfWeek'] = M.time.dt.dayofweek.astype(float)\n",
    "\n",
    "    \n",
    "def add_shortterm_price_features(*,U,u):\n",
    "    ################################################################ no NaNs here:\n",
    "    #!U['(oo-oo0)_'] = U.oo_ - U.oo0_\n",
    "    for ww in ['oo','oo0']:#!,'(oo-oo0)']:\n",
    "        window = np.flip(U[ww+'_'],axis=0)[:20]\n",
    "        for c in combos.ckco(20,5):\n",
    "            name = '{}{{{}}}'.format(ww+'_', combos.name.consec(c))\n",
    "            u[name] = c@window\n",
    "    ################################################################# can be NaNs:\n",
    "    #U['(oo-oo0)*'] = U.oo - U.oo0\n",
    "    #U['(cc-cc0)*'] = U.cc - U.cc0\n",
    "    #for ww in ['(oo-oo0)','(cc-cc0)']:\n",
    "    #    window = np.flip(U[ww+'*'],axis=0)[:3]\n",
    "    #    for c in combos.union(combos.omo(3),combos.mintco(3,1,1)):\n",
    "    #        name = '{}{{{}}}'.format(ww, combos.name.index(c))\n",
    "    #        if name[-3]=='{0}':\n",
    "    #            name = name[:-3]\n",
    "    #        u[name] = c@window\n",
    "    ################################################################# can be NaNs:\n",
    "    #!log_open, log_close = np.log(U.open), np.log(U.close) # can be NaNs here\n",
    "    #!U['af'] = log_open - np.shift(log_close,1,axis=0)\n",
    "    #!U['it'] = log_close - log_open\n",
    "    #u['af{1}'] = U.af[-2]\n",
    "    #u['it{1}'] = U.it[-2]\n",
    "    \n",
    "    u['(oo0-cc0)'] = U.oo0[-1] - U.cc0[-1]\n",
    "    #!near0 = np.stack([U.it[-1],U.af[-1],U.it[-2],U.oo0[-1],U.cc0[-1]], axis=0) # can be NaNs\n",
    "    #near1 = np.stack([U.it[-2],U.af[-2],U.it[-3],U.oo0[-2],U.cc0[-2]], axis=0) # can be NaNs\n",
    "    #!for c in combos.omo(5):\n",
    "        #!name = '(it,af,it{{1}},oo0,cc0){{{}}}'.format(combos.name.index(c))\n",
    "        #!u[name] = c@near0\n",
    "        #name = '(it{{1}},af{{1}},it{{2}},oo0{{1}},cc0{{1}}){{{}}}'.format(combos.name.index(c))\n",
    "        #u[name] = c@near1\n",
    "    ################################################################### NaNs exist ish:\n",
    "    #!log_volume = np.log(U.volume)\n",
    "    #!u['volumeRatioMeanBack2'] = log_volume[-1] - np.log(U.volume[-3:-1].mean(axis=0))\n",
    "    #!u['volumeRatioMeanBack2{1}'] = log_volume[-2] - np.log(U.volume[-4:-2].mean(axis=0))\n",
    "    #!u['volumeRatioMean5'] = log_volume[-1] - np.log(U.volume[-5:].mean(axis=0))\n",
    "    #!u['volumeRatioMean10'] = log_volume[-1] - np.log(U.volume[-10:].mean(axis=0))\n",
    "    #u['volumeRatioMean10{5}'] = log_volume[-6] - np.log(U.volume[-15:-5].mean(axis=0))\n",
    "    #u['volumeRatioMean5ByMean20'] = np.log(U.volume[-5:].mean(axis=0)) - np.log(U.volume[-20:].mean(axis=0))\n",
    "            \n",
    "    \n",
    "def add_longterm_price_features(*,U,u,horizons=[21,62,125,250]):\n",
    "    ################################################################# no NaNs\n",
    "    #!u['oo0_20'] = U.oo0_10_[-11::10].sum(axis=0)\n",
    "    #!u['oo0_120'] = U.oo0_10_[-121::10].sum(axis=0)\n",
    "    \n",
    "    #!u['oo_20'] = U.oo_10_[-11::10].sum(axis=0)\n",
    "    #!u['oo_120'] = U.oo_10_[-121::10].sum(axis=0)\n",
    "    \n",
    "    #!u['(oo-oo0)_10'] = U.oo_10[-1] - U.oo0_10[-1]\n",
    "    #!u['(oo-oo0)_20'] = U.oo_10_[-11::10].sum(axis=0) - U.oo0_10_[-11::10].sum(axis=0)\n",
    "    #!u['(oo-oo0)_120'] = U.oo_10_[-121::10].sum(axis=0) - U.oo0_10_[-121::10].sum(axis=0)\n",
    "    #################################################################### no NaNs\n",
    "    for ww in ['oo','oo0']:\n",
    "        for h in horizons:\n",
    "            strh = str(h)\n",
    "            since = U[ww+'Since'+strh] = U[ww+'_'][-h:].cumsum(axis=0)\n",
    "            \n",
    "            maxSince = U[ww+'MaxSince'+strh] = np.maximum.accumulate(since, axis=0)\n",
    "            drawdownSince = U[ww+'DrawdownSince'+strh] = maxSince - since\n",
    "            u[ww+'MaxDrawdown5Since'+strh] = drawdownSince[-5:].max(axis=0)\n",
    "            u[ww+'MaxDrawdown10Since'+strh] = drawdownSince[-10:].max(axis=0)\n",
    "            #u[ww+'MaxDrawdown20Since'+strh] = drawdownSince[-20:].max(axis=0)\n",
    "            #u[ww+'MaxDrawdown(10-5)Since'+strh] = drawdownSince[-10:-5].max(axis=0)\n",
    "            #!u[ww+'MaxDrawdown(20-10)Since'+strh] = drawdownSince[-20:-10].max(axis=0)\n",
    "            #u[ww+'Prev5MaxSince'+strh] = maxSince[-6]\n",
    "            u[ww+'Prev10MaxSince'+strh] = maxSince[-11]\n",
    "            #u[ww+'Prev20MaxSince'+strh] = maxSince[-21]\n",
    "            \n",
    "            minSince = U[ww+'MinSince'+strh] = np.minimum.accumulate(since, axis=0)\n",
    "            #!drawupSince = U[ww+'DrawupSince'+strh] = since - minSince\n",
    "            #maxDrawup5Since = U[ww+'MaxDrawup5Since'+strh] = drawupSince[-5:].max(axis=0)[np.newaxis,:]\n",
    "            #!maxDrawup10Since = U[ww+'MaxDrawup10Since'+strh] = drawupSince[-10:].max(axis=0)[np.newaxis,:]\n",
    "            #maxDrawup20Since = U[ww+'MaxDrawup20Since'+strh] = drawupSince[-20:].max(axis=0)[np.newaxis,:]\n",
    "            #maxDrawup10_5Since = U[ww+'MaxDrawup(10-5)Since'+strh] = drawupSince[-10:-5].max(axis=0)[np.newaxis,:]\n",
    "            #!maxDrawup20_10Since = U[ww+'MaxDrawup(20-10)Since'+strh] = drawupSince[-20:-10].max(axis=0)[np.newaxis,:]\n",
    "            #u[ww+'Prev5MinSince'+strh] = minSince[-6]\n",
    "            u[ww+'Prev10MinSince'+strh] = minSince[-11]\n",
    "            #u[ww+'Prev20MinSince'+strh] = minSince[-21]\n",
    "            \n",
    "\n",
    "def add_postprocessing_features(*,F):\n",
    "    F['assetCodeIdWTFlogabs'] = F.assetCodeId.map(str).map(hash).pipe(np.abs).pipe(np.log)\n",
    "    F['assetCodeIdWTFsin2'] = F.assetCodeId.map(str).map(hash).pipe(np.sin).pipe(lambda x: x * x)\n",
    "    F['assetCodeIdWTFFlogabs'] = F.assetCodeId.map(str).map(hash).map(str).map(hash).pipe(np.abs).pipe(np.log)\n",
    "    F['assetCodeIdWTFFsin2'] = F.assetCodeId.map(str).map(hash).map(str).map(hash).pipe(np.sin).pipe(lambda x: x * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_single_A_U_u(*,M):\n",
    "    '''M needs to assetCodeId indexed'''\n",
    "    A = pd.DataFrame(index=pd.Series(range(len(assetCodeIdMap)),name='assetCodeId')).join(M)\n",
    "    #^ A = join onto standard assetCode row-index\n",
    "    V = O(**{c:A[c] for c in columns_for_U})\n",
    "    U = O(**{c:A[c].values[np.newaxis,:] for c in columns_for_U},\n",
    "          **{c+'_':np.nan_to_num(A[c].values[np.newaxis,:]) for c in columns_for_U})\n",
    "    return A, U, O()\n",
    "\n",
    "def make_U(*,M):\n",
    "    Us = [make_single_A_U_u(M=m)[1] for _,m in M.groupby('time')]\n",
    "    U = O(**{c:np.concatenate([U[c] for U in Us],axis=0) for c in Us[0]})\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some initialization work to get the static list of columns of interest\n",
    "\n",
    "Minit = M[M.time<=M.time.unique()[longterm]]\n",
    "set_basic_features(M=Minit)\n",
    "Uinit = make_U(M=Minit)\n",
    "uinit = O()\n",
    "debug.U0_keys = set(dict.keys(Uinit))\n",
    "add_shortterm_price_features(U=Uinit,u=uinit)\n",
    "add_longterm_price_features(U=Uinit,u=uinit)\n",
    "\n",
    "Mcolumns = [c for c in Minit.columns if c not in excluded_columns]\n",
    "setMcolumns = set(Mcolumns)\n",
    "Ucolumns = [c for c in Uinit if c not in Mcolumns and c[-1] not in '*_']\n",
    "ucolumns = [c for c in uinit if c not in Mcolumns and c[-1] not in '*_']\n",
    "\n",
    "del Minit,Uinit,uinit; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_features_templates(MNP_iter, *, U_):\n",
    "    U_, term = U_\n",
    "    for M, N, P in MNP_iter:\n",
    "        orig_index = M.index\n",
    "        set_basic_features(M=M) # adds \"long\" features and deletes non-log price features\n",
    "        M.set_index('assetCodeId', inplace=True)\n",
    "        A, U, u = make_single_A_U_u(M=M)\n",
    "        assert debug.U0_keys==set(dict.keys(U))\n",
    "        M.drop(columns=[c for c in M.columns if c not in setMcolumns], inplace=True)\n",
    "        # expand rows in old U_ if new assetCodeIds were seen\n",
    "        akey = next(iter(U))\n",
    "        diff = U[akey].shape[1] - U_[akey].shape[1]\n",
    "        if diff > 0:\n",
    "            for key in U_:\n",
    "                if key[-1] != '_': # normal features\n",
    "                    U_[key] = np.pad(U_[key], pad_width=((0,0),(0,diff)), mode='constant', constant_values=np.nan)\n",
    "                else: # NaN-filled-with-0 features\n",
    "                    U_[key] = np.pad(U_[key], pad_width=((0,0),(0,diff)), mode='constant', constant_values=0)\n",
    "        # join new row vectors in U to the old tables in U_\n",
    "        for key in U:\n",
    "            U_[key] = np.concatenate([U_[key],U[key]], axis=0)\n",
    "            if len(U_[key])>term:\n",
    "                U_[key] = U_[key][-term:]\n",
    "        # add features to U_ and U__\n",
    "        gc.collect()\n",
    "        add_shortterm_price_features(U=U_,u=u)\n",
    "        gc.collect()\n",
    "        add_longterm_price_features(U=U_,u=u)\n",
    "        gc.collect()\n",
    "        assert len(set(U_)&set(u))==0\n",
    "        # take out the bottom row of the feature tables to feed out as our feature construction iterator\n",
    "        _dict = {c: U_[c][-1] for c in Ucolumns}\n",
    "        _dict.update({c: u[c] for c in ucolumns})\n",
    "        # piece everything together\n",
    "        columns = Ucolumns + ucolumns\n",
    "        F = pd.DataFrame([_dict[c] for c in columns], index=columns, columns=A.index).T\n",
    "        F = M.join(F)\n",
    "        assert 'assetCodeId' not in F.columns\n",
    "        F.reset_index(inplace=True)\n",
    "        F.index = orig_index\n",
    "        for c in enumeration_columns:\n",
    "            assert np.issubdtype(F[c].dtype, np.integer)\n",
    "        add_postprocessing_features(F=F)\n",
    "        # downgrade columns to 32bit dtypes for memory saving\n",
    "        for c in F.columns:\n",
    "            if np.issubdtype(F[c].dtype, np.float):\n",
    "                if F[c].dtype != np.float32:\n",
    "                    F[c] = F[c].astype(np.float32)\n",
    "            elif np.issubdtype(F[c].dtype, np.integer):\n",
    "                if F[c].dtype != np.int32:\n",
    "                    F[c] = F[c].astype(np.int32)\n",
    "            else:\n",
    "                assert False, 'dtype other than float or int found in features'\n",
    "        yield F, P\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iter_MNP_train(*,M,N):\n",
    "    M_, N_ = M, N\n",
    "    for time, M in M_.groupby('time'):\n",
    "        if time<train_start_time:\n",
    "            continue\n",
    "        M['quarter'] = M.time.dt.year+(M.time.dt.quarter-1)/4\n",
    "        P = M[excluded_columns]\n",
    "        M = M.drop(columns=['returnsOpenNextMktres10','quarter'])\n",
    "        yield M, None, P\n",
    "        \n",
    "Mstart = M[M.time<train_start_time]\n",
    "set_basic_features(M=Mstart)\n",
    "U_ = make_U(M=Mstart)\n",
    "u_ = O()\n",
    "add_shortterm_price_features(U=U_,u=u_)\n",
    "add_longterm_price_features(U=U_,u=u_)\n",
    "del Mstart, u_; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.........100.........200.........300.........400.........500.........600.........700.........800.........900.........1000.........1100.........1200.........1300.........1400.........1500.........1600.........1700.........1800.........1900.........2000.CPU times: user 1h 38min 30s, sys: 3min 20s, total: 1h 41min 50s\n",
      "Wall time: 43min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def make_train():\n",
    "    feat_iter = iter_features_templates(iter_MNP_train(M=M,N=None), U_=(U_,longterm))\n",
    "    train = [[print_progress(i,10),(F,P)][-1] for i,(F,P) in enumerate(feat_iter)]\n",
    "    F = pd.concat([FP[0] for FP in train], axis=0)\n",
    "    P = pd.concat([FP[1] for FP in train], axis=0)\n",
    "    F.index = P.index\n",
    "    return F,P\n",
    "F,P = make_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### saving some variables for leaderboard submission loop before deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this cell defines some variables necessary for initial start of the feature processing loop\n",
    "Mstart = M[M.time>=M.time.unique()[-longterm]]\n",
    "set_basic_features(M=Mstart)\n",
    "U_ = make_U(M=Mstart)\n",
    "del Mstart; gc.collect()\n",
    "u_ = O()\n",
    "add_shortterm_price_features(U=U_,u=u_)\n",
    "add_longterm_price_features(U=U_,u=u_)\n",
    "del u_; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del M; gc.collect() # used to delet U_ too, but now need it for final submission loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ~ ~ ~ ~ ~ saving/loading for local testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.to_pickle((F,P), '/big/data/saves/train_4Newnewfault32.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FF,PP = pd.read_pickle('/big/data/saves/train_3allright32.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F0,P0 = pd.read_pickle('/big/data/saves/train_newfault.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F,P = FF,PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training some particular model! /////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "ho = P.quarter>=2015.5\n",
    "ho.name = None\n",
    "tr, cv = next(GroupShuffleSplit(n_splits=1, test_size=.5, random_state=44).split(F[~ho], P[~ho], groups=P[~ho].quarter))\n",
    "_dummy = pd.Series(range(len(P)),index=P.index)\n",
    "tr, cv = _dummy.isin(tr), _dummy.isin(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P['target'] = P.returnsOpenNextMktres10>0\n",
    "P['upDown'] = (P.target*2-1)\n",
    "P['upDown1'] = P.upDown*P.universe.astype(int)\n",
    "P['absVal'] = np.abs(P.returnsOpenNextMktres10)\n",
    "P['absVal1'] = P.absVal*P.universe\n",
    "P['weight'] = P.absVal#.qtl()\n",
    "P['weight1'] = P.weight*P.universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature sets definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fThefault\n"
     ]
    }
   ],
   "source": [
    "fThefault = [\"volume\",\"close\",\"open\",\"assetCodeId\",\"assetNameId\",\"cc\",\"oo\",\"cc0\",\"oo0\",\"cc_10\",\"oo_10\",\"cc0_10\",\"oo0_10\",\"dayOfYear\",\"dayOfWeek\",\"af\",\"it\",\"ooSince21\",\"ooMaxSince21\",\"ooDrawdownSince21\",\"ooMinSince21\",\"ooDrawupSince21\",\"ooMaxDrawup5Since21\",\"ooMaxDrawup10Since21\",\"ooMaxDrawup(10-5)Since21\",\"ooMaxDrawup(20-10)Since21\",\"ooSince62\",\"ooMaxSince62\",\"ooDrawdownSince62\",\"ooMinSince62\",\"ooDrawupSince62\",\"ooMaxDrawup5Since62\",\"ooMaxDrawup10Since62\",\"ooMaxDrawup(10-5)Since62\",\"ooMaxDrawup(20-10)Since62\",\"ooSince125\",\"ooMaxSince125\",\"ooDrawdownSince125\",\"ooMinSince125\",\"ooDrawupSince125\",\"ooMaxDrawup5Since125\",\"ooMaxDrawup10Since125\",\"ooMaxDrawup(10-5)Since125\",\"ooMaxDrawup(20-10)Since125\",\"ooSince250\",\"ooMaxSince250\",\"ooDrawdownSince250\",\"ooMinSince250\",\"ooDrawupSince250\",\"ooMaxDrawup5Since250\",\"ooMaxDrawup10Since250\",\"ooMaxDrawup(10-5)Since250\",\"ooMaxDrawup(20-10)Since250\",\"oo0Since21\",\"oo0MaxSince21\",\"oo0DrawdownSince21\",\"oo0MinSince21\",\"oo0DrawupSince21\",\"oo0MaxDrawup5Since21\",\"oo0MaxDrawup10Since21\",\"oo0MaxDrawup(10-5)Since21\",\"oo0MaxDrawup(20-10)Since21\",\"oo0Since62\",\"oo0MaxSince62\",\"oo0DrawdownSince62\",\"oo0MinSince62\",\"oo0DrawupSince62\",\"oo0MaxDrawup5Since62\",\"oo0MaxDrawup10Since62\",\"oo0MaxDrawup(10-5)Since62\",\"oo0MaxDrawup(20-10)Since62\",\"oo0Since125\",\"oo0MaxSince125\",\"oo0DrawdownSince125\",\"oo0MinSince125\",\"oo0DrawupSince125\",\"oo0MaxDrawup5Since125\",\"oo0MaxDrawup10Since125\",\"oo0MaxDrawup(10-5)Since125\",\"oo0MaxDrawup(20-10)Since125\",\"oo0Since250\",\"oo0MaxSince250\",\"oo0DrawdownSince250\",\"oo0MinSince250\",\"oo0DrawupSince250\",\"oo0MaxDrawup5Since250\",\"oo0MaxDrawup10Since250\",\"oo0MaxDrawup(10-5)Since250\",\"oo0MaxDrawup(20-10)Since250\",\"oo_{(0..4)^1}\",\"oo_{(0..9)^1}\",\"oo_{(0..14)^1}\",\"oo_{(0..19)^1}\",\"oo_{(5..9)^1}\",\"oo_{(5..14)^1}\",\"oo_{(5..19)^1}\",\"oo_{(10..14)^1}\",\"oo_{(10..19)^1}\",\"oo_{(15..19)^1}\",\"oo0_{(0..4)^1}\",\"oo0_{(0..9)^1}\",\"oo0_{(0..14)^1}\",\"oo0_{(0..19)^1}\",\"oo0_{(5..9)^1}\",\"oo0_{(5..14)^1}\",\"oo0_{(5..19)^1}\",\"oo0_{(10..14)^1}\",\"oo0_{(10..19)^1}\",\"oo0_{(15..19)^1}\",\"(oo-oo0)_{(0..4)^1}\",\"(oo-oo0)_{(0..9)^1}\",\"(oo-oo0)_{(0..14)^1}\",\"(oo-oo0)_{(0..19)^1}\",\"(oo-oo0)_{(5..9)^1}\",\"(oo-oo0)_{(5..14)^1}\",\"(oo-oo0)_{(5..19)^1}\",\"(oo-oo0)_{(10..14)^1}\",\"(oo-oo0)_{(10..19)^1}\",\"(oo-oo0)_{(15..19)^1}\",\"(oo-oo0){0/1}\",\"(oo-oo0){0/2}\",\"(oo-oo0){1/2}\",\"(oo-oo0){0}\",\"(oo-oo0){1}\",\"(oo-oo0){2}\",\"(cc-cc0){0/1}\",\"(cc-cc0){0/2}\",\"(cc-cc0){1/2}\",\"(cc-cc0){0}\",\"(cc-cc0){1}\",\"(cc-cc0){2}\",\"af{1}\",\"it{1}\",\"(it,af,it{1},oo0,cc0){0/1}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){0/1}\",\"(it,af,it{1},oo0,cc0){0/2}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){0/2}\",\"(it,af,it{1},oo0,cc0){0/3}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){0/3}\",\"(it,af,it{1},oo0,cc0){0/4}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){0/4}\",\"(it,af,it{1},oo0,cc0){1/2}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){1/2}\",\"(it,af,it{1},oo0,cc0){1/3}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){1/3}\",\"(it,af,it{1},oo0,cc0){1/4}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){1/4}\",\"(it,af,it{1},oo0,cc0){2/3}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){2/3}\",\"(it,af,it{1},oo0,cc0){2/4}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){2/4}\",\"(it,af,it{1},oo0,cc0){3/4}\",\"(it{1},af{1},it{2},oo0{1},cc0{1}){3/4}\",\"volumeRatioMeanBack2\",\"volumeRatioMeanBack2{1}\",\"volumeRatioMean5\",\"volumeRatioMean10\",\"volumeRatioMean10{5}\",\"volumeRatioMean5ByMean20\",\"oo0_20\",\"oo0_60\",\"oo0_120\",\"oo0_250\",\"ooMaxDrawdown5Since21\",\"ooMaxDrawdown10Since21\",\"ooMaxDrawdown(10-5)Since21\",\"ooMaxDrawdown(20-10)Since21\",\"ooPrev5MaxSince21\",\"ooPrev10MaxSince21\",\"ooPrev5MinSince21\",\"ooPrev10MinSince21\",\"ooMaxDrawdown5Since62\",\"ooMaxDrawdown10Since62\",\"ooMaxDrawdown(10-5)Since62\",\"ooMaxDrawdown(20-10)Since62\",\"ooPrev5MaxSince62\",\"ooPrev10MaxSince62\",\"ooPrev5MinSince62\",\"ooPrev10MinSince62\",\"ooMaxDrawdown5Since125\",\"ooMaxDrawdown10Since125\",\"ooMaxDrawdown(10-5)Since125\",\"ooMaxDrawdown(20-10)Since125\",\"ooPrev5MaxSince125\",\"ooPrev10MaxSince125\",\"ooPrev5MinSince125\",\"ooPrev10MinSince125\",\"ooMaxDrawdown5Since250\",\"ooMaxDrawdown10Since250\",\"ooMaxDrawdown(10-5)Since250\",\"ooMaxDrawdown(20-10)Since250\",\"ooPrev5MaxSince250\",\"ooPrev10MaxSince250\",\"ooPrev5MinSince250\",\"ooPrev10MinSince250\",\"oo0MaxDrawdown5Since21\",\"oo0MaxDrawdown10Since21\",\"oo0MaxDrawdown(10-5)Since21\",\"oo0MaxDrawdown(20-10)Since21\",\"oo0Prev5MaxSince21\",\"oo0Prev10MaxSince21\",\"oo0Prev5MinSince21\",\"oo0Prev10MinSince21\",\"oo0MaxDrawdown5Since62\",\"oo0MaxDrawdown10Since62\",\"oo0MaxDrawdown(10-5)Since62\",\"oo0MaxDrawdown(20-10)Since62\",\"oo0Prev5MaxSince62\",\"oo0Prev10MaxSince62\",\"oo0Prev5MinSince62\",\"oo0Prev10MinSince62\",\"oo0MaxDrawdown5Since125\",\"oo0MaxDrawdown10Since125\",\"oo0MaxDrawdown(10-5)Since125\",\"oo0MaxDrawdown(20-10)Since125\",\"oo0Prev5MaxSince125\",\"oo0Prev10MaxSince125\",\"oo0Prev5MinSince125\",\"oo0Prev10MinSince125\",\"oo0MaxDrawdown5Since250\",\"oo0MaxDrawdown10Since250\",\"oo0MaxDrawdown(10-5)Since250\",\"oo0MaxDrawdown(20-10)Since250\",\"oo0Prev5MaxSince250\",\"oo0Prev10MaxSince250\",\"oo0Prev5MinSince250\",\"oo0Prev10MinSince250\"]\n",
    "print('fThefault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fNewfault\n"
     ]
    }
   ],
   "source": [
    "fNewfault = [\"volume\",\"close\",\"open\",\"assetCodeId\",\"assetNameId\",\"cc\",\"oo\",\"cc0\",\"oo0\",\"cc_10\",\"oo_10\",\"cc0_10\",\"oo0_10\",\"dayOfYear\",\"dayOfWeek\",\"ooSince21\",\"ooMaxSince21\",\"ooDrawdownSince21\",\"ooMaxDrawdown5Since21\",\"ooMaxDrawdown10Since21\",\"ooPrev10MaxSince21\",\"ooMinSince21\",\"ooPrev10MinSince21\",\"ooSince62\",\"ooMaxSince62\",\"ooDrawdownSince62\",\"ooMaxDrawdown5Since62\",\"ooMaxDrawdown10Since62\",\"ooPrev10MaxSince62\",\"ooMinSince62\",\"ooPrev10MinSince62\",\"ooSince125\",\"ooMaxSince125\",\"ooDrawdownSince125\",\"ooMaxDrawdown5Since125\",\"ooMaxDrawdown10Since125\",\"ooPrev10MaxSince125\",\"ooMinSince125\",\"ooPrev10MinSince125\",\"ooSince250\",\"ooMaxSince250\",\"ooDrawdownSince250\",\"ooMaxDrawdown5Since250\",\"ooMaxDrawdown10Since250\",\"ooPrev10MaxSince250\",\"ooMinSince250\",\"ooPrev10MinSince250\",\"oo0Since21\",\"oo0MaxSince21\",\"oo0DrawdownSince21\",\"oo0MaxDrawdown5Since21\",\"oo0MaxDrawdown10Since21\",\"oo0Prev10MaxSince21\",\"oo0MinSince21\",\"oo0Prev10MinSince21\",\"oo0Since62\",\"oo0MaxSince62\",\"oo0DrawdownSince62\",\"oo0MaxDrawdown5Since62\",\"oo0MaxDrawdown10Since62\",\"oo0Prev10MaxSince62\",\"oo0MinSince62\",\"oo0Prev10MinSince62\",\"oo0Since125\",\"oo0MaxSince125\",\"oo0DrawdownSince125\",\"oo0MaxDrawdown5Since125\",\"oo0MaxDrawdown10Since125\",\"oo0Prev10MaxSince125\",\"oo0MinSince125\",\"oo0Prev10MinSince125\",\"oo0Since250\",\"oo0MaxSince250\",\"oo0DrawdownSince250\",\"oo0MaxDrawdown5Since250\",\"oo0MaxDrawdown10Since250\",\"oo0Prev10MaxSince250\",\"oo0MinSince250\",\"oo0Prev10MinSince250\",\"oo_{(0..4)^1}\",\"oo_{(0..9)^1}\",\"oo_{(0..14)^1}\",\"oo_{(0..19)^1}\",\"oo_{(5..9)^1}\",\"oo_{(5..14)^1}\",\"oo_{(5..19)^1}\",\"oo_{(10..14)^1}\",\"oo_{(10..19)^1}\",\"oo_{(15..19)^1}\",\"oo0_{(0..4)^1}\",\"oo0_{(0..9)^1}\",\"oo0_{(0..14)^1}\",\"oo0_{(0..19)^1}\",\"oo0_{(5..9)^1}\",\"oo0_{(5..14)^1}\",\"oo0_{(5..19)^1}\",\"oo0_{(10..14)^1}\",\"oo0_{(10..19)^1}\",\"oo0_{(15..19)^1}\",\"(it,af,it{1},oo0,cc0){3/4}\"]\n",
    "fNewnewfault = fNewfault[:-1] + ['(oo0-cc0)']\n",
    "print('fNewfault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f2firstkaggle\n"
     ]
    }
   ],
   "source": [
    "f2firstkaggle = [\"assetCodeId\",\"volume\",\"close\",\"open\",\"assetNameId\",\"cc\",\"oo\",\"cc0\",\"oo0\",\"cc_10\",\"oo_10\",\"cc0_10\",\"oo0_10\",\"dayOfYear\",\"dayOfWeek\",\"af\",\"it\",\"ooSince21\",\"ooMaxSince21\",\"ooDrawdownSince21\",\"ooMinSince21\",\"ooDrawupSince21\",\"ooMaxDrawup10Since21\",\"ooMaxDrawup(20-10)Since21\",\"ooSince125\",\"ooMaxSince125\",\"ooDrawdownSince125\",\"ooMinSince125\",\"ooDrawupSince125\",\"ooMaxDrawup10Since125\",\"ooMaxDrawup(20-10)Since125\",\"oo_{(0..4)^1}\",\"oo_{(0..9)^1}\",\"oo_{(0..14)^1}\",\"oo_{(0..19)^1}\",\"oo_{(5..9)^1}\",\"oo_{(5..14)^1}\",\"oo_{(5..19)^1}\",\"oo_{(10..14)^1}\",\"oo_{(10..19)^1}\",\"oo_{(15..19)^1}\",\"oo0_{(0..4)^1}\",\"oo0_{(0..9)^1}\",\"oo0_{(0..14)^1}\",\"oo0_{(0..19)^1}\",\"oo0_{(5..9)^1}\",\"oo0_{(5..14)^1}\",\"oo0_{(5..19)^1}\",\"oo0_{(10..14)^1}\",\"oo0_{(10..19)^1}\",\"oo0_{(15..19)^1}\",\"(oo-oo0)_{(0..4)^1}\",\"(oo-oo0)_{(0..9)^1}\",\"(oo-oo0)_{(0..14)^1}\",\"(oo-oo0)_{(0..19)^1}\",\"(oo-oo0)_{(5..9)^1}\",\"(oo-oo0)_{(5..14)^1}\",\"(oo-oo0)_{(5..19)^1}\",\"(oo-oo0)_{(10..14)^1}\",\"(oo-oo0)_{(10..19)^1}\",\"(oo-oo0)_{(15..19)^1}\",\"(it,af,it{1},oo0,cc0){0/1}\",\"(it,af,it{1},oo0,cc0){0/2}\",\"(it,af,it{1},oo0,cc0){0/3}\",\"(it,af,it{1},oo0,cc0){0/4}\",\"(it,af,it{1},oo0,cc0){1/2}\",\"(it,af,it{1},oo0,cc0){1/3}\",\"(it,af,it{1},oo0,cc0){1/4}\",\"(it,af,it{1},oo0,cc0){2/3}\",\"(it,af,it{1},oo0,cc0){2/4}\",\"(it,af,it{1},oo0,cc0){3/4}\",\"volumeRatioMeanBack2\",\"volumeRatioMeanBack2{1}\",\"volumeRatioMean5\",\"volumeRatioMean10\",\"oo0_20\",\"oo0_120\",\"oo_20\",\"oo_120\",\"(oo-oo0)_10\",\"(oo-oo0)_20\",\"(oo-oo0)_120\",\"ooMaxDrawdown10Since21\",\"ooMaxDrawdown(20-10)Since21\",\"ooPrev10MaxSince21\",\"ooPrev10MinSince21\",\"ooMaxDrawdown10Since125\",\"ooMaxDrawdown(20-10)Since125\",\"ooPrev10MaxSince125\",\"ooPrev10MinSince125\"]#,\"assetCodeIdWTFlogabs\",\"assetCodeIdWTFsin2\",\"assetCodeIdWTFFlogabs\",\"assetCodeIdWTFFsin2\"]\n",
    "print('f2firstkaggle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fTime fAsset fPriceAbsolute\n"
     ]
    }
   ],
   "source": [
    "fTime = 'dayOfYear dayOfWeek'.split()\n",
    "fAsset = 'assetCodeId assetNameId'.split()\n",
    "fPriceAbsolute = 'close open'.split()\n",
    "print('fTime fAsset fPriceAbsolute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_relative combinations...\n"
     ]
    }
   ],
   "source": [
    "def select_relative(f):\n",
    "    return f not in set(fTime+fAsset+fPriceAbsolute)\n",
    "\n",
    "fThefaultRelative = list(filter(select_relative, fThefault))\n",
    "\n",
    "fHack1 = ['assetCodeIdWTFlogabs', 'assetCodeIdWTFsin2']\n",
    "fHack2 = ['assetCodeIdWTFFlogabs', 'assetCodeIdWTFFsin2']\n",
    "fNewfaultRelativeHack0 = list(filter(select_relative, fNewfault)) + fHack2\n",
    "\n",
    "print('select_relative combinations...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### choose our feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fSelection = list(filter(select_relative, fNewnewfault)) + fHack2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the lgb data structure and train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_ = F[fSelection]\n",
    "\n",
    "lgb_data_info = dict(\n",
    "    feature_name = list(F_.columns),\n",
    "    categorical_feature = list(F_.dtypes[F_.dtypes==np.int64].index),\n",
    "    free_raw_data = True,\n",
    ")\n",
    "\n",
    "L = O()\n",
    "L.tr = lgb.Dataset(F_[tr], P.target[tr], weight=P.weight1[tr], **lgb_data_info)\n",
    "L.cv = lgb.Dataset(F_[cv], P.target[cv], reference=L.tr, weight=P.weight1[cv], **lgb_data_info)\n",
    "L.ho = lgb.Dataset(F_[ho], P.target[ho], weight=P.weight1[ho], **lgb_data_info)\n",
    "del F_; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L.tr.timeFactor = P.time[tr].factorize()[0]\n",
    "L.cv.timeFactor = P.time[cv].factorize()[0]\n",
    "L.tr.value = (P.upDown1*P.absVal1)[tr]\n",
    "L.cv.value = (P.upDown1*P.absVal1)[cv]\n",
    "L.tr.i = 0\n",
    "L.cv.i = 0\n",
    "\n",
    "def lgb_kaggle_metric(preds, valid_data):\n",
    "    df_time = valid_data.timeFactor\n",
    "    #labels = valid_data.get_label()\n",
    "    values = valid_data.value\n",
    "    #assert len(labels) == len(df_time)\n",
    "\n",
    "    preds = preds*2-1\n",
    "    #labels = labels*2-1\n",
    "    x_t = preds * values\n",
    "    \n",
    "    # Here we take advantage of the fact that `labels` (used to calculate `x_t`)\n",
    "    # is a pd.Series and call `group_by`\n",
    "    x_t_sum = x_t.groupby(df_time).sum()\n",
    "    score = x_t_sum.mean() / x_t_sum.std()\n",
    "\n",
    "    valid_data.i += lgb_kaggle_metric.hack\n",
    "    return 'kaggle', score+valid_data.i, True\n",
    "lgb_kaggle_metric.hack = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[10]\ttr's kaggle: 0.636333\tcv's kaggle: 0.570462\n",
      "[20]\ttr's kaggle: 0.667688\tcv's kaggle: 0.612908\n",
      "[30]\ttr's kaggle: 0.685424\tcv's kaggle: 0.626002\n",
      "[40]\ttr's kaggle: 0.699955\tcv's kaggle: 0.630407\n",
      "[50]\ttr's kaggle: 0.711198\tcv's kaggle: 0.631784\n",
      "[60]\ttr's kaggle: 0.719196\tcv's kaggle: 0.630734\n",
      "[70]\ttr's kaggle: 0.723436\tcv's kaggle: 0.632577\n",
      "[80]\ttr's kaggle: 0.724491\tcv's kaggle: 0.637849\n",
      "[90]\ttr's kaggle: 0.730191\tcv's kaggle: 0.642192\n",
      "[100]\ttr's kaggle: 0.735556\tcv's kaggle: 0.646784\n",
      "[110]\ttr's kaggle: 0.742969\tcv's kaggle: 0.645634\n",
      "[120]\ttr's kaggle: 0.747262\tcv's kaggle: 0.645531\n",
      "[130]\ttr's kaggle: 0.752392\tcv's kaggle: 0.645446\n",
      "[140]\ttr's kaggle: 0.758293\tcv's kaggle: 0.645346\n",
      "[150]\ttr's kaggle: 0.761816\tcv's kaggle: 0.646842\n",
      "[160]\ttr's kaggle: 0.769674\tcv's kaggle: 0.648701\n",
      "[170]\ttr's kaggle: 0.776949\tcv's kaggle: 0.648432\n",
      "[180]\ttr's kaggle: 0.783252\tcv's kaggle: 0.646126\n",
      "[190]\ttr's kaggle: 0.787807\tcv's kaggle: 0.646194\n",
      "[200]\ttr's kaggle: 0.793179\tcv's kaggle: 0.647384\n",
      "[210]\ttr's kaggle: 0.795785\tcv's kaggle: 0.647007\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttr's kaggle: 0.77109\tcv's kaggle: 0.64905\n"
     ]
    }
   ],
   "source": [
    "lgb_params = dict(\n",
    "    #task = 'train',\n",
    "    objective = 'binary',\n",
    "    \n",
    "    num_iterations = 500,\n",
    "    early_stopping_round = 50,\n",
    "    \n",
    "    learning_rate = .05, #.02, #0.05,\n",
    "    num_leaves = 1<<12, #1<<16, #1<<12,\n",
    "    max_depth = 12, #16, #12,\n",
    "    min_data_in_leaf = 150, #120, #200(rd26)/120(rd17), #150,\n",
    "    min_sum_hessian_in_leaf = 50, #0, #50,\n",
    "    #bagging_fraction = 1,\n",
    "    #bagging_freq = 0,\n",
    "    #feature_fraction = 1,\n",
    "    lambda_l1 = .01, #.0, #0.01,\n",
    "    lambda_l2 = .01, #.0, #0.01,\n",
    "    min_gain_to_split = 0,\n",
    "    \n",
    "    #min_data_per_group = 100,\n",
    "    #max_cat_threshold = 32,\n",
    "    #cat_l2 = 10.0,\n",
    "    #cat_smooth = 10.0,\n",
    "    #max_cat_to_onehot = 4,\n",
    "    \n",
    "    #max_bin = 255,\n",
    "    \n",
    "    metric = 'None',\n",
    "    \n",
    "    seed = 44, # Change for better luck! :)\n",
    "    bagging_seed = 45,\n",
    "    feature_fraction_seed = 46,\n",
    "    #data_random_seed = 1,\n",
    ")\n",
    "\n",
    "evals_result = {}\n",
    "bst = lgb.train(lgb_params, L.tr, valid_sets=[L.tr,L.cv], valid_names=['tr','cv'],\n",
    "              feval=lgb_kaggle_metric, evals_result=evals_result, verbose_eval=10)\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame(evals_result['cv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ds, metrics in evals_result.items():\n",
    "#     for m_name, m_list in metrics.items():\n",
    "#         if m_name=='kaggle':\n",
    "#             for i,m in enumerate(m_list):\n",
    "#                 m_list[i] = m % (lgb_kaggle_metric.hack or 1e6)\n",
    "#         else:\n",
    "#             for i,m in enumerate(m_list):\n",
    "#                 m_list[i] *= -1\n",
    "                \n",
    "# canvas(12,6)\n",
    "# fig, (ax0, ax1) = plt.subplots(1,2)\n",
    "# #ax = lgb.plot_metric(evals_result, metric='binary_logloss', ax=ax0);\n",
    "# ax = lgb.plot_metric(evals_result, metric='kaggle', ax=ax1);\n",
    "# canvas(12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P['guess'] = bst.predict(F_)*2-1\n",
    "# P.guess = P.guess*(np.abs(P.guess)>=0.0)\n",
    "\n",
    "# P['trade'] = P.guess*P.upDown1*P.absVal1\n",
    "\n",
    "# daily = P[cv].groupby('time').trade.sum()\n",
    "# print(daily.mean()/daily.std(ddof=0))\n",
    "# plt.hist(daily, bins=80);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~@~@~@~@~@~@~@~@~@~@~ local analysis of performance ~@~@~@~@~@~@~@~@~@~@~@~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +-+-+-+-+-+-+-+-+-+-+-+-+-+-+- Prediction and submission +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define our prdiction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(F):\n",
    "    return bst.predict(F[fSelection]) * 2 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the rest of the administrative pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........500.........510.........520.........530.........540.........550.........560.........570.........580.........590.........600.........610.........620.........630........"
     ]
    }
   ],
   "source": [
    "def do_submission_loop():\n",
    "    feat_iter = iter_features_templates(__env__.get_prediction_days(), U_=(U_,longterm))\n",
    "    for i, (f, p) in enumerate(feat_iter):\n",
    "        print_progress(i)\n",
    "        p.confidenceValue = predict(F=f)\n",
    "        __env__.predict(p)\n",
    "        gc.collect()\n",
    "do_submission_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved. Once you `Commit` your Kernel and it finishes running, you can submit the file to the competition from the Kernel Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "__env__.write_submission_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ LOCAL TESTING ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_pickle('../data/given/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([day[0][['time','assetCode','returnsOpenPrevMktres10']] for day in test], axis=0)\n",
    "X.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Z = pd.concat([day[2] for day in test], axis=0)\n",
    "#Z.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all this cell just to make the target column\n",
    "\n",
    "times = X.time.unique()\n",
    "times10 = np.shift(times, -10)\n",
    "times10map = dict(zip(times,times10))\n",
    "\n",
    "Y = X.copy()\n",
    "Y.time = X.time.map(times10map)\n",
    "next10index = Y[~Y.time.isna()].set_index(['time','assetCode']).index\n",
    "\n",
    "_ans = X.set_index(['time','assetCode']).loc[next10index].returnsOpenPrevMktres10.values\n",
    "_ans = np.pad(_ans, pad_width=(0,len(X)-len(_ans)), mode='constant', constant_values=0.)\n",
    "X['answer'] = _ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['guess'] = __env__._submission.confidenceValue.values * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['universe'] = (~X.answer.isna()) & (np.abs(X.answer) < 2)\n",
    "\n",
    "#X.answer = Z.returnsOpenNextMktres10.values\n",
    "#X.universe = Z.universe.values\n",
    "\n",
    "X['target'] = X.answer > 0\n",
    "X['upDown'] = X.target * 2 - 1\n",
    "X['upDown1'] = X.upDown * X.universe.astype(int)\n",
    "X['absVal'] = np.abs(X.answer)\n",
    "X['absVal1'] = X.absVal * X.universe\n",
    "X['weight'] = X.absVal#.qtl()\n",
    "X['weight1'] = X.weight * X.universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['trade'] = X.guess*X.upDown1*X.absVal1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10556716614607231\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAALBCAYAAABbbWcNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/weUDlIA5KjY5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c6c5460b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lb = X.time < '2018-09-01'\n",
    "daily = X[lb].groupby('time').trade.sum()\n",
    "print(daily.mean()/daily.std(ddof=0))\n",
    "plt.hist(daily, bins=80);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------- SCRATCH ----------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
