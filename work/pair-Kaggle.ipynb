{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# definitely not production code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hashtags: #edit #kill #todo #note #float32 #new #del 1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debug vars: SEE DEBUG TEST PROD BUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from common import *\n",
    "# from pandas.api.types import CategoricalDtype\n",
    "# import warnings \n",
    "# warnings.filterwarnings('ignore')\n",
    "# %matplotlib inline\n",
    "# canvas(12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ho_time = pd.Timestamp('2015-07-01',tz='UTC')\n",
    "\n",
    "# def fake(*,M,N):\n",
    "#     M_, N_ = M, N\n",
    "#     for time, M in M_.groupby('time'):\n",
    "#         if time<ho_time:\n",
    "#             continue\n",
    "#         M['quarter'] = M.time.dt.year+(M.time.dt.quarter-1)/4\n",
    "#         P = M[excluded_columns]\n",
    "#         M = M.drop(columns=['returnsOpenNextMktres10','quarter'])\n",
    "#         P['confidenceValue'] = 0.\n",
    "#         yield M, None, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### important devops code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST = False\n",
    "SEE = lambda*a,**k:None\n",
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #################################################### START HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "M = pd.read_pickle('../data/given/M.pkl') # market obs\n",
    "N = None #pd.read_pickle('../data/given/N.pkl') # news\n",
    "#test = pd.read_pickle('../data/given/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _make_env():\n",
    "    '''this creates a testing version of the actual env from Kaggle kernels'''\n",
    "    class __env__():\n",
    "        _submitted = []\n",
    "        # -1 = begin, 0 = just yielded, 1 = just predicted, -2 = finished, -3 = finished and submission file written too\n",
    "        _states = [-1]\n",
    "\n",
    "        class KaggleEnvError(Exception):\n",
    "            pass\n",
    "\n",
    "        @staticmethod\n",
    "        def get_training_data():\n",
    "            global N\n",
    "            try:\n",
    "                return M, N\n",
    "            except NameError:\n",
    "                return M, None\n",
    "\n",
    "        @staticmethod\n",
    "        def get_prediction_days():\n",
    "            env = __class__\n",
    "\n",
    "            class iter_get_prediction_days():\n",
    "                def __iter__(self):\n",
    "                    if env._states[-1] != -1:\n",
    "                        raise env.KaggleEnvError('can only call get_prediction_days once!')\n",
    "                    \n",
    "                    global test\n",
    "                    test = pd.read_pickle('../data/given/test.pkl')\n",
    "                    env._days_iter = test.__iter__()\n",
    "                    return self\n",
    "\n",
    "                def __next__(self):\n",
    "                    if env._states[-1] == 0:\n",
    "                        raise env.KaggleEnvError('can only yield next day after the previous day was submitted')\n",
    "                    elif env._states[-1] not in [-1, 1, -2, -3]:\n",
    "                        raise env.KaggleEnvError(\n",
    "                            'environment internal error [bad state {} for __next__]'.format(env._states[-1]))\n",
    "\n",
    "                    try:\n",
    "                        ret = env._days_iter.__next__()\n",
    "                    except StopIteration:\n",
    "                        if env._states[-1] not in [-2, -3]:\n",
    "                            env._states.append(-2)\n",
    "                        raise\n",
    "\n",
    "                    env._states.append(0)\n",
    "                    return ret\n",
    "\n",
    "            return iter_get_prediction_days()\n",
    "\n",
    "        @staticmethod\n",
    "        def predict(p):\n",
    "            env = __class__\n",
    "            if env._states[-1] == 1:\n",
    "                raise env.KaggleEnvError('must get next prediction day before submitting a prediction again')\n",
    "            elif env._states[-1] == -1:\n",
    "                raise env.KaggleEnvError('must get next prediction day before submitting a prediction')\n",
    "            elif env._states[-1] in [-2, -3]:\n",
    "                raise env.KaggleEnvError('cannot submit prediction, every prediction has already been submitted')\n",
    "            elif env._states[-1] != 0:\n",
    "                raise env.KaggleEnvError('environment internal error [bad state {}]'.format(env._states[-1]))\n",
    "            env._submitted.append(p)\n",
    "            env._states.append(1)\n",
    "\n",
    "        @staticmethod\n",
    "        def write_submission_file():\n",
    "            env = __class__\n",
    "            if env._states[-1] not in [-2, -3]:\n",
    "                raise env.KaggleEnvError('must be finished predicting before writing submission file')\n",
    "\n",
    "            template = pd.concat((day[2] for day in test), axis=0)\n",
    "            try:\n",
    "                submission = pd.concat((sub for sub in env._submitted), axis=0)\n",
    "                assert (template.shape==submission.shape), 'submissions have malformed shape'\n",
    "                assert (template.index==submission.index).all(), 'submissions have malformed index'\n",
    "                assert (template.columns==submission.columns).all(), 'submissions have malformed columns'\n",
    "                assert (template.assetCode==submission.assetCode).all(), 'submissions have malformed assetCode column'\n",
    "            except Exception as e:\n",
    "                raise env.KaggleEnvError(e)\n",
    "\n",
    "            env._submission = submission\n",
    "            if env._states[-1] != -3:\n",
    "                env._states.append(-3)\n",
    "            print('''Your submission file has been saved. Once you `Commit` your Kernel and it finishes running, '''+\n",
    "                    '''you can submit the file to the competition from the Kernel Viewer `Output` tab.''')\n",
    "    return __env__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__env__ = _make_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #TODO #KILL everything above this here ^^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++ production additions ++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random, math, functools, itertools, os, gc\n",
    "from collections import Counter, namedtuple\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import altair as alt\n",
    "#from altair import *\n",
    "#sns.set()\n",
    "plt.style.use(['classic', 'seaborn', 'seaborn-colorblind'])\n",
    "\n",
    "def canvas(width, height):\n",
    "    dpi = 96\n",
    "    from pylab import rcParams\n",
    "    rcParams['figure.figsize'] = width, height\n",
    "    \n",
    "import lightgbm as lgb\n",
    "import numba\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `utility.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from importlib import reload\n",
    "from functools import wraps, reduce, lru_cache\n",
    "memoized = lru_cache(maxsize=-1, typed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inside(cls, name=None):\n",
    "    '''decorator with one argument that sets the decorated as an attribute of the argument.\n",
    "    also optional argument `name` exists for assigning things that don't automatically get __name__ attribute attached'''\n",
    "    def put_inside(a):\n",
    "        nonlocal name\n",
    "        name = name if name is not None else a.__name__\n",
    "        setattr(cls, name, a)\n",
    "        return a\n",
    "    return put_inside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `object.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell implements Namespace objects. Read the README here https://github.com/yumichael/pytil\n",
    "\n",
    "import collections\n",
    "\n",
    "def _mydict_init_items_(*args, **kwargs):\n",
    "    items = ()\n",
    "    if len(args) == 3:\n",
    "        space = args[2]\n",
    "        for k in list(space.keys()):\n",
    "            if str.startswith(k, '__') and str.endswith(k, '__'):\n",
    "                del space[k]\n",
    "        items = space.items()\n",
    "    elif args and isinstance(args[0], collections.Mapping):\n",
    "        items = args[0].items()\n",
    "    elif args and isinstance(args[0], collections.Iterable):\n",
    "        items = args[0]\n",
    "    if kwargs:\n",
    "        items = chain(items, kwargs.items())\n",
    "    return items\n",
    "\n",
    "def _mydict_pretty_factory_(start='{', end='}', relater=': ', delimiter=',',\n",
    "                            key_action=lambda p, k: p.pretty(k), base=None):\n",
    "    def _repr_pretty_(obj, p, cycle):\n",
    "        nonlocal start, end, relater, delimiter, key_action, base\n",
    "        typ = type(obj)\n",
    "\n",
    "        beginning = typ.__name__ + '(' + start\n",
    "        ending = end + \")\"\n",
    "\n",
    "        if typ is not base and typ.__repr__ != base.__repr__:\n",
    "            # If the subclass provides its own repr, use it instead.\n",
    "            return p.text(typ.__repr__(obj))\n",
    "\n",
    "        if cycle:\n",
    "            return p.text(beginning + '...' + ending)\n",
    "        p.begin_group(1, beginning)\n",
    "        keys = typ.keys(obj)\n",
    "        # if dict isn't large enough to be truncated,\n",
    "        #   sort keys before displaying\n",
    "        if not (p.max_seq_length and len(obj) >= p.max_seq_length):\n",
    "            try:\n",
    "                keys = sorted(keys)\n",
    "            except Exception:\n",
    "                # Sometimes the keys don't sort.\n",
    "                pass\n",
    "        for idx, key in p._enumerate(keys):\n",
    "            if idx:\n",
    "                p.text(delimiter)\n",
    "                p.breakable()\n",
    "            key_action(p, key)\n",
    "            p.text(relater)\n",
    "            p.pretty(obj[key])\n",
    "        p.end_group(1, ending)\n",
    "    return _repr_pretty_\n",
    "\n",
    "def add_mydict_pprinter(*args, **kwargs):\n",
    "    def decorator(cls):\n",
    "        kwds = dict(kwargs)\n",
    "        kwds['base'] = cls\n",
    "        cls._repr_pretty_ = _mydict_pretty_factory_(*args, **kwds)\n",
    "        return cls\n",
    "    return decorator\n",
    "\n",
    "\n",
    "class DefaultSlots(type):\n",
    "    def __new__(meta, name, bases, attrs):\n",
    "        if '__slots__' not in attrs:\n",
    "            attrs['__slots__'] = ()\n",
    "        return super().__new__(meta, name, bases, attrs)\n",
    "\n",
    "@add_mydict_pprinter()\n",
    "class DictObject(dict, metaclass=DefaultSlots):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        data = ((k, v) for k, v in _mydict_init_items_(*args, **kwargs))\n",
    "        super().__init__(data)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"{}({})\".format(type(self).__name__, super().__repr__())\n",
    "\n",
    "    \n",
    "    def __getattribute__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            errstr = \"'{}' object has no attribute '{}'\"\n",
    "            raise AttributeError(errstr.format(type(self).__name__, name))\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "\n",
    "    def __delattr__(self, name):\n",
    "        try:\n",
    "            del self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "@add_mydict_pprinter('', '', '=', ',', lambda p, k: p.text(k))\n",
    "class Namespace(DictObject):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        items = _mydict_init_items_(*args, **kwargs)\n",
    "        data = ((k, v) for k, v in items if isinstance(k, str))\n",
    "        super(__class__, type(self)).__init__(self, data)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if not isinstance(name, str):\n",
    "            errstr = \"{} is not a valid attribute name identifier\"\n",
    "            raise ValueError(errstr.format(name))\n",
    "        self[name] = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        attach = __class__.__repr__\n",
    "        is_orig = False\n",
    "        if not hasattr(attach, '_seen'):\n",
    "            is_orig = True\n",
    "            attach._seen = {}\n",
    "        elif id(self) in attach._seen:\n",
    "            return type(self).__name__ + \"(...)\"\n",
    "        attach._seen[id(self)] = self\n",
    "        try:\n",
    "            it = type(self).items(self)\n",
    "            body = ', '.join(\"{}={}\".format(a, repr(v)) for a, v in it)\n",
    "            return \"{}({})\".format(type(self).__name__, body)\n",
    "        finally:\n",
    "            del attach._seen[id(self)]\n",
    "            if is_orig:\n",
    "                del attach._seen\n",
    "\n",
    "    def mycopy(self, copied={}):\n",
    "        is_orig = not copied\n",
    "        selfc = copied[id(self)] = type(self)()\n",
    "        for key, obj in type(self).items(self):\n",
    "            if isinstance(obj, __class__):\n",
    "                if id(obj) in copied:\n",
    "                    selfc[key] = copied[id(obj)]\n",
    "                else:\n",
    "                    selfc[key] = type(obj).mycopy(obj, copied=copied)\n",
    "            else:\n",
    "                selfc[key] = obj\n",
    "        if is_orig:\n",
    "            copied.clear()\n",
    "        return selfc\n",
    "    \n",
    "    py = lambda o: {str(k): v for k, v in dict.items(o)}\n",
    "\n",
    "def copy(obj):\n",
    "    assert isinstance(obj, Namespace)\n",
    "    return type(obj).mycopy(obj)\n",
    "\n",
    "########################################################################\n",
    "O = Namespace\n",
    "Namespace.__name__ = '<>'\n",
    "\n",
    "class NamedNamespace(Namespace):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if len(args) == 3:\n",
    "            self.__name__ = args[0]\n",
    "    def __repr__(self):\n",
    "        attach = __class__.__repr__\n",
    "        is_orig = False\n",
    "        if not hasattr(attach, '_seen'):\n",
    "            is_orig = True\n",
    "            attach._seen = {}\n",
    "        elif id(self) in attach._seen:\n",
    "            return f\"<{self.__name__}>(...)\"\n",
    "        attach._seen[id(self)] = self\n",
    "        try:\n",
    "            it = type(self).items(self)\n",
    "            body = ', '.join(\"{}={}\".format(a, repr(v)) for a, v in it if a != '__name__')\n",
    "            return f\"<{self.__name__}>({body})\"\n",
    "        finally:\n",
    "            del attach._seen[id(self)]\n",
    "            if is_orig:\n",
    "                del attach._seen\n",
    "NamedO = NamedNamespace\n",
    "NamedO.__name__ = '<>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `combos.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mostly ignore this cell, it's only here because it would be annoying to rework one bit of feature generation code to not\n",
    "# use the code here\n",
    "\n",
    "import itertools\n",
    "import functools\n",
    "import math\n",
    "import operator\n",
    "\n",
    "\n",
    "def binom(n, k):\n",
    "    k = min(k, n - k)\n",
    "    return functools.reduce(lambda a, b: a * (n - b) // (b + 1), range(k), 1)\n",
    "\n",
    "\n",
    "@memoized\n",
    "def consecutive_1s(n):\n",
    "    s = n * (n + 1) // 2\n",
    "    c = np.zeros([s, n], dtype=np.int8)\n",
    "    t = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n + 1):\n",
    "            for k in range(i, j):\n",
    "                c[t, k] = 1\n",
    "            t += 1\n",
    "    return c\n",
    "\n",
    "\n",
    "@memoized\n",
    "def one_minus_one(n):\n",
    "    s = n * (n - 1) // 2\n",
    "    c = np.zeros([s, n], dtype=np.int8)\n",
    "    t = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            c[t, i] = 1\n",
    "            c[t, j] = -1\n",
    "            t += 1\n",
    "    return c\n",
    "\n",
    "\n",
    "@memoized\n",
    "def one_minus_one_skip_by_k(n, k):\n",
    "    m = math.ceil(n / k)\n",
    "    s = m * (m - 1) // 2\n",
    "    c = np.zeros([s, n], dtype=np.int8)\n",
    "    t = 0\n",
    "    for i in range(0,n,k):\n",
    "        for j in range(i + k, n, k):\n",
    "            c[t, i] = 1\n",
    "            c[t, j] = -1\n",
    "            t += 1\n",
    "    return c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@memoized\n",
    "def int_coefficients_mod_sign(n, m, duplicates=True):\n",
    "    guys = []\n",
    "    path = [0]\n",
    "    while True:\n",
    "        while True:\n",
    "            if not path:\n",
    "                return np.stack(guys, axis=0) if guys else np.ndarray([0, n], dtype=np.int8)\n",
    "            path[-1] += 1\n",
    "            if path[-1] == 0:\n",
    "                path[-1] += 1\n",
    "            if path[-1] > m:\n",
    "                path.pop()\n",
    "                continue\n",
    "            if len(path) == n:\n",
    "                break\n",
    "            path.append(-m - 1)\n",
    "        if duplicates or functools.reduce(math.gcd, path) == 1:\n",
    "            guys.append(np.asarray(path, dtype=np.int8))\n",
    "\n",
    "\n",
    "@memoized\n",
    "def up_to_m_int_coefficients_mod_sign(n, m, h, duplicates=True):\n",
    "    guys = []\n",
    "    ident = np.eye(n, dtype=np.int8)\n",
    "    for k in range(1, m + 1):\n",
    "        for x_list in itertools.combinations(ident, k):\n",
    "            for sc in int_coefficients_mod_sign(k, h, duplicates):\n",
    "                guy = sum(x * b for b, x in zip(sc, x_list))\n",
    "                guys.append(guy)\n",
    "    return np.stack(guys, axis=0).astype(np.int8, copy=False)\n",
    "\n",
    "\n",
    "@memoized\n",
    "def consecutive_k_1s(m,k):\n",
    "    assert m%k==0, 'consecutive_k_1s argument m must be divisible by argument k'\n",
    "    n = m // k\n",
    "    s = n * (n + 1) // 2\n",
    "    c = np.zeros([s, k*n], dtype=np.int8)\n",
    "    t = 0\n",
    "    for i in range(0,k*n,k):\n",
    "        for j in range(i + k, k*n + 1, k):\n",
    "            for l in range(i, j):\n",
    "                c[t, l] = 1\n",
    "            t += 1\n",
    "    return c\n",
    "\n",
    "\n",
    "class name(metaclass=O):\n",
    "    def index(c):\n",
    "        assert len(c) < 16\n",
    "        pos, neg = [], []\n",
    "        for i, a in enumerate(c):\n",
    "            assert isinstance(a, np.integer) or isinstance(a, int)\n",
    "            if a != 0:\n",
    "                arr = pos if a > 0 else neg\n",
    "                arr += [i] * abs(a)\n",
    "        strpos = ''.join(hex(i)[2:] for i in pos)\n",
    "        strneg = ''.join(hex(i)[2:] for i in neg)\n",
    "        if not neg:\n",
    "            return strpos\n",
    "        else:\n",
    "            return strpos+'/'+strneg\n",
    "    def consec(c):\n",
    "        assert c.any() and (c!=np.shift(c,-1))[:-1].sum()<=2 # c switches from 0 to something then to 0, or switch less\n",
    "        nonzero = c.nonzero()[0]\n",
    "        i, j = nonzero[0], nonzero[-1]\n",
    "        return '({}..{})^{}'.format(i,j,c[i])\n",
    "\n",
    "\n",
    "def union(*cbs):\n",
    "    assert all(cb.shape[1] == cbs[0].shape[1] for cb in cbs)\n",
    "    seen, the = set(), []\n",
    "    for cb in cbs:\n",
    "        for c in cb:\n",
    "            if tuple(c) not in seen:\n",
    "                the.append(c)\n",
    "                seen.update([tuple(c), tuple(-c)])\n",
    "    return np.stack(the)\n",
    "    \n",
    "    \n",
    "class combos(metaclass=O):\n",
    "    name = name\n",
    "    union = union\n",
    "    c1co = consecutive_1s #(n)\n",
    "    ckco = consecutive_k_1s #(n)\n",
    "    mintco = lambda n, m, h: up_to_m_int_coefficients_mod_sign(n, m, h, False) #(n, m=<max # !=0 coefs>, <max |coef|>)\n",
    "    omo = one_minus_one\n",
    "    omok = one_minus_one_skip_by_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `helper.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lens(*it):\n",
    "    return tuple(len(x) for x in it)\n",
    "def shapes(*arrs):\n",
    "    return tuple(x.shape for x in arrs)\n",
    "def sums(*it):\n",
    "    return tuple(sum(x) for x in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift(a, shift, axis=None):\n",
    "    '''Params - a: np.ndarray\n",
    "                shift: integer, + means entries moved to greater indices, - means entries moved to smaller indices\n",
    "                axis: one integer\n",
    "    Equivalent to pd.DataFrame.shift\n",
    "    '''\n",
    "    if axis is None:\n",
    "        assert len(a.shape)==1, \"Only an array of single dimension can be shifted without specifying axis\"\n",
    "        axis = 0\n",
    "    assert isinstance(axis, int) and isinstance(shift, int)\n",
    "    if not shift:\n",
    "        return a\n",
    "    padding = (shift,0) if shift>0 else (0,-shift)\n",
    "    slicing = slice(None,-shift) if shift>0 else slice(-shift,None)\n",
    "    n = len(a.shape)\n",
    "    axis = n+axis if axis<0 else axis\n",
    "    ret = np.pad(a, ((0,0),)*axis+(padding,)+((0,0),)*(n-axis-1), mode='constant', constant_values=(np.nan,))\n",
    "    ret = ret[(slice(None),)*axis + (slicing,) + (slice(None),)*(n-axis-1)]\n",
    "    return ret\n",
    "np.shift = shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_progress(i, dot=1, numdot=10, print=print):\n",
    "    '''prints dots (.) on loop index at `dot` intervals and prints the actual index on `dot*numdot` intervals'''\n",
    "    print('.' if i // dot % numdot else i, end='', flush=True) if i % dot == 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offdiag = lambda a: a[np.where(~np.eye(a.shape[0],dtype=bool))]\n",
    "nonnans = lambda a: a[np.isfinite(a)]\n",
    "plist = lambda a, **kw: print('['+','.join(str(x) for x in a)+']', **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rolling_window_axis0(a, size, step=1):\n",
    "    '''backward rolling window only\n",
    "    windows dimension will be appended to a.shape (available at index -1)'''\n",
    "    a_ext = np.concatenate(( np.full((step*(size-1),)+a.shape[1:],np.nan), a), axis=0)\n",
    "    n = a_ext.strides[0]\n",
    "    strided = np.lib.stride_tricks.as_strided     \n",
    "    return strided(a_ext, shape=a.shape+(size,), strides=a_ext.strides+(step*n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def only_nans(a):\n",
    "    '''Assume `a` either pd.DataFrame, pd.Series, or np.ndarray\n",
    "    `a` but with all non-NaN values replaced with 0'''\n",
    "    if isinstance(a, pd.DataFrame) or isinstance(a, pd.Series):\n",
    "        return a.isna().replace(True, np.nan)\n",
    "    else:\n",
    "        a = a.copy()\n",
    "        a[~np.isnan(a)] = 0\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wmean(a, weights, axis=0):\n",
    "    '''Params - a: either a {observations}x{features} `DataFrame`/`ndarray` or a 1D `ndarray`\n",
    "                weights: weights of same shape as `a` or else broadcastable to `a`\n",
    "    Weighted mean, with `a.shape` minus the {observations} dimension.'''\n",
    "    w = weights + only_nans(a) #broadcast(weights, only_nans(a), '+')\n",
    "    return np.nansum(a * w, axis=axis) / np.nansum(w, axis=axis)\n",
    "pd.DataFrame.wmean = wmean\n",
    "pd.Series.wmean = wmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class staticclass(type):\n",
    "    '''The staticclass metatype. Use as a metaclass. Will make your class methods static by default.'''\n",
    "    class InstantiationError(Exception):\n",
    "        pass\n",
    "    def __new__(cls, name, parents, attrs):\n",
    "        for k, v in list(dict.items(attrs)):\n",
    "            if not isinstance(v, staticmethod) and callable(v):\n",
    "                attrs[k] = staticmethod(v)\n",
    "        return super(__class__, __class__).__new__(cls, name, parents, attrs)\n",
    "    def __call__(cls, *a, **k):\n",
    "        raise __class__.InstantiationError('cannot instantiate a staticclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ffill_axis0(arr):\n",
    "    '''Forward fill your np.ndarray along the index 0 axis'''\n",
    "    n = len(arr.shape)\n",
    "    mask = np.isnan(arr)\n",
    "    idx = np.where(~mask, np.arange(mask.shape[0])[(slice(None),)+(np.newaxis,)*(n-1)], 0)\n",
    "    np.maximum.accumulate(idx,axis=0, out=idx)\n",
    "    out = arr[(idx,) + tuple(\n",
    "        np.arange(idx.shape[i])[(np.newaxis,)*i+(slice(None),)+(np.newaxis,)*(n-1-i)] for i in range(1, n)\n",
    "    ) ]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stringify_list = lambda a: '[\"'+'\",\"'.join(str(x) for x in a)+'\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "don't forget the others didn't import in `helper.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper code but only for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Bisection algorithms. This is literally just copied from Python Library's bisect module, but numba decorated.\"\"\"\n",
    "@njit\n",
    "def bisect_left(a, x, lo=0, hi=None):\n",
    "    \"\"\"Return the index where to insert item x in list a, assuming a is sorted.\n",
    "    The return value i is such that all e in a[:i] have e < x, and all e in\n",
    "    a[i:] have e >= x.  So if x already appears in the list, a.insert(x) will\n",
    "    insert just before the leftmost x already there.\n",
    "    Optional args lo (default 0) and hi (default len(a)) bound the\n",
    "    slice of a to be searched.\n",
    "    \"\"\"\n",
    "\n",
    "    if lo < 0:\n",
    "        raise ValueError('lo must be non-negative')\n",
    "    if hi is None:\n",
    "        hi = len(a)\n",
    "    while lo < hi:\n",
    "        mid = (lo+hi)//2\n",
    "        if a[mid] < x: lo = mid+1\n",
    "        else: hi = mid\n",
    "    return lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this cell's code is for scrambling a categorical (int) column\n",
    "# basically creates \"random numbers\". just an idea I had where I wanted to get \"random\" but deterministic assetCodeIds\n",
    "\n",
    "@njit\n",
    "def shiftWrap32(num, shift):\n",
    "    d = np.uint8(32)\n",
    "    n = np.uint32(num & 0xFFFFFFFF) # coerce num to a int32 value\n",
    "    i = np.uint8(shift % d) # coerce shift to a int8 value\n",
    "    return np.uint32(n << i) | np.uint32(n >> (d-i))\n",
    "\n",
    "@njit\n",
    "def randomThing(i, j):\n",
    "    return (\n",
    "        ((0x80085111 ^ shiftWrap32(i, j**2)) * \n",
    "        #(0xFA100000 - ~shiftWrap32(i, (j+1)**2))) * \n",
    "        #((0x1337C0DE + shiftWrap32(i, (j+2)**2)) ^ \n",
    "        (0xABCDEF77 ^ shiftWrap32(i, (j+3)**2)))\n",
    "    )\n",
    "\n",
    "@memoized\n",
    "def randMap32(ident):\n",
    "    i = ident\n",
    "    @njit\n",
    "    def func(n):\n",
    "        s = shiftWrap32\n",
    "        x = n\n",
    "        x *= randomThing(i, 777) | 0x5558982A\n",
    "        x += randomThing(i, 263435)\n",
    "        x *= x\n",
    "        x = (x >> 8) + (x << 8)\n",
    "        x ^= randomThing(i, 2000004444)\n",
    "        x *= x\n",
    "        return x\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert32(F):\n",
    "    '''just converts all columns in dataframe `F` into 32-bit dtypes'''\n",
    "    for c in F.columns:\n",
    "        if np.issubdtype(F[c].dtype, np.float):\n",
    "            if F[c].dtype != np.float32:\n",
    "                F[c] = F[c].astype(np.float32)\n",
    "        elif np.issubdtype(F[c].dtype, np.integer):\n",
    "            if F[c].dtype != np.int32:\n",
    "                F[c] = F[c].astype(np.int32)\n",
    "        else:\n",
    "            assert False, 'dtype other than float or int found in features'\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from types import LambdaType\n",
    "\n",
    "class Featurespace(Namespace):\n",
    "    '''This cell defines a Namespace subclass that chooses selectively to evaluate and save its attribute assignments or not.\n",
    "    It is needed because my feature generation code generates A LOT of features, not all of which I want to use.\n",
    "    So the `allow` function filters out features I don't want to use, so as to save memory and time.\n",
    "    \n",
    "    It has its __setitem__ overloaded so that it either takes the actual value, a function -> actual value, or a tuple\n",
    "    of (function -> actual value, function -> next row to append to actual value)\n",
    "    \n",
    "    Also, some features depend on previous features existing, so there is logic to build the dependent features set.\n",
    "    '''\n",
    "    allow = lambda name: True\n",
    "    depend_graph = {}\n",
    "    record_dependency = False\n",
    "    _accessed = set()\n",
    "    \n",
    "    @classmethod\n",
    "    def build_dependency(cls):\n",
    "        stack = list(filter(cls.allow, cls.depend_graph))\n",
    "        seen = set(stack)\n",
    "        cls.depends = set(stack)\n",
    "        while stack:\n",
    "            name = stack.pop()\n",
    "            for next in cls.depend_graph.get(name, frozenset()):\n",
    "                if next not in seen:\n",
    "                    stack.append(next)\n",
    "                    seen.add(next)\n",
    "                    cls.depends.add(next)\n",
    "    \n",
    "    def __getitem__(self, name):\n",
    "        cls = type(self)\n",
    "        if cls.record_dependency:\n",
    "            cls._accessed.add(name)\n",
    "        return super(__class__, type(self)).__getitem__(self, name)\n",
    "    \n",
    "    def __getattribute__(self, name):\n",
    "        cls = type(self)\n",
    "        if cls.record_dependency:\n",
    "            cls._accessed.add(name)\n",
    "        return super(__class__, type(self)).__getattribute__(self, name)\n",
    "    \n",
    "    def __setitem__(self, name, value):\n",
    "        cls = type(self)\n",
    "        \n",
    "        if hasattr(cls, 'depends'):\n",
    "            care = name in cls.depends\n",
    "        else:\n",
    "            care = cls.allow(name)\n",
    "        if not cls.record_dependency and not care:\n",
    "            return\n",
    "        \n",
    "        if isinstance(value, LambdaType):\n",
    "            ans = super(__class__, type(self)).__setitem__(self, name, value())\n",
    "        elif isinstance(value,tuple) and len(value)==2 and all(isinstance(value[i],LambdaType) for i in range(2)):\n",
    "            if name not in self:\n",
    "                ans = super(__class__, type(self)).__setitem__(self, name, value[0]())\n",
    "            else:\n",
    "                changed = np.concatenate([self[name], value[1]()[np.newaxis]], axis=0)\n",
    "                ans = super(__class__, type(self)).__setitem__(self, name, changed)\n",
    "        else:\n",
    "            ans = super(__class__, type(self)).__setitem__(self, name, value)\n",
    "            \n",
    "        if cls.record_dependency:\n",
    "            assert name not in cls.depend_graph, 'each name in Featurespace should only be assigned once'\n",
    "            cls.depend_graph[name] = frozenset(cls._accessed)\n",
    "            cls._accessed = set()\n",
    "            \n",
    "        return ans\n",
    "OX = Featurespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## %%%%%%%%%%% requirements check for main prediction code: %%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok go\n"
     ]
    }
   ],
   "source": [
    "__env__\n",
    "O\n",
    "gc\n",
    "canvas\n",
    "print(\"ok go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================== MAIN PREDICTION CODE ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BUG = O() # put stuff in this that you want to see for debugging needs\n",
    "\n",
    "%matplotlib inline\n",
    "canvas(12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M, N = __env__.get_training_data()\n",
    "del N; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bit of a hack of the previouly LB securing random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO #KILL? this should not be in the production code\n",
    "# this was an old feature of the scrambled assetCodeIds that I could not regenerate programmatically any more\n",
    "dfHack2 = pd.read_csv('dfHack2Str.csv', index_col='assetCodeId',\n",
    "                      dtype={'assetCodeId':np.int,'assetCodeIdWTFFlogabs':np.float32,'assetCodeIdWTFFsin2':np.float32})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/ Model Definitions ~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!!!!!!!!!!!!!!!!! BEGIN code that you should not read because it just defines the old InitKaggleGo features\n",
    "fTransNewfault = [\"volume\",\"close\",\"open\",\"assetCodeId\",\"assetNameId\",\"cc\",\"oo\",\"acc\",\"aoo\",\"ccTEN\",\"ooTEN\",\"accTEN\",\"aooTEN\",\"dayOfYear\",\"dayOfWeek\",\"oo1Since21\",\"oo1MaxSince21\",\"oo1Drawdown1Since21\",\"oo1Drawdown5Since21\",\"oo1Drawdown10Since21\",\"oo1MaxSince21{10}\",\"oo1MinSince21\",\"oo1MinSince21{10}\",\"oo1Since62\",\"oo1MaxSince62\",\"oo1Drawdown1Since62\",\"oo1Drawdown5Since62\",\"oo1Drawdown10Since62\",\"oo1MaxSince62{10}\",\"oo1MinSince62\",\"oo1MinSince62{10}\",\"oo1Since125\",\"oo1MaxSince125\",\"oo1Drawdown1Since125\",\"oo1Drawdown5Since125\",\"oo1Drawdown10Since125\",\"oo1MaxSince125{10}\",\"oo1MinSince125\",\"oo1MinSince125{10}\",\"oo1Since250\",\"oo1MaxSince250\",\"oo1Drawdown1Since250\",\"oo1Drawdown5Since250\",\"oo1Drawdown10Since250\",\"oo1MaxSince250{10}\",\"oo1MinSince250\",\"oo1MinSince250{10}\",\"aoo1Since21\",\"aoo1MaxSince21\",\"aoo1Drawdown1Since21\",\"aoo1Drawdown5Since21\",\"aoo1Drawdown10Since21\",\"aoo1MaxSince21{10}\",\"aoo1MinSince21\",\"aoo1MinSince21{10}\",\"aoo1Since62\",\"aoo1MaxSince62\",\"aoo1Drawdown1Since62\",\"aoo1Drawdown5Since62\",\"aoo1Drawdown10Since62\",\"aoo1MaxSince62{10}\",\"aoo1MinSince62\",\"aoo1MinSince62{10}\",\"aoo1Since125\",\"aoo1MaxSince125\",\"aoo1Drawdown1Since125\",\"aoo1Drawdown5Since125\",\"aoo1Drawdown10Since125\",\"aoo1MaxSince125{10}\",\"aoo1MinSince125\",\"aoo1MinSince125{10}\",\"aoo1Since250\",\"aoo1MaxSince250\",\"aoo1Drawdown1Since250\",\"aoo1Drawdown5Since250\",\"aoo1Drawdown10Since250\",\"aoo1MaxSince250{10}\",\"aoo1MinSince250\",\"aoo1MinSince250{10}\",\"oo5\",\"oo10\",\"oo15\",\"oo20\",\"oo(10-5)\",\"oo(15-5)\",\"oo(20-5)\",\"oo(15-10)\",\"oo(20-10)\",\"oo(20-15)\",\"aoo5\",\"aoo10\",\"aoo15\",\"aoo20\",\"aoo(10-5)\",\"aoo(15-5)\",\"aoo(20-5)\",\"aoo(15-10)\",\"aoo(20-10)\",\"aoo(20-15)\",\"(it,af,it{1},aoo,acc){3/4}\"]\n",
    "fTransNewnewfault = fTransNewfault[:-1] + ['(aoo-acc)']\n",
    "fTime = 'dayOfYear dayOfWeek'.split()\n",
    "fAsset = 'assetCodeId assetNameId'.split()\n",
    "fPriceAbsolute = 'close open'.split()\n",
    "def select_relative(f):\n",
    "    return f not in set(fTime+fAsset+fPriceAbsolute)\n",
    "fInitKaggleGo = list(filter(select_relative, fTransNewnewfault)) + ['assetCodeIdWTFFlogabs', 'assetCodeIdWTFFsin2']\n",
    "# _fMust = ['oo','(oo-aoo)','(cc-acc)','(oo-cc)','(aoo-acc)','vp1dd']\n",
    "# fMustInclude = _fMust+[c+'1' for c in _fMust]+[c+'*' for c in _fMust]\n",
    "# fMustInclude += 'af it aoo acc'.split()\n",
    "class ikg(NamedO()):\n",
    "    features = fInitKaggleGo\n",
    "    train_on = [2009.,2009.75,2010.75,2011.5,2012.25,2012.5,2012.75,2013.,2013.25,2013.75,2014.,2014.25,2015.]\n",
    "    weight = 'flat_weight'\n",
    "    params = dict(early_stopping_round=50,learning_rate=.05,num_leaves=1<<12,max_depth=12,min_data_in_leaf=150,min_sum_hessian_in_leaf=50,lambda_l1=.01,lambda_l2=.01)\n",
    "_ikg = ikg; del ikg\n",
    "#!!!!!!!!!!!!!!!!!!!!!! END code that you should not read\n",
    "\n",
    "fullhouse = [2010.,2010.25,2010.5,2010.75,\n",
    "             2011.,2011.25,2011.5,2011.75,\n",
    "             2012.,2012.25,2012.5,2012.75,\n",
    "             2013.,2013.25,2013.5,2013.75,\n",
    "             2014.,2014.25,2014.5,2014.75,\n",
    "             2015.,2015.25,#2015.5,2015.75,\n",
    "             #2016.,2016.25,2016.5,2016.75,\n",
    "             ]\n",
    "\n",
    "class bstdefs(O()):\n",
    "    '''Each item under here fully defines a model\n",
    "        features = the list of feature names\n",
    "        train_on = the quarters that LightGBM should train on\n",
    "        weight = the name of the weight to use\n",
    "        params = LGBM params (in addition to default)\n",
    "    '''\n",
    "    ikg = _ikg # the InitKaggleGo model\n",
    "    class IKGCover(NamedO()):\n",
    "        features = [\"assetCodeId\",\"volume\",\"cc\",\"oo\",\"acc\",\"aoo\",\"oo5\",\"oo10\",\"oo15\",\"aoo5\",\"aoo10\",\"aoo15\",\"af\",\"it\",\"rr\",\"oo(10-5)\",\"oo(15-10)\",\"oo(20-15)\",\"oo(15-5)\",\"oo(20-10)\",\"oo(20-5)\",\"aoo(10-5)\",\"aoo(15-10)\",\"aoo(20-15)\",\"aoo(15-5)\",\"aoo(20-10)\",\"aoo(20-5)\",\"af{1}\",\"it{1}\",\"(it,af,it{1},aoo,acc){0/1}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/1}\",\"(it,af,it{1},aoo,acc){0/2}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/2}\",\"(it,af,it{1},aoo,acc){0/3}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/3}\",\"(it,af,it{1},aoo,acc){0/4}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/4}\",\"(it,af,it{1},aoo,acc){1/2}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){1/2}\",\"(it,af,it{1},aoo,acc){1/3}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){1/3}\",\"(it,af,it{1},aoo,acc){1/4}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){1/4}\",\"(it,af,it{1},aoo,acc){2/3}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){2/3}\",\"(it,af,it{1},aoo,acc){2/4}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){2/4}\",\"oo1Since21\",\"oo1MaxSince21\",\"oo1Drawdown1Since21\",\"oo1Drawdown5Since21\",\"oo1Drawdown10Since21\",\"oo1MinSince21\",\"oo1MinSince21{10}\",\"aoo1Since21\",\"aoo1MaxSince21\",\"aoo1Drawdown1Since21\",\"aoo1Drawdown5Since21\",\"aoo1Drawdown10Since21\",\"aoo1MinSince21\",\"aoo1MinSince21{10}\",\"oo1Since62\",\"oo1MaxSince62\",\"oo1Drawdown1Since62\",\"oo1Drawdown5Since62\",\"oo1Drawdown10Since62\",\"oo1MinSince62\",\"oo1MinSince62{10}\",\"aoo1Since62\",\"aoo1MaxSince62\",\"aoo1Drawdown1Since62\",\"aoo1Drawdown5Since62\",\"aoo1Drawdown10Since62\",\"aoo1MinSince62\",\"aoo1MinSince62{10}\",\"oo1Since125\",\"oo1MaxSince125\",\"oo1Drawdown1Since125\",\"oo1Drawdown5Since125\",\"oo1Drawdown10Since125\",\"oo1MinSince125\",\"oo1MinSince125{10}\",\"aoo1Since125\",\"aoo1MaxSince125\",\"aoo1Drawdown1Since125\",\"aoo1Drawdown5Since125\",\"aoo1Drawdown10Since125\",\"aoo1MinSince125\",\"aoo1MinSince125{10}\",\"oo1Since250\",\"oo1MaxSince250\",\"oo1Drawdown1Since250\",\"oo1Drawdown5Since250\",\"oo1Drawdown10Since250\",\"oo1MinSince250\",\"oo1MinSince250{10}\",\"aoo1Since250\",\"aoo1MaxSince250\",\"aoo1Drawdown1Since250\",\"aoo1Drawdown5Since250\",\"aoo1Drawdown10Since250\",\"aoo1MinSince250\",\"aoo1MinSince250{10}\",\"assetCode_inUniCount\"]\n",
    "        feats_ctor = '\\n    <>~Market & (\\n        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&\\n            <>(oo|cc|aoo|acc|daoc)\\n            & index[0]\\n          }\\n        | Return{.&pure&~index} & ~Since & Return{.&\\n            <>(oo|aoo)\\n            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]\\n          }\\n        | (\\n            <>Return{(oo{.&[1:]}|aoo[1:])}\\n            & (\\n                <> ~Drawdown&~Drawup&~Since{Min}&~Since{Max}\\n                | Drawdown[1:, 5:,10:]\\n                | Since{Max&index[0]}\\n                | Since{Min&index[0,10]}\\n              )\\n            & Since[21:,62:,125:,250:]\\n          )\\n      )\\n    |\\n        <>AssetEnc{InUni}\\n        | AssetEnc{Code}\\n    |\\n        <>FaceValue{Volume}\\n        | Return{mix[1,2,3,4,5,6,7,8,9,11,12,13,14,15,16,17,18,19]}\\n        | Return{rr|af|it}\\n    '\n",
    "        train_on = fullhouse\n",
    "        weight = 'flat_weight'\n",
    "        params = dict(num_iterations=450,learning_rate=0.05,max_depth=-1,num_leaves=4096,min_data_in_leaf=120,min_sum_hessian_in_leaf=100,lambda_l1=0,lambda_l2=0)\n",
    "    class IKGCoverHomo(NamedO()):\n",
    "        features = [\"volume\",\"cc\",\"oo\",\"acc\",\"aoo\",\"oo5\",\"oo10\",\"oo15\",\"aoo5\",\"aoo10\",\"aoo15\",\"af\",\"it\",\"rr\",\"oo(10-5)\",\"oo(15-10)\",\"oo(20-15)\",\"oo(15-5)\",\"oo(20-10)\",\"oo(20-5)\",\"aoo(10-5)\",\"aoo(15-10)\",\"aoo(20-15)\",\"aoo(15-5)\",\"aoo(20-10)\",\"aoo(20-5)\",\"af{1}\",\"it{1}\",\"(it,af,it{1},aoo,acc){0/1}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/1}\",\"(it,af,it{1},aoo,acc){0/2}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/2}\",\"(it,af,it{1},aoo,acc){0/3}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/3}\",\"(it,af,it{1},aoo,acc){0/4}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/4}\",\"(it,af,it{1},aoo,acc){1/2}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){1/2}\",\"(it,af,it{1},aoo,acc){1/3}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){1/3}\",\"(it,af,it{1},aoo,acc){1/4}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){1/4}\",\"(it,af,it{1},aoo,acc){2/3}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){2/3}\",\"(it,af,it{1},aoo,acc){2/4}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){2/4}\",\"oo1Since21\",\"oo1MaxSince21\",\"oo1Drawdown1Since21\",\"oo1Drawdown5Since21\",\"oo1Drawdown10Since21\",\"oo1MinSince21\",\"oo1MinSince21{10}\",\"aoo1Since21\",\"aoo1MaxSince21\",\"aoo1Drawdown1Since21\",\"aoo1Drawdown5Since21\",\"aoo1Drawdown10Since21\",\"aoo1MinSince21\",\"aoo1MinSince21{10}\",\"oo1Since62\",\"oo1MaxSince62\",\"oo1Drawdown1Since62\",\"oo1Drawdown5Since62\",\"oo1Drawdown10Since62\",\"oo1MinSince62\",\"oo1MinSince62{10}\",\"aoo1Since62\",\"aoo1MaxSince62\",\"aoo1Drawdown1Since62\",\"aoo1Drawdown5Since62\",\"aoo1Drawdown10Since62\",\"aoo1MinSince62\",\"aoo1MinSince62{10}\",\"oo1Since125\",\"oo1MaxSince125\",\"oo1Drawdown1Since125\",\"oo1Drawdown5Since125\",\"oo1Drawdown10Since125\",\"oo1MinSince125\",\"oo1MinSince125{10}\",\"aoo1Since125\",\"aoo1MaxSince125\",\"aoo1Drawdown1Since125\",\"aoo1Drawdown5Since125\",\"aoo1Drawdown10Since125\",\"aoo1MinSince125\",\"aoo1MinSince125{10}\",\"oo1Since250\",\"oo1MaxSince250\",\"oo1Drawdown1Since250\",\"oo1Drawdown5Since250\",\"oo1Drawdown10Since250\",\"oo1MinSince250\",\"oo1MinSince250{10}\",\"aoo1Since250\",\"aoo1MaxSince250\",\"aoo1Drawdown1Since250\",\"aoo1Drawdown5Since250\",\"aoo1Drawdown10Since250\",\"aoo1MinSince250\",\"aoo1MinSince250{10}\"]\n",
    "        feats_ctor = '\\n    <>~Market & (\\n        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&\\n            <>(oo|cc|aoo|acc|daoc)\\n            & index[0]\\n          }\\n        | Return{.&pure&~index} & ~Since & Return{.&\\n            <>(oo|aoo)\\n            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]\\n          }\\n        | (\\n            <>Return{(oo{.&[1:]}|aoo[1:])}\\n            & (\\n                <> ~Drawdown&~Drawup&~Since{Min}&~Since{Max}\\n                | Drawdown[1:, 5:,10:]\\n                | Since{Max&index[0]}\\n                | Since{Min&index[0,10]}\\n              )\\n            & Since[21:,62:,125:,250:]\\n          )\\n      )\\n    |\\n        <>FaceValue{Volume}\\n        | Return{mix[1,2,3,4,5,6,7,8,9,11,12,13,14,15,16,17,18,19]}\\n        | Return{rr|af|it}\\n    '\n",
    "        train_on = fullhouse\n",
    "        weight = 'flat_weight'\n",
    "        params = dict(num_iterations=450,learning_rate=0.05,max_depth=-1,num_leaves=4096,min_data_in_leaf=120,min_sum_hessian_in_leaf=100,lambda_l1=0,lambda_l2=0)\n",
    "    class pIKGCoverHomo(NamedO()):\n",
    "        Pair = O(hi=None, lo=(.6,500), repeat=3)\n",
    "        copy_features = [\"volume\",\"cc\",\"oo\",\"acc\",\"aoo\",\"oo5\",\"oo10\",\"oo15\",\"aoo5\",\"aoo10\",\"aoo15\",\"af\",\"it\",\"rr\",\"oo(10-5)\",\"oo(15-10)\",\"oo(20-15)\",\"oo(15-5)\",\"oo(20-10)\",\"oo(20-5)\",\"aoo(10-5)\",\"aoo(15-10)\",\"aoo(20-15)\",\"aoo(15-5)\",\"aoo(20-10)\",\"aoo(20-5)\",\"af{1}\",\"it{1}\",\"(it,af,it{1},aoo,acc){0/1}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/1}\",\"(it,af,it{1},aoo,acc){0/2}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/2}\",\"(it,af,it{1},aoo,acc){0/3}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/3}\",\"(it,af,it{1},aoo,acc){0/4}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/4}\",\"(it,af,it{1},aoo,acc){1/2}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){1/2}\",\"(it,af,it{1},aoo,acc){1/3}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){1/3}\",\"(it,af,it{1},aoo,acc){1/4}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){1/4}\",\"(it,af,it{1},aoo,acc){2/3}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){2/3}\",\"(it,af,it{1},aoo,acc){2/4}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){2/4}\",\"oo1Since21\",\"oo1MaxSince21\",\"oo1Drawdown1Since21\",\"oo1Drawdown5Since21\",\"oo1Drawdown10Since21\",\"oo1MinSince21\",\"oo1MinSince21{10}\",\"aoo1Since21\",\"aoo1MaxSince21\",\"aoo1Drawdown1Since21\",\"aoo1Drawdown5Since21\",\"aoo1Drawdown10Since21\",\"aoo1MinSince21\",\"aoo1MinSince21{10}\",\"oo1Since62\",\"oo1MaxSince62\",\"oo1Drawdown1Since62\",\"oo1Drawdown5Since62\",\"oo1Drawdown10Since62\",\"oo1MinSince62\",\"oo1MinSince62{10}\",\"aoo1Since62\",\"aoo1MaxSince62\",\"aoo1Drawdown1Since62\",\"aoo1Drawdown5Since62\",\"aoo1Drawdown10Since62\",\"aoo1MinSince62\",\"aoo1MinSince62{10}\",\"oo1Since125\",\"oo1MaxSince125\",\"oo1Drawdown1Since125\",\"oo1Drawdown5Since125\",\"oo1Drawdown10Since125\",\"oo1MinSince125\",\"oo1MinSince125{10}\",\"aoo1Since125\",\"aoo1MaxSince125\",\"aoo1Drawdown1Since125\",\"aoo1Drawdown5Since125\",\"aoo1Drawdown10Since125\",\"aoo1MinSince125\",\"aoo1MinSince125{10}\",\"oo1Since250\",\"oo1MaxSince250\",\"oo1Drawdown1Since250\",\"oo1Drawdown5Since250\",\"oo1Drawdown10Since250\",\"oo1MinSince250\",\"oo1MinSince250{10}\",\"aoo1Since250\",\"aoo1MaxSince250\",\"aoo1Drawdown1Since250\",\"aoo1Drawdown5Since250\",\"aoo1Drawdown10Since250\",\"aoo1MinSince250\",\"aoo1MinSince250{10}\"]\n",
    "        diff_features = [\"volume\",\"cc\",\"oo\",\"acc\",\"aoo\",\"oo5\",\"oo10\",\"oo15\",\"aoo5\",\"aoo10\",\"aoo15\",\"af\",\"it\",\"rr\",\"oo(10-5)\",\"oo(15-10)\",\"oo(20-15)\",\"oo(15-5)\",\"oo(20-10)\",\"oo(20-5)\",\"aoo(10-5)\",\"aoo(15-10)\",\"aoo(20-15)\",\"aoo(15-5)\",\"aoo(20-10)\",\"aoo(20-5)\",\"af{1}\",\"it{1}\",\"(it,af,it{1},aoo,acc){0/1}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/1}\",\"(it,af,it{1},aoo,acc){0/2}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/2}\",\"(it,af,it{1},aoo,acc){0/3}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/3}\",\"(it,af,it{1},aoo,acc){0/4}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){0/4}\",\"(it,af,it{1},aoo,acc){1/2}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){1/2}\",\"(it,af,it{1},aoo,acc){1/3}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){1/3}\",\"(it,af,it{1},aoo,acc){1/4}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){1/4}\",\"(it,af,it{1},aoo,acc){2/3}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){2/3}\",\"(it,af,it{1},aoo,acc){2/4}\",\"(it{1},af{1},it{2},aoo{1},acc{1}){2/4}\",\"oo1Since21\",\"oo1MaxSince21\",\"oo1Drawdown1Since21\",\"oo1Drawdown5Since21\",\"oo1Drawdown10Since21\",\"oo1MinSince21\",\"oo1MinSince21{10}\",\"aoo1Since21\",\"aoo1MaxSince21\",\"aoo1Drawdown1Since21\",\"aoo1Drawdown5Since21\",\"aoo1Drawdown10Since21\",\"aoo1MinSince21\",\"aoo1MinSince21{10}\",\"oo1Since62\",\"oo1MaxSince62\",\"oo1Drawdown1Since62\",\"oo1Drawdown5Since62\",\"oo1Drawdown10Since62\",\"oo1MinSince62\",\"oo1MinSince62{10}\",\"aoo1Since62\",\"aoo1MaxSince62\",\"aoo1Drawdown1Since62\",\"aoo1Drawdown5Since62\",\"aoo1Drawdown10Since62\",\"aoo1MinSince62\",\"aoo1MinSince62{10}\",\"oo1Since125\",\"oo1MaxSince125\",\"oo1Drawdown1Since125\",\"oo1Drawdown5Since125\",\"oo1Drawdown10Since125\",\"oo1MinSince125\",\"oo1MinSince125{10}\",\"aoo1Since125\",\"aoo1MaxSince125\",\"aoo1Drawdown1Since125\",\"aoo1Drawdown5Since125\",\"aoo1Drawdown10Since125\",\"aoo1MinSince125\",\"aoo1MinSince125{10}\",\"oo1Since250\",\"oo1MaxSince250\",\"oo1Drawdown1Since250\",\"oo1Drawdown5Since250\",\"oo1Drawdown10Since250\",\"oo1MinSince250\",\"oo1MinSince250{10}\",\"aoo1Since250\",\"aoo1MaxSince250\",\"aoo1Drawdown1Since250\",\"aoo1Drawdown5Since250\",\"aoo1Drawdown10Since250\",\"aoo1MinSince250\",\"aoo1MinSince250{10}\"]\n",
    "        sign_features = []\n",
    "        corr_features = []\n",
    "        feats_ctor = '\\n    <>~Market & (\\n        <>Return{.&pure&~digit&~TEN} & ~Since & Return{.&\\n            <>(oo|cc|aoo|acc|daoc)\\n            & index[0]\\n          }\\n        | Return{.&pure&~index} & ~Since & Return{.&\\n            <>(oo|aoo)\\n            & [5:,10:,15:,10:5,15:10,20:15,15:5,20:10,20:5]\\n          }\\n        | (\\n            <>Return{(oo{.&[1:]}|aoo[1:])}\\n            & (\\n                <> ~Drawdown&~Drawup&~Since{Min}&~Since{Max}\\n                | Drawdown[1:, 5:,10:]\\n                | Since{Max&index[0]}\\n                | Since{Min&index[0,10]}\\n              )\\n            & Since[21:,62:,125:,250:]\\n          )\\n      )\\n    |\\n        <>FaceValue{Volume}\\n        | Return{mix[1,2,3,4,5,6,7,8,9,11,12,13,14,15,16,17,18,19]}\\n        | Return{rr|af|it}\\n    '\n",
    "        train_on = fullhouse\n",
    "        weight = 'pair_weight'\n",
    "        params = dict(num_iterations=250,learning_rate=0.05,max_depth=-1,num_leaves=4096,min_data_in_leaf=120,min_sum_hessian_in_leaf=20,lambda_l1=0,lambda_l2=0)\n",
    "_bd = bstdefs\n",
    "for name in _bd:\n",
    "    if 'feats_ctor' in _bd[name]:\n",
    "        _bd[name].feats_ctor = f\"<{name}>\"+_bd[name].feats_ctor\n",
    "\n",
    "def _get_allowed(model):\n",
    "    if hasattr(model, 'features'):\n",
    "        return model.features\n",
    "    else:\n",
    "        return model.copy_features+model.diff_features+model.sign_features\n",
    "        \n",
    "class themodel(O()):\n",
    "    '''this defines the model blending'''\n",
    "    solo = O(specs=[_bd.IKGCover], coefs=[1])\n",
    "    pair = O(specs=[_bd.pIKGCoverHomo], coefs=[.33])\n",
    "    xAllowed = reduce(operator.__or__,\n",
    "        [frozenset(_get_allowed(s)) for s,c in chain(zip(solo.specs,solo.coefs), zip(pair.specs,pair.coefs)) if c!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as a note, I sometimes begin a variable name with x, like 'xAllowed', and this just means it's a set (speeds up lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/~/ END Model Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### very important ID assignment code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IdAssign:\n",
    "    '''This class assigns an integer (>=0) ID to things.\n",
    "    It automatically updates the count when it sees a new thing without an ID before.\n",
    "    \n",
    "    `self.series` gives you a pd.Series where index=ID and the column values give you the original value\n",
    "    Using `self` as a function maps values to their IDs\n",
    "    '''\n",
    "    class NO_MISSING(metaclass=staticclass): # special filler value because `None` might actually be meaningfully used\n",
    "        pass\n",
    "    def __init__(self, init, missing, name):\n",
    "        self.name = name\n",
    "        self.map = {}\n",
    "        if missing is not __class__.NO_MISSING:\n",
    "            self.map[missing] = -1\n",
    "        i = 0\n",
    "        for x in init:\n",
    "            if x not in self.map and x != missing:\n",
    "                self.map[x] = i\n",
    "                i += 1\n",
    "        self.cache = None\n",
    "    def __call__(self, key):\n",
    "        if key not in self.map:\n",
    "            self.map[key] = len(self.map)\n",
    "        return self.map[key]\n",
    "    def __len__(self):\n",
    "        return self.map.__len__()\n",
    "    @property\n",
    "    def series(self):\n",
    "        if self.cache==len(self):\n",
    "            return self._series\n",
    "        # Python 3.?+ guarantees that dict keys and values are itered in same order, and that order is insertion order\n",
    "        self._series = pd.Series(list(self.map.keys()), index=list(self.map.values()), name=self.name)\n",
    "        self._series.index.name = self.name+'Id'\n",
    "        self.cache = len(self)\n",
    "        return self._series\n",
    "\n",
    "assetCodeSeries = pd.Series(M.assetCode.unique())\n",
    "assetCodeIdAssign = IdAssign(assetCodeSeries, missing='', name='assetCode')\n",
    "del assetCodeSeries\n",
    "assetNameSeries = pd.Series(M.assetName.unique())\n",
    "assetNameIdAssign = IdAssign(assetNameSeries, missing='Unknown', name='assetName')\n",
    "del assetNameSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some data specific helper func/structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stringify_columns = stringify_list\n",
    "\n",
    "returns_columns = { # I map these guys from linear space to log space, and make them into shorter names\n",
    "    'returnsClosePrevRaw1':'cc', 'returnsOpenPrevRaw1':'oo',\n",
    "    'returnsClosePrevMktres1':'acc', 'returnsOpenPrevMktres1':'aoo',\n",
    "    'returnsClosePrevRaw10':'ccTEN','returnsOpenPrevRaw10':'ooTEN',\n",
    "    'returnsClosePrevMktres10':'accTEN','returnsOpenPrevMktres10':'aooTEN'\n",
    "}\n",
    "columns_for_U = set(returns_columns.values()) | set(['open', 'close', 'volume'])\n",
    "excluded_columns = [\n",
    "    'time','assetCode','assetName','universe','returnsOpenNextMktres10','quarter','y'\n",
    "]\n",
    "exclusion_filter = lambda c: c not in excluded_columns\n",
    "object_columns = ['assetCode', 'assetName']\n",
    "enumeration_columns = ['assetCodeId', 'assetNameId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### hard coded constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_start_time = pd.Timestamp('2009-01-01',tz='UTC')\n",
    "lookback = 60\n",
    "shortterm = 21\n",
    "longterm = 250 + lookback*2 #idk it's hard to reason about how much I _really_ need, so this should be pretty safe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setting up only the stocks that we have seen in-universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M['assetCodeId'] = M.assetCode.map(assetCodeIdAssign).astype(int)\n",
    "inUniCount = M[M.time>=train_start_time].groupby('assetCodeId').universe.sum()\n",
    "stocksInUni = (inUniCount != 0).pipe(lambda x: x.index[x])\n",
    "assert stocksInUni.is_monotonic\n",
    "xStocksInUni = set(stocksInUni) #EDITCELL\n",
    "inUniCountSeries = inUniCount.astype(float) #EDITCELL\n",
    "stocksAlways = (inUniCount >= 1981).pipe(lambda x: x.index[x])\n",
    "xStocksAlways = set(stocksAlways)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_basic_features(*,M):\n",
    "    M['assetCodeId'] = M.assetCode.map(assetCodeIdAssign)#.astype(int) # much more efficient to process everything as float\n",
    "    del M['assetCode']\n",
    "    M['assetNameId'] = M.assetName.map(assetNameIdAssign)#.astype(int)\n",
    "    del M['assetName']\n",
    "    for orig_col, new_col in returns_columns.items():\n",
    "        M[new_col] = np.log1p(M[orig_col])\n",
    "        del M[orig_col]\n",
    "    # time features\n",
    "    M['dayOfYear'] = M.time.dt.dayofyear.astype(float)\n",
    "    M['dayOfWeek'] = M.time.dt.dayofweek.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_P(*, F, P, vp=True, always=True):\n",
    "    P['quarter'] = P.time.dt.year+(P.time.dt.quarter-1)/4\n",
    "    P['target'] = P.y>0\n",
    "    P['upDown'] = (P.target*2-1)\n",
    "    P['absVal'] = np.abs(P.y)\n",
    "    P['flat_weight'] = P.absVal\n",
    "    if vp:\n",
    "        P['vp1_weight'] = P.absVal*F.vp1/1e9\n",
    "        P['vp5_weight'] = P.absVal*F.vp5/1e9\n",
    "        P['vp10_weight'] = P.absVal*F.vp10/1e9\n",
    "        P['vp20_weight'] = P.absVal*F.vp20/1e9\n",
    "    if always:\n",
    "        P['always_weight'] = P.absVal*F.assetCodeId.isin(xStocksAlways)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making correlations data for pair trading !!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def offdiag_items(ix, x, y):\n",
    "    m, n = x.shape\n",
    "    assert (m, n) == y.shape\n",
    "    assert m == n\n",
    "    assert (m,) == ix.shape\n",
    "    t = (n**2-n) // 2\n",
    "    I = np.full(t, -1, dtype=np.int64)\n",
    "    J = np.full(t, -1, dtype=np.int64)\n",
    "    X = np.full(t, 0, dtype=x.dtype)\n",
    "    Y = np.full(t, 0, dtype=y.dtype)\n",
    "    k = -1\n",
    "    for i in range(m):\n",
    "        for j in range(i+1, n):\n",
    "            k += 1\n",
    "            I[k] = ix[i]\n",
    "            J[k] = ix[j]\n",
    "            X[k] = x[i,j]\n",
    "            Y[k] = y[i,j]\n",
    "    return I, J, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_W_D():\n",
    "    Mt = M[M.time>=train_start_time]\n",
    "    set_basic_features(M=Mt)\n",
    "    ##########################\n",
    "    W = O()\n",
    "    W.y1 = Mt[['time','assetCodeId','oo']].pivot('time','assetCodeId').oo\n",
    "    W.ay1 = Mt[['time','assetCodeId','aoo']].pivot('time','assetCodeId').aoo\n",
    "    W.y10 = Mt[['time','assetCodeId','ooTEN']].pivot('time','assetCodeId').ooTEN\n",
    "    W.ay10 = Mt[['time','assetCodeId','aooTEN']].pivot('time','assetCodeId').aooTEN\n",
    "    W.y20 = W.y10 + W.y10.shift(10)\n",
    "    W.ay20 = W.ay10 + W.ay10.shift(10)\n",
    "    W.u = Mt[['time','assetCodeId','universe']].pivot('time','assetCodeId').universe.fillna(0).astype(int)\n",
    "    # for c in W:\n",
    "    #     W[c] = W[c][W[c].index>=train_start_time]\n",
    "    del Mt; gc.collect()\n",
    "    ##################################\n",
    "    C = O()\n",
    "    #C.y1 = W.y1.corr()\n",
    "    #C.ay1 = W.ay1.corr()\n",
    "    #C.y10 = W.y10.corr()\n",
    "    C.ay10 = W.ay10.corr()\n",
    "    C.u = W.u.T @ W.u\n",
    "    #############################\n",
    "    D = O()\n",
    "    #D.v1 = pd.DataFrame(dict(zip([0, 1, 'Corr', 'Unic'], offdiag_items(C.y1.index.values, C.y1.values, C.u.values))))\n",
    "    #D.av1 = pd.DataFrame(dict(zip([0, 1, 'Corr', 'Unic'], offdiag_items(C.ay1.index.values, C.ay1.values, C.u.values))))\n",
    "    #D.v10 = pd.DataFrame(dict(zip([0, 1, 'Corr', 'Unic'], offdiag_items(C.y10.index.values, C.y10.values, C.u.values))))\n",
    "    D.av10 = pd.DataFrame(dict(zip([0, 1, 'Corr', 'Unic'], offdiag_items(C.ay10.index.values, C.ay10.values, C.u.values))))\n",
    "    for c in ['av10']:#['v1','av1','v10','av10']:\n",
    "        D[c] = D[c][D[c].Unic!=0]\n",
    "        D[c].sort_values('Corr', ascending=False, inplace=True)\n",
    "    del C; gc.collect()\n",
    "    return W, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_search = bisect_left\n",
    "\n",
    "@njit\n",
    "def index_unique_pairs(A, B, values, repeat):\n",
    "    assert len(A)==len(B)\n",
    "    seen = [0] * len(values)\n",
    "    ans = []\n",
    "    for i, (a, b) in enumerate(zip(A, B)):\n",
    "        ia = binary_search(values, a); ib = binary_search(values, b);\n",
    "        if repeat==-1 or (seen[ia]<repeat and seen[ib]<repeat):\n",
    "            seen[ia] += 1; seen[ib] += 1;\n",
    "            ans.append(i)\n",
    "    return ans\n",
    "\n",
    "def make_unique_pairs(*, Dl, repeat=-1):\n",
    "    if repeat==-1:\n",
    "        return Dl\n",
    "    ii = index_unique_pairs(Dl[0].values, Dl[1].values, sorted(set(Dl[0].values)|set(Dl[1].values)), repeat=repeat)\n",
    "    return Dl.iloc[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_CC_G_Q_from_Dl_F_P_W(*, Dl, F, P, W, lo, hi=None, repeat=-1,\n",
    "                              roll_corr=list(product(['ay1','ay10','ay20'],[10,21,62,250]))):\n",
    "    global TRAIN\n",
    "    SEE(f'(pair) len(F.columns) = {len(F.columns)}')\n",
    "    \n",
    "    D = Dl\n",
    "    allTime = pd.Series(P.time.unique())\n",
    "    allTime.index = allTime\n",
    "    \n",
    "    # |begin| subset the pairs list\n",
    "    if hi is None:\n",
    "        hi = (1., 9999)\n",
    "    D = D[(lo[0]<=D.Corr)&(D.Corr<=hi[0])&(lo[1]<=D.Unic)&(D.Unic<=hi[1])]\n",
    "    if isinstance(repeat, int):\n",
    "        D = D.pipe(lambda x: make_unique_pairs(Dl=x, repeat=repeat))\n",
    "        w = (D.Corr.fillna(0)*0 + 1.).values\n",
    "    elif repeat=='prop':\n",
    "        D01 = D\n",
    "        D10 = D[[1,0,'Corr','Unic']]\n",
    "        D2 = pd.concat([D01,D10], axis=0)\n",
    "        aw = D2.groupby(0).Corr.sum()\n",
    "        w = (D.Corr / np.maximum(D[0].map(aw), D[1].map(aw))).values\n",
    "        w /= w.mean()\n",
    "    else:\n",
    "        assert False\n",
    "    if TRAIN:\n",
    "        hgt = sum(p[-1] for p in D.itertuples())\n",
    "        CC = np.zeros((hgt,2+len(roll_corr)))\n",
    "        G0, G1 = np.zeros((hgt,len(F.columns))), np.zeros((hgt,len(F.columns)))\n",
    "    else:\n",
    "        CC = []\n",
    "        G0, G1 = [], []\n",
    "    Q0, Q1 = [], []\n",
    "    # |end| subset the pairs list\n",
    "    \n",
    "    i = 0\n",
    "    SEE(f'(pair) generating [{len(D)}]', end='')\n",
    "    for ii, ((_,a0,a1,corr,unic), weight) in enumerate(zip(D.itertuples(),w)):\n",
    "        print_progress(ii, dot=10, print=SEE)\n",
    "        assert len(weight.shape)==0\n",
    "        BUG.F, BUG.P, BUG.a0, BUG.a1 = F, P, a0, a1\n",
    "        in0, in1 = (F.assetCodeId==a0)&(P.universe!=0), (F.assetCodeId==a1)&(P.universe!=0)\n",
    "        A0, A1 = F[in0], F[in1]\n",
    "        B0, B1 = P[in0], P[in1]\n",
    "        inTime = set(B0.time)&set(B1.time)\n",
    "        tm0, tm1 = B0.time.isin(inTime), B1.time.isin(inTime)\n",
    "        A0, A1 = A0[tm0], A1[tm1]\n",
    "        B0, B1 = B0[tm0], B1[tm1]\n",
    "        \n",
    "        tm = allTime.isin(inTime).values\n",
    "        def iter_roll_corr():\n",
    "            for y, r in roll_corr:\n",
    "                yield W[y][a0].rolling(window=r, min_periods=5).corr(W[y][a1])[tm] #TODO hard coded min_periods\n",
    "        unic_ = [np.ones_like(W[next(iter(W))].iloc[:,0][tm])*unic]\n",
    "        weight_ = [np.ones_like(W[next(iter(W))].iloc[:,0][tm])*weight]\n",
    "        C = np.stack(chain(iter_roll_corr(),unic_,weight_), axis=1)\n",
    "        \n",
    "        if TRAIN:\n",
    "            G0[i:i+unic], G1[i:i+unic] = A0.values, A1.values\n",
    "            CC[i:i+unic] = C\n",
    "        else:\n",
    "            G0.append(A0); G1.append(A1);\n",
    "            CC.append(C)\n",
    "        Q0.append(B0); Q1.append(B1);\n",
    "        \n",
    "        i += unic\n",
    "    SEE()\n",
    "    \n",
    "    Fcols = F.columns\n",
    "    del Dl, F, P, W; gc.collect()\n",
    "        \n",
    "    Q0, Q1 = pd.concat(Q0, axis=0), pd.concat(Q1, axis=0)\n",
    "    if TRAIN:\n",
    "        G0, G1 = pd.DataFrame(G0), pd.DataFrame(G1)\n",
    "    else:\n",
    "        G0, G1 = pd.concat(G0, axis=0), pd.concat(G1, axis=0)\n",
    "        CC = np.concatenate(CC, axis=0)\n",
    "    G0.index = Q0.index; G1.index = Q1.index;\n",
    "    G0.columns = Fcols; G1.columns = Fcols;\n",
    "    CC = pd.DataFrame(CC, columns=[f'__corr__{y}_{r}' for y,r in roll_corr]+['bothInUniCount','weight'])\n",
    "    return CC, (G0,G1), (Q0,Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_FG_PQ_from_CC_G_Q(copy_filter, diff_filter, sign_filter, corr_filter, *, CC, G, Q):\n",
    "    SEE('(pair) putting together...', end=' ')\n",
    "    \n",
    "    weight = CC['weight'].values\n",
    "    \n",
    "    Gcols, Qcols = G[0].columns, Q[0].columns\n",
    "    assert (Gcols==G[1].columns).all() and (Qcols==Q[1].columns).all()\n",
    "    \n",
    "    \n",
    "    cop, dif, sgn = list(filter(copy_filter, Gcols)), list(filter(diff_filter, Gcols)), list(filter(sign_filter, Gcols))\n",
    "    G0, G1 = G[0][cop].values, G[1][cop].values\n",
    "    H01 = G[0][dif].values - G[1][dif].values\n",
    "    I01 = G[0][sgn].values > G[1][sgn].values; I10 = G[1][sgn].values > G[0][sgn].values;\n",
    "    CC = CC[list(filter(corr_filter, CC.columns))]\n",
    "    \n",
    "    F01, F10 = np.concatenate([G0,G1,H01,I01,CC.values], axis=1), np.concatenate([G1,G0,-H01,I10,CC.values], axis=1)\n",
    "    FG = np.concatenate([F01, F10], axis=0)\n",
    "    if not np.issubdtype(FG.dtype, np.float):\n",
    "        FG = FG.astype(np.float32)\n",
    "    \n",
    "    FGcols = (['__0__'+c for c in cop] + ['__1__'+c for c in cop] + ['__0-1__'+c for c in dif]\n",
    "              + ['__0>1__'+c for c in sgn] + list(CC.columns))\n",
    "    FG = pd.DataFrame(FG, columns=FGcols, copy=False)\n",
    "    \n",
    "    \n",
    "    Q = Q[0].reset_index(drop=True), Q[1].reset_index(drop=True)\n",
    "    assert(Q[0].time==Q[1].time).all()\n",
    "    \n",
    "    Q01 = pd.DataFrame(dict(time=Q[0].time, y=Q[0].y-Q[1].y,\n",
    "                            **{f'__0__{c}': Q[0][c] for c in ['assetCode','assetName','universe']},\n",
    "                            **{f'__1__{c}': Q[1][c] for c in ['assetCode','assetName','universe']}))\n",
    "    Q10 = pd.DataFrame(dict(time=Q[1].time, y=Q[1].y-Q[0].y,\n",
    "                            **{f'__0__{c}': Q[1][c] for c in ['assetCode','assetName','universe']},\n",
    "                            **{f'__1__{c}': Q[0][c] for c in ['assetCode','assetName','universe']}))\n",
    "    \n",
    "    PQ = pd.concat([Q01, Q10], axis=0, ignore_index=True)\n",
    "    PQ['pair_weight'] = np.concatenate([weight, weight], axis=0)\n",
    "    \n",
    "    PQ.sort_values('time', inplace=True)\n",
    "    FG = FG.reindex(index=PQ.index, copy=False)\n",
    "    \n",
    "    FG.reset_index(drop=True, inplace=True)\n",
    "    PQ.reset_index(drop=True, inplace=True)\n",
    "    setup_P(F=None, P=PQ, vp=False, always=False)\n",
    "    \n",
    "    SEE('(pair) done')\n",
    "    return FG, PQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE definitive features generators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_rollwind = rolling_window_axis0\n",
    "\n",
    "def noinf_log(a):\n",
    "    '''np.log, but makes maps 0 => np.nan instead of -np.inf'''\n",
    "    ret = np.log(a)\n",
    "    if len(ret.shape)==0:\n",
    "        return ret if not np.isneginf(ret) else np.nan\n",
    "    ret[np.isneginf(ret)] = np.nan\n",
    "    return ret\n",
    "\n",
    "def _vol(a, axis, fill):\n",
    "    '''helper that calculates the volatility'''\n",
    "    var = np.nanvar(a, axis=axis, ddof=1) # ddof=1 for better estimate\n",
    "    nsamps = np.maximum(np.count_nonzero(~np.isnan(a), axis=axis) - 1, 0)\n",
    "    # weight by global average to help curb extreme values when cumulating in features constructed from this\n",
    "    return np.sqrt((var * np.expm1(nsamps) + fill**2) / (np.expm1(nsamps) + 1))\n",
    "_vol.fill = lambda r: np.sqrt(r) / 22 # these approximate the global average std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below until the next header are the main feature generation functions.\n",
    "\n",
    "To save myself time I use single capital letter variables to denote very specific entities\n",
    "\n",
    "- M = a DataFrame like the original given market obs\n",
    "- U = an O that maps feature name => np.ndarray of shape ({days up to current day}, {all the stocks, in assetCodeId order})\n",
    "  - The features are stored in this format to be able to generate lag and drawdown features\n",
    "- u = an O that maps feature name => np.ndarray of shape ({all the stocks, in assetCodeId order},)\n",
    "  - These features we don't care about past entries, so only the present day value is included acorss the stocks\n",
    "- V = an O that maps feature name => np.ndarray of shape ({days up to current day},)\n",
    "  - These are global (across stocks) features that we need to look back in time for\n",
    "- v = an O that maps feature name => numbers\n",
    "  - It's just one number which is the current value of this global feature on the current day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_shortterm_price_features(*,U,u):\n",
    "    # volume*price ############################################################################\n",
    "    # just the volume*price. it is maximally NaN\n",
    "    U['vp'] = lambda: U.volume * U.open, lambda: U.volume[-1] * U.open[-1]\n",
    "    \n",
    "    # the 1 suffix means there is a best attempt at cleaning up the NaNs and is start of a series of things spanning n days\n",
    "    U['vp1'] = lambda: ffill_axis0(U['vp']), lambda: ffill_axis0(U['vp'][-2:])[-1]\n",
    "    # volume*price meaned over h days\n",
    "    for h in [5,10]:\n",
    "        U[f'vp{h}'] = lambda: np.nanmean(_rollwind(U.vp1, h), axis=-1), lambda: np.nanmean(U.vp1[-h:], axis=0)\n",
    "    for h in [20,60]:\n",
    "        u[f'vp{h}'] = lambda: np.nanmean(U.vp1[-h:], axis=0)\n",
    "        \n",
    "    # volume*price day-to-day over h days # 'dd' means \"day-to-day\". it is the \"return\" equivalent for volume*price\n",
    "    for h in [1,5,10]:\n",
    "        U[f'vp{h}dd1'] = (lambda: noinf_log(U[f'vp{h}']) - noinf_log(np.shift(U[f'vp{h}'],1,axis=0)),\n",
    "                          lambda: noinf_log(U[f'vp{h}'][-1]) - noinf_log(U[f'vp{h}'][-2]))\n",
    "    \n",
    "    #######################\n",
    "    # just because this wasn't defined for us in `make_single_A_...`\n",
    "    U['(oo-aoo)1'] = lambda: U.oo1 - U.aoo1\n",
    "    \n",
    "    # SHORT TERM COMBOS ######################################################################################\n",
    "    for ww in ['oo','aoo','(oo-aoo)','vp1dd','vp5dd','volatility']:\n",
    "        ww1 = ww+'1'\n",
    "        #! size 5 combos in this section\n",
    "        if 'olatility' not in ww:\n",
    "            for i in [5,10,15, 3,6,9,12,18]: # the (i-0) time slices needed by other calcs\n",
    "                U[ww+str(i)] = lambda: np.nansum(_rollwind(U[ww1],i), axis=-1), lambda: np.nansum(U[ww1][-i:], axis=0)\n",
    "            for i in [20,60]: # the (i-0) time slices not needed by others\n",
    "                u[ww+str(i)] = lambda: np.nansum(U[ww1][-i:], axis=0)\n",
    "        else:\n",
    "            for r in [5,10,15,20,60, 3,6,9,12,18]:\n",
    "                U['volatility'+str(r)] = (lambda: _vol(_rollwind(U.oo,r), axis=-1, fill=_vol.fill(r)),\n",
    "                                          lambda: _vol(U.oo[-r:], axis=0, fill=_vol.fill(r)))\n",
    "        for r,d in zip([5,10,15, 3,6,9,12,18], [5]*3+[3]*5): # lagged guys\n",
    "            i = 1\n",
    "            while r+d*i <= 21:\n",
    "                u[f'{ww}({r+d*i}-{d*i})'] = lambda: U[f'{ww}{r}'][-1-i*d]\n",
    "                i += 1\n",
    "        \n",
    "    #================================================== LEGACY ============================================================\n",
    "    T = OX()\n",
    "    ################################################################# can be NaNs:\n",
    "    U['(oo-aoo)'] = lambda: U.oo - U.aoo\n",
    "    U['(cc-acc)'] = lambda: U.cc - U.acc\n",
    "    U['(oo-cc)'] = lambda: U.oo - U.cc\n",
    "    U['(aoo-acc)'] = lambda: U.aoo - U.acc\n",
    "    for ww in ['oo','(oo-aoo)','(cc-acc)','(oo-cc)','(aoo-acc)','vp1dd']:\n",
    "        T[ww+'Window*'] = lambda: np.flip( (U[ww] if ww in U else U[ww+'*'] if ww+'*' in U else U[ww+'1']) ,axis=0)[:3]\n",
    "        window = lambda: T[ww+'Window*']\n",
    "        for c in combos.union(combos.omo(3),combos.mintco(3,1,1)):\n",
    "            name = '{}{{{}}}'.format(ww, combos.name.index(c))\n",
    "            if name[-3:]=='{0}':\n",
    "                name = name[:-3]\n",
    "            if name not in U and name not in u:\n",
    "                u[name] = lambda: c@window()\n",
    "    ################################################################# can be NaNs: # mostly still here for legacy reasons\n",
    "    log_open, log_close = np.log(U.open), np.log(U.close) # can be NaNs here\n",
    "    U['af'] = lambda: log_open - np.shift(log_close,1,axis=0)\n",
    "    U['it'] = lambda: log_close - log_open\n",
    "    U['rr'] = lambda: log_open - np.shift(log_open,1,axis=0)\n",
    "    u['af{1}'] = lambda: U.af[-2]\n",
    "    u['it{1}'] = lambda: U.it[-2]\n",
    "    \n",
    "    T['near0*'] = lambda: np.stack([U.it[-1],U.af[-1],U.it[-2],U.aoo[-1],U.acc[-1]], axis=0); near0 = lambda: T['near0*']\n",
    "    T['near1*'] = lambda: np.stack([U.it[-2],U.af[-2],U.it[-3],U.aoo[-2],U.acc[-2]], axis=0); near1 = lambda: T['near1*']\n",
    "    for c in combos.omo(5):\n",
    "        name = '(it,af,it{{1}},aoo,acc){{{}}}'.format(combos.name.index(c))\n",
    "        u[name] = lambda: c@near0()\n",
    "        name = '(it{{1}},af{{1}},it{{2}},aoo{{1}},acc{{1}}){{{}}}'.format(combos.name.index(c))\n",
    "        u[name] = lambda: c@near1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _add_minmax_pools(ww, h, lag, *, Z, z): #.-`~,-'~.-`~,-'~.-`~,-'~.-`~,-'~ HELPER FUNCTION!\n",
    "    strh = str(h)\n",
    "    T = OX()\n",
    "    \n",
    "    guy = lambda: Z[ww][-h:]\n",
    "    if lag == 0: # includes the case when we have 'volatility'\n",
    "        T[f'{ww}Since{strh}*'] = lambda: guy(); since = lambda: T[f'{ww}Since{strh}*']\n",
    "    else:\n",
    "        T[f'{ww}Since{strh}*'] = lambda: np.nancumsum(guy(), axis=0); since = lambda: T[f'{ww}Since{strh}*']\n",
    "        z[f'{ww}Since{strh}'] = lambda: since()[-1]\n",
    "        \n",
    "    \n",
    "    for mm, MM, flag, updown, nanfunc in [('max','Max',-np.inf,'down',np.nanmin), ('min','Min',np.inf,'up',np.nanmax)]:\n",
    "        def _mmSince():\n",
    "            sinceForMM = since().copy()\n",
    "            sinceForMM[np.isnan(since())] = flag\n",
    "            mmSince = (np.maximum if mm=='max' else np.minimum).accumulate(sinceForMM, axis=0)\n",
    "            mmSince[mmSince==flag] = np.nan\n",
    "            return mmSince\n",
    "        T[f'{ww}{MM}Since{strh}*'] = _mmSince; mmSince = lambda: T[f'{ww}{MM}Since{strh}*']\n",
    "        z[f'{ww}{MM}Since{strh}'] = lambda: mmSince()[-1]\n",
    "        \n",
    "        T[ww+f'Draw{updown}1Since{strh}*'] = lambda:since()-mmSince(); drawSince = lambda:T[ww+f'Draw{updown}1Since{strh}*']\n",
    "        z[f'{ww}Draw{updown}1Since{strh}'] = lambda: drawSince()[-1]\n",
    "        \n",
    "        # if mm=='max' Drawdown is negative so we take np.nanmin; if mm=='min' Drawup is positive so we take np.nanmax;\n",
    "        z[f'{ww}Draw{updown}5Since{strh}'] = lambda: nanfunc(drawSince()[-5:], axis=0)\n",
    "        z[f'{ww}Draw{updown}10Since{strh}'] = lambda: nanfunc(drawSince()[-10:], axis=0)\n",
    "        z[f'{ww}Draw{updown}20Since{strh}'] = lambda: nanfunc(drawSince()[-20:], axis=0)\n",
    "        z[f'{ww}Draw{updown}(10-5)Since{strh}'] = lambda: nanfunc(drawSince()[-10:-5], axis=0)\n",
    "        z[f'{ww}Draw{updown}(20-10)Since{strh}'] = lambda: nanfunc(drawSince()[-20:-10], axis=0)\n",
    "        z[f'{ww}{MM}Since{strh}{{5}}'] = lambda: mmSince()[-6]\n",
    "        z[f'{ww}{MM}Since{strh}{{10}}'] = lambda: mmSince()[-11]\n",
    "        z[f'{ww}{MM}Since{strh}{{20}}'] = lambda: mmSince()[-21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_longterm_price_features(*,U,u,horizons=[21,62,125,250]):\n",
    "    # longterm return horizons ################################################################ oo + aoo already in mm_pool\n",
    "#     for ww in ['oo','aoo','(oo-aoo)']:\n",
    "#         U[ww+'60'] = lambda: np.nansum(_rollwind(U[ww+'20'],3,20), axis=-1), lambda: np.nansum(U[ww+'20'][-41::20], axis=0)\n",
    "#         u[ww+'120'] = lambda: np.nansum(U[ww+'60'][-61::60], axis=0)\n",
    "    # MINMAX POOLS ################################################################### no NaNs\n",
    "    for h in horizons:\n",
    "        ##### historical liquity #NEW\n",
    "        u['fracRecordedDaysSince'+str(h)] = lambda: (~np.isnan(U.volume[-h:])).sum(axis=0) / h\n",
    "        ##### drawdowns and drawups\n",
    "        for ww, lag in [('oo1',1),('aoo1',1),('(oo-aoo)1',1), ('oo10',10),('aoo10',10),('(oo-aoo)10',10),\n",
    "                        ('vp1dd1',1),('vp5dd1',1),('vp10dd1',1), ('volatility10',0),('volatility20',0)]:\n",
    "            _add_minmax_pools(ww, h, Z=U, z=u, lag=lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_global_price_features(*,U,u,V,v,horizons=[21,62,125,250]):\n",
    "    ''''m_' prefix means \"market\", i.e. averaged (weights uniform) across the market at each time\n",
    "    'wVPm_' prefix means \"market, weighted by volume*price\"'''\n",
    "#     V['m_vp1dd1'] = (lambda: noinf_log(V.m_vp1) - noinf_log(np.shift(V.m_vp1,1,axis=0)),\n",
    "#                      lambda: noinf_log(V.m_vp1[-1]) - noinf_log(V.m_vp1[-2]))\n",
    "    ################################################################## market returns, no NaNs #NEW\n",
    "    V['m_vp5_'] = lambda: noinf_log( np.nansum(U.vp5, axis=1) ), lambda: noinf_log( np.nansum(U.vp5[-1]) )\n",
    "    V['m_vp5dd1'] = lambda: V.m_vp5_ - np.shift(V.m_vp5_,1,axis=0), lambda: V.m_vp5_[-1] - V.m_vp5_[-2]\n",
    "    V['m_oo1'] = (lambda: noinf_log( np.nanmean( np.exp(U.oo1) , axis=1) ),\n",
    "                  lambda: noinf_log( np.nanmean( np.exp(U.oo1[-1]) ) ))\n",
    "    V['wVPm_oo1'] = (lambda: noinf_log( wmean( np.exp(U.oo1) , np.shift(U.vp1,1,axis=0), axis=1) ),\n",
    "                     lambda: noinf_log( wmean( np.exp(U.oo1[-1]) , U.vp1[-2]) ))\n",
    "    for i in [5,10,20,60]:\n",
    "        s = str(i) \n",
    "        # this 'm_oo{i}' is first taking returns over horizon for each stock, then averaging uniformly across market\n",
    "        if i < 20:\n",
    "            v['m_oo'+s] = lambda: noinf_log( np.nanmean( np.exp(U['oo'+s][-1]) ) )\n",
    "        else:\n",
    "            v['m_oo'+s] = lambda: noinf_log( np.nanmean( np.exp(u['oo'+s]) ) )\n",
    "        # we are doing log change of average 5 day volume*price speard globally\n",
    "        v['m_vp5dd'+s] = lambda: V.m_vp5_[-1] - V.m_vp5_[-1-i]\n",
    "        # 'wVPm_' returns are first averaged horizontally across market, then averaged vertically across time using\n",
    "        # changing market volume*price weight, and this is somewhat necessary because volume*price changes across time\n",
    "        v['wVPm_oo'+s] = lambda: np.nansum(V.wVPm_oo1[-i:])\n",
    "        # volatility here. just, straightforward calc off the global returns\n",
    "        v['m_volatility'+s] = lambda: np.nanstd(V.m_oo1[-i:])\n",
    "        v['wVPm_volatility'+s] = lambda: np.nanstd(V.wVPm_oo1[-i:])\n",
    "    ########################################################################\n",
    "#     for h in horizons:\n",
    "#         strh = str(h)\n",
    "#         for ww, lag in [('m_vp1dd1',1),('m_vp5dd1',1),('m_oo1',1),('m_oo10',10),('wVPm_oo1',1),('wVPm_oo10',10),\n",
    "#                         ('m_volatility10',0),('m_volatility20',0),('wVPm_volatility10',0),('wVPm_volatility20',0)]:\n",
    "#             _add_minmax_pools(ww, h, Z=V, z=v, lag=lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_postprocessing_features(*,F):\n",
    "    ################## systematic assetCode encodings ####################\n",
    "    F['assetCode_inUniCount'] = F.assetCodeId.map(inUniCountSeries)\n",
    "    \n",
    "    ############# random assetCode encodings ################################\n",
    "    for i in range(1,11):\n",
    "        F['assetCode_randMap32_'+str(i**2)] = F.assetCodeId.map(randMap32(i**2)).astype(float)\n",
    "    #F['assetCodeIdWTFlogabs'] = F.assetCodeId.map(str).map(hash).pipe(np.abs).pipe(np.log)\n",
    "    #F['assetCodeIdWTFsin2'] = F.assetCodeId.map(str).map(hash).pipe(np.sin).pipe(lambda x: x * x)\n",
    "    F['assetCodeIdWTFFlogabs'] = F.assetCodeId.map(dfHack2.assetCodeIdWTFFlogabs)\n",
    "    F['assetCodeIdWTFFsin2'] = F.assetCodeId.map(dfHack2.assetCodeIdWTFFsin2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some rather unfortunate hack-like code to reliably generate features day-by-day follows until the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honestly don't bother trying to understand the code from here up till the header \"**HELLO READ THIS**\"\n",
    "\n",
    "It's all just plumbing work to get the feature generation code above to work in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_single_A_U_u_V_v(*,M):\n",
    "    '''M needs to assetCodeId indexed'''\n",
    "    assert M.index.name == 'assetCodeId', \"argument to make_single_A_U_u_V_v must be assetCodeId-indexed\"\n",
    "    A = pd.DataFrame(index=stocksInUni).join(M, how='left') #EDITLINE\n",
    "    #^ A = join onto standard assetCode row-index\n",
    "    U = OX(**{c:A[c].values[np.newaxis,:] for c in columns_for_U},\n",
    "          **{c+'1':np.nan_to_num(A[c].values[np.newaxis,:]) for c in set(returns_columns.values())})\n",
    "    if OX.record_dependency:\n",
    "        for c in (c for c in U if c not in OX.depend_graph):\n",
    "            U[c] = U[c] # for building dependency graph\n",
    "    return A, U, OX(), OX(), OX()\n",
    "\n",
    "def make_U(*,M):\n",
    "    Us = [make_single_A_U_u_V_v(M=m.set_index('assetCodeId'))[1] for _,m in M.groupby('time')]\n",
    "    U = OX(**{c:np.concatenate([U[c] for U in Us],axis=0) for c in Us[0]})\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a minimal initial run of feature generation to get the static list of columns of interest and\n",
    "# also generate feature dependency and the set of features to allow\n",
    "OX.allow = lambda x: x in themodel.xAllowed\n",
    "\n",
    "Minit = M[M.time<=M.time.unique()[longterm]]\n",
    "set_basic_features(M=Minit)\n",
    "Uinit = make_U(M=Minit)\n",
    "\n",
    "OX.record_dependency = True; OX.depend_graph = {}\n",
    "\n",
    "uinit = OX()\n",
    "BUG.U0_keys = set(dict.keys(Uinit))\n",
    "add_shortterm_price_features(U=Uinit,u=uinit)\n",
    "add_longterm_price_features(U=Uinit,u=uinit)\n",
    "Vinit, vinit = OX(), OX()\n",
    "add_global_price_features(U=Uinit,u=uinit,V=Vinit,v=vinit)\n",
    "\n",
    "OX.record_dependency = False; OX.build_dependency()\n",
    "\n",
    "Mcolumns = [c for c in Minit.columns if c not in excluded_columns]\n",
    "xMcolumns = set(Mcolumns)\n",
    "Ucolumns = [c for c in Uinit if c not in Mcolumns and c[-1] not in '*_' and c in OX.depends]\n",
    "ucolumns = [c for c in uinit if c not in Mcolumns and c[-1] not in '*_' and c in OX.depends]\n",
    "Vcolumns = [c for c in Vinit if c not in Mcolumns and c[-1] not in '*_' and c in OX.depends]\n",
    "vcolumns = [c for c in vinit if c not in Mcolumns and c[-1] not in '*_' and c in OX.depends]\n",
    "xUcolumns,xucolumns,xVcolumns,xvcolumns = [set(C) for C in [Ucolumns,ucolumns,Vcolumns,vcolumns]]\n",
    "for i, a in enumerate([xUcolumns,xucolumns,xVcolumns,xvcolumns]):\n",
    "    for j, b in enumerate([xUcolumns,xucolumns,xVcolumns,xvcolumns]):\n",
    "        assert a is b or len(a&b)==0, f'a and b: {i} {j}'\n",
    "\n",
    "del Minit,Uinit,uinit,Vinit,vinit; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_features_templates(MNP_iter, *, U_, V_, train=False):\n",
    "    U_, termU = U_\n",
    "    V_, termV = V_\n",
    "    for M, N, P in MNP_iter:\n",
    "        orig_index = M.index\n",
    "        set_basic_features(M=M) # adds \"long\" features and deletes non-log price features\n",
    "        M.set_index('assetCodeId', inplace=True)\n",
    "        A, U, u, V, v = make_single_A_U_u_V_v(M=M); del V\n",
    "        \n",
    "        assert BUG.U0_keys==set(dict.keys(U))\n",
    "        M.drop(columns=[c for c in M.columns if c not in xMcolumns], inplace=True)\n",
    "        \n",
    "        try:\n",
    "            akey = next(iter(U))\n",
    "            assert U[akey].shape[1] == U_[akey].shape[1]\n",
    "            # expand rows in old U_ if new assetCodeIds were seen #NOTE don't need this anymore, decided to only use inUni assets\n",
    "    #         akey = next(iter(U))\n",
    "    #         diff = U[akey].shape[1] - U_[akey].shape[1]\n",
    "    #         if diff > 0:\n",
    "    #             for key in U_:\n",
    "    #                 if key[-1] != '_': # normal features\n",
    "    #                     U_[key] = np.pad(U_[key], pad_width=((0,0),(0,diff)), mode='constant', constant_values=np.nan)\n",
    "    #                 else: # NaN-filled-with-0 features\n",
    "    #                     U_[key] = np.pad(U_[key], pad_width=((0,0),(0,diff)), mode='constant', constant_values=0)\n",
    "        except StopIteration: # no features in U\n",
    "            pass\n",
    "        \n",
    "        # join new row vectors in U to the old tables in U_\n",
    "        for key in U:\n",
    "            U_[key] = np.concatenate([U_[key],U[key]], axis=0)\n",
    "        xsingleUcolumns = set(U); del U\n",
    "        \n",
    "        # retain dimensions of U_ and V_ objects for sanity check after feature generation\n",
    "        _U_shape, _V_shape = {k:x.shape for k,x in dict.items(U_)}, {k:x.shape for k,x in dict.items(V_)}\n",
    "        \n",
    "        # add features to U_ and u and V and v\n",
    "        gc.collect()\n",
    "        add_shortterm_price_features(U=U_,u=u)\n",
    "        gc.collect()\n",
    "        add_longterm_price_features(U=U_,u=u)\n",
    "        gc.collect()\n",
    "        add_global_price_features(U=U_,u=u,V=V_,v=v)\n",
    "        gc.collect()\n",
    "        assert len(set(U_)&set(u))==0 and len(set(V_)&set(v))==0\n",
    "        \n",
    "        # run time check that the shape of the U things are ok\n",
    "        ##############################################BEGIN####CHECK####################################################\n",
    "        #dict.update(BUG, U=U,U_=U_,V_=V_,u=u,v=v,_U_shape=_U_shape,_V_shape=_V_shape)\n",
    "#         assert all(c in xMcolumns or c[-1] in '*_' for c in set(U_)^xUcolumns), (\n",
    "#             '!F! columns found in U_ not in Ucolumns must be in Mcolumns or end in exclusion suffixes')\n",
    "        #\n",
    "        try: # for U, u\n",
    "            c0 = next(iter(Ucolumns))\n",
    "            for c in Ucolumns:\n",
    "                assert len(U_[c].shape)==2 and U_[c].shape[1]==U_[c0].shape[1], '!F! U_[c] must have expected shape'\n",
    "                if c in xsingleUcolumns:\n",
    "                    assert U_[c].shape==_U_shape[c], '!F! U_[c] shape must be consistent with same from make_single_A_U_...'\n",
    "                else:\n",
    "                    assert U_[c].shape[0]==_U_shape[c][0]+1 and U_[c].shape[1]==_U_shape[c][1], '!F! U_[c] shape consistency'\n",
    "            assert all(c in xMcolumns or c[-1] in '*_' for c in set(u)^xucolumns), (\n",
    "                '!F! columns found in u not in ucolumns must be in Mcolumns or end in exclusion suffixes')\n",
    "            for c in ucolumns:\n",
    "                assert len(u[c].shape)==1 and u[c].shape[0]==U_[c0].shape[1], (\n",
    "                    f'`u` items shape must match last dimension: c={c}, u={u[c].shape}, U_={U_[c0].shape}')\n",
    "        except StopIteration: # U has no features (#TODO also doesn't check u even if u has features)\n",
    "            pass\n",
    "        #                for V,v\n",
    "        try: \n",
    "            assert all(c in xMcolumns or c[-1] in '*_' for c in set(V_)^xVcolumns), (\n",
    "                '!F! columns found in V_ not in Vcolumns must be in Mcolumns or end in exclusion suffixes')\n",
    "            c0 = next(iter(Vcolumns))\n",
    "            for c in Vcolumns:\n",
    "                assert len(V_[c].shape)==1 and V_[c].shape[0]==V_[c0].shape[0], 'V_[c] shape must be consistent'\n",
    "                assert V_[c].shape[0]==_V_shape[c][0]+1, 'V_[c].shape[0] must grow by 1 each day'\n",
    "            assert all(c in xMcolumns or c[-1] in '*_' for c in set(v)^xvcolumns), (\n",
    "                '!F! columns found in v not in vcolumns must be in Mcolumns or end in exclusion suffixes')\n",
    "        except StopIteration: # V has no features\n",
    "            pass\n",
    "        for c in vcolumns:\n",
    "            assert v[c].shape==(), 'v[c] must be scalar (i.e. shape=()) shaped'\n",
    "        #################################################END#######CHECK###############################################\n",
    "        \n",
    "        # cutoff excess past terms to save memory\n",
    "        for key in U_:\n",
    "            if len(U_[key])>termU:\n",
    "                U_[key] = U_[key][-termU:]\n",
    "        for key in V_:\n",
    "            if len(V_[key])>termV:\n",
    "                V_[key] = V_[key][-termV:]\n",
    "        \n",
    "        # take out the bottom row of the feature tables to feed out as our feature construction iterator\n",
    "        _wide = np.zeros(u[next(iter(u))].shape, dtype=np.int8) # dtype as np.int8 to make it not upcast orig dtype\n",
    "        _dict = {c: U_[c][-1] for c in Ucolumns}\n",
    "        _dict.update({c: u[c] for c in ucolumns})\n",
    "        _dict.update({c: V_[c][-1] + _wide for c in Vcolumns})\n",
    "        _dict.update({c: v[c] + _wide for c in vcolumns})\n",
    "        del u, v\n",
    "#         dict.update(BUG, U_=U_,V_=V_,u=u,v=v)\n",
    "        # piece everything together\n",
    "        columns = Ucolumns + ucolumns + Vcolumns + vcolumns\n",
    "        F = pd.DataFrame([_dict[c] for c in columns], index=columns, columns=A.index).T\n",
    "        F = M.join(F, how='left')\n",
    "        assert 'assetCodeId' not in F.columns\n",
    "        F.reset_index(inplace=True)\n",
    "        F.index = orig_index\n",
    "        \n",
    "        if train: # remove rows of stocks that are not inUni\n",
    "            keep = F.assetCodeId.isin(xStocksInUni).values & (P.universe!=0).values\n",
    "            F, P = F[keep], P[keep]\n",
    "        \n",
    "#         for c in enumeration_columns:\n",
    "#             assert np.issubdtype(F[c].dtype, np.integer)\n",
    "        add_postprocessing_features(F=F)\n",
    "        \n",
    "        # downgrade columns to 32bit dtypes for memory saving\n",
    "#        convert32(F) #FLOAT32 # we don't do this anymore because memsave_concat can do it for us\n",
    "        yield F, P\n",
    "        del F, P; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make initial historical U_ and u_ for creating the whole training features #EDITNOTE\n",
    "\n",
    "def iter_M_N_P_train(*,M,N):\n",
    "    assert M.time.iloc[0] >= train_start_time, '`iter_M_N_P_train` needs to be fed `M` and `N` filtered on the training days'\n",
    "    M_, N_ = M, N\n",
    "    for time, M in M_.groupby('time'):\n",
    "#         if time<train_start_time: # no longer needed because I enforce feeding M already filtered for the training days\n",
    "#             continue\n",
    "        #M['quarter'] = M.time.dt.year+(M.time.dt.quarter-1)/4\n",
    "        P = M[[c for c in excluded_columns if c in M]] #EDITLINE\n",
    "        M = M.drop(columns=['returnsOpenNextMktres10'])#,'quarter'])\n",
    "        yield M, None, P\n",
    "        \n",
    "Mstart = M[M.time<train_start_time]\n",
    "set_basic_features(M=Mstart)\n",
    "U_ = make_U(M=Mstart)\n",
    "u_ = OX()\n",
    "add_shortterm_price_features(U=U_,u=u_)\n",
    "add_longterm_price_features(U=U_,u=u_)\n",
    "V_, v_ = OX(), OX()\n",
    "add_global_price_features(U=U_,u=u_,V=V_,v=v_)\n",
    "del Mstart, u_, v_; gc.collect()\n",
    "\n",
    "Mtrain = M[M.time>=train_start_time]\n",
    "#del M; gc.collect() #NOPE #TODO? this is totally wrong I need M after to generate the test U_ and V_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### make train helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memsave_concat(train):\n",
    "    m = (Mtrain.assetCode.map(assetCodeIdAssign).isin(xStocksInUni) & (Mtrain.universe!=0)).sum()\n",
    "    P_ = []\n",
    "    for k, (F, P) in enumerate(train):\n",
    "        if k == 0:\n",
    "            col = F.columns\n",
    "            ans = np.zeros([m,len(col)], dtype=np.float32) # #FLOAT32\n",
    "            m0 = 0\n",
    "        assert (F.index == P.index).all()\n",
    "        P_.append(P)\n",
    "        del P\n",
    "        m1 = m0 + len(F)\n",
    "        assert (F.columns == col).all()\n",
    "        ans[m0:m1] = F\n",
    "        del F; gc.collect()\n",
    "        m0 = m1\n",
    "    Pret = pd.concat(P_, axis=0)\n",
    "    Fret = pd.DataFrame(ans, index=Pret.index, columns=col, copy=False)\n",
    "    return Fret, Pret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cell to generate the training features. WARNING: takes a long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.........100.........200.........300.........400.........500.........600.........700.........800.........900.........1000.........1100.........1200.........1300.........1400.........1500.........1600.........1700.........1800.........1900.........2000.CPU times: user 2h 1min 53s, sys: 2min 29s, total: 2h 4min 22s\n",
      "Wall time: 1h 37min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def make_train():\n",
    "    global U_, V_\n",
    "    feat_iter = iter_features_templates(iter_M_N_P_train(M=Mtrain,N=None), U_=(U_,longterm), V_=(V_,longterm), train=True)\n",
    "    train = ( (print_progress(i,10), FP)[-1] for i,FP in enumerate(feat_iter) )\n",
    "    del U_, V_; gc.collect()\n",
    "    F, P = memsave_concat(train)\n",
    "    F.index = P.index\n",
    "    return F,P\n",
    "F,P = make_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W, D = make_W_D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saving some variables for leaderboard submission loop before deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defines U_ ahead of time for initial start of the feature processing loop in submission stage\n",
    "\n",
    "Mstart = M[M.time>=M.time.unique()[-longterm]]\n",
    "set_basic_features(M=Mstart)\n",
    "U_ = make_U(M=Mstart)\n",
    "del Mstart; gc.collect()\n",
    "u_, V_, v_ = OX(), OX(), OX()\n",
    "add_shortterm_price_features(U=U_,u=u_)\n",
    "add_longterm_price_features(U=U_,u=u_)\n",
    "add_global_price_features(U=U_,u=u_,V=V_,v=v_)\n",
    "del u_, v_; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del M; gc.collect() # We still need U_ and V_ for final submission loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELLO READ THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now we have DataFrames F and P\n",
    "- F = The features data. shape = ({training and cv days}, {all the features})\n",
    "- P = The target and other columns not in F. Same index as F\n",
    "\n",
    "import to note,\n",
    "- columns under F: assetCodeId\n",
    "- columns under P: assetCode, time, quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### some P columns setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##P.rename(columns={'returnsOpenNextMktres10':'y'}, inplace=True)\n",
    "P['y'] = P.returnsOpenNextMktres10\n",
    "#globalStd = (P.universe*P.y).std()\n",
    "#grp = P.groupby(F.assetCodeId)[['y','universe']]\n",
    "#assetStds = grp.apply(lambda x: np.sqrt((x.universe*x.y**2).sum()/(x.universe).sum()) if x.universe.sum()>25 else globalStd)\n",
    "#P['assetCodeId'] = P.assetCode.map(assetCodeIdAssign)\n",
    "#P.y /= P.assetCodeId.map(assetStds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup_P(F=F,P=P,vp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _~ ~ ~ ~ ~ saving/loading for local testing_ #TODO #KILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.to_pickle((F,P),'../data/saves/ikg.test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.to_pickle((F,P), '/big/data/saves/train_5fixedsince.32.pkl')\n",
    "#pd.to_pickle((F,P), '/big/data/saves/train_5fixedsince+1threecombos.32.pkl')\n",
    "F,P = pd.read_pickle('../data/saves/train_5fixedsince+1.32.pkl')\n",
    "P.rename(columns={'weight':'flat_weight'}, inplace=True)\n",
    "W, C, D = pd.read_pickle('../data/pair/working_2ONEorTEN.pkl'); W, C, D = O(**W), O(**C), O(**D); del C; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.to_pickle((F,P), '/big/data/saves/train_4Newnewfault64xx.pkl')\n",
    "#F,P = pd.read_pickle('/big/data/saves/train_4Newnewfault64xx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FF,PP = pd.read_pickle('/big/data/saves/train_3allright32.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F0,P0 = pd.read_pickle('/big/data/saves/train_thefault.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F,P = FF,PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @#@///////////////////////////////////// Training some particular model! /////////////////////////////////@#@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgb_kaggle_metric(preds, valid_data):\n",
    "    df_time = valid_data.timeFactor\n",
    "    #labels = valid_data.get_label()\n",
    "    values = valid_data.value\n",
    "    #assert len(labels) == len(df_time)\n",
    "\n",
    "    preds = preds*2-1\n",
    "    #labels = labels*2-1\n",
    "    x_t = preds * values\n",
    "    \n",
    "    # Here we take advantage of the fact that `labels` (used to calculate `x_t`)\n",
    "    # is a pd.Series and call `group_by`\n",
    "    x_t_sum = x_t.groupby(df_time).sum()\n",
    "    score = x_t_sum.mean() / x_t_sum.std()\n",
    "\n",
    "    valid_data.i += lgb_kaggle_metric.hack\n",
    "    return 'kaggle', score+valid_data.i, True\n",
    "lgb_kaggle_metric.hack = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the lgb data structure and train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_booster(model, *, F, P):\n",
    "    F_, P_ = F[model.features], P.copy() #TODO #MEM\n",
    "    lgb_data_info = dict(\n",
    "        feature_name = list(F_.columns),\n",
    "        categorical_feature = list(F_.dtypes[F_.dtypes.isin([np.int64,np.int32])].index),\n",
    "        free_raw_data = True,\n",
    "    )\n",
    "    theweight = model.weight\n",
    "    ho = P_.quarter >= 2015.5\n",
    "    tr = P_.quarter.isin(model.train_on)\n",
    "    #cv = (P_.time>=train_start_time) & ~(tr|ho)\n",
    "    L = O()\n",
    "    L.tr = lgb.Dataset(F_[tr], P_.target[tr], weight=P_[theweight][tr], **lgb_data_info)\n",
    "    #L.cv = lgb.Dataset(F_[cv], P_.target[cv], reference=L.tr, weight=P_[theweight][cv], **lgb_data_info)\n",
    "    L.ho = lgb.Dataset(F_[ho], P_.target[ho], weight=P_[theweight][ho], **lgb_data_info)\n",
    "    \n",
    "    L.tr.timeFactor = P_.time[tr].factorize()[0]\n",
    "    #L.cv.timeFactor = P_.time[cv].factorize()[0]\n",
    "    _value = (P_.upDown*P_[theweight])\n",
    "    L.tr.value = _value[tr]\n",
    "    #L.cv.value = _value[cv]\n",
    "    L.tr.i = 0\n",
    "    #L.cv.i = 0\n",
    "    \n",
    "    params = dict(\n",
    "        objective = 'binary',\n",
    "        #num_iterations = 450,\n",
    "        #early_stopping_round = 32,\n",
    "        metric = 'None',\n",
    "        seed = 44,\n",
    "        bagging_seed = 45,\n",
    "        feature_fraction_seed = 46,\n",
    "    )\n",
    "    params.update(model.params)\n",
    "    global VERBOSE_EVAL\n",
    "    model.bst = bst = lgb.train(params, L.tr, valid_sets=[L.tr], valid_names=['tr'],\n",
    "                                feval=lgb_kaggle_metric, verbose_eval=VERBOSE_EVAL)\n",
    "    if VERBOSE_EVAL:\n",
    "        print('='*60)\n",
    "    P_['guess'] = bst.predict(F_)*2-1\n",
    "    P_['trade'] = P_.guess*P_.upDown*P_[theweight]\n",
    "    daily = P_[~ho].groupby('time').trade.sum()\n",
    "    bst.std = daily.std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pair_F_P(model, *, F, P):\n",
    "    if not hasattr(model, 'filts'):\n",
    "        model.x_copy_features = set(model.copy_features)\n",
    "        model.x_diff_features = set(model.diff_features)\n",
    "        model.x_sign_features = set(model.sign_features)\n",
    "        model.x_corr_features = set(model.corr_features)\n",
    "        filts = model.filts = [lambda x,s=s,model=model: x in getattr(model, f'x_{s}_features')\n",
    "                               for s in 'copy diff sign corr'.split()]\n",
    "    else:\n",
    "        filts = model.filts\n",
    "\n",
    "    feats = list(filter(lambda x: filts[0](x)|filts[1](x)|filts[2](x), F.columns))\n",
    "    if 'assetCodeId' not in feats:\n",
    "        feats = ['assetCodeId'] + feats\n",
    "        \n",
    "    CC, G, Q = make_CC_G_Q_from_Dl_F_P_W(\n",
    "        F=F, P=P, W=W, Dl=D.av10,\n",
    "        lo = model.Pair.lo,\n",
    "        hi = model.Pair.hi,\n",
    "        repeat = model.Pair.repeat\n",
    "    )\n",
    "\n",
    "    FG, PQ = make_FG_PQ_from_CC_G_Q(*filts, CC=CC, G=G, Q=Q)\n",
    "\n",
    "    model.features = list(FG.columns)\n",
    "    return FG, PQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resolve_pair_guess(model, guess, P, PQ):\n",
    "    P['assetCodeId'] = P.assetCode.map(assetCodeIdAssign)\n",
    "    PQ['__0__assetCodeId'] = PQ.__0__assetCode.map(assetCodeIdAssign)\n",
    "    PQ['__1__assetCodeId'] = PQ.__1__assetCode.map(assetCodeIdAssign)\n",
    "    PQ['guess'] = guess * PQ[model.weight]\n",
    "    \n",
    "    dummy = P.set_index(['time','assetCodeId'])[[]]\n",
    "    PQ.rename(columns={'__0__assetCodeId':'assetCodeId'}, inplace=True)\n",
    "    buy = dummy.join(PQ.groupby(['time','assetCodeId']).guess.sum()).fillna(0)\n",
    "    PQ.rename(columns={'assetCodeId':'__0__assetCodeId','__1__assetCodeId':'assetCodeId'}, inplace=True)\n",
    "    sell = dummy.join(PQ.groupby(['time','assetCodeId']).guess.sum()).fillna(0)\n",
    "    PQ.rename(columns={'assetCodeId':'__1__assetCodeId'}, inplace=True)\n",
    "    \n",
    "    return (buy-sell).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO IT. Train the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttr's kaggle: 0.894557\n",
      "[100]\ttr's kaggle: 1.02789\n",
      "[150]\ttr's kaggle: 1.13252\n",
      "[200]\ttr's kaggle: 1.21308\n",
      "[250]\ttr's kaggle: 1.27962\n",
      "[300]\ttr's kaggle: 1.3391\n",
      "[350]\ttr's kaggle: 1.39301\n",
      "[400]\ttr's kaggle: 1.44017\n",
      "[450]\ttr's kaggle: 1.47991\n",
      "============================================================\n",
      "CPU times: user 44min 35s, sys: 18.1 s, total: 44min 53s\n",
      "Wall time: 5min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "VERBOSE_EVAL = 50\n",
    "for model, c in zip(themodel.solo.specs, themodel.solo.coefs):\n",
    "    if c != 0:\n",
    "        create_booster(model,F=F,P=P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pair) len(F.columns) = 1259\n",
      "(pair) generating [350]0.........100.........200.........300....\n",
      "(pair) putting together... (pair) done\n",
      "[50]\ttr's kaggle: 1.0072\n",
      "[100]\ttr's kaggle: 1.44753\n",
      "[150]\ttr's kaggle: 1.77931\n",
      "[200]\ttr's kaggle: 1.976\n",
      "[250]\ttr's kaggle: 2.09887\n",
      "============================================================\n",
      "CPU times: user 28min 14s, sys: 25.2 s, total: 28min 40s\n",
      "Wall time: 5min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "VERBOSE_EVAL = 50\n",
    "SEE = print\n",
    "for model, c in zip(themodel.pair.specs, themodel.pair.coefs):\n",
    "    if c != 0:\n",
    "        FG, PQ = make_pair_F_P(model,F=F,P=P)\n",
    "        create_booster(model,F=FG,P=PQ)\n",
    "SEE = lambda*a,**k:None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the model aggregating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inside(themodel)\n",
    "def guess(*, F, P):\n",
    "    weight_map_multiplier = {'vp1_weight':F.vp1/1e9,'vp10_weight':F.vp10/1e9,'flat_weight':1,}\n",
    "    \n",
    "    def _pair_func(model, *, F, P):\n",
    "        FG, PQ = make_pair_F_P(model,F=F,P=P)\n",
    "        guess = model.bst.predict(FG) * 2 - 1\n",
    "        del FG, PQ; gc.collect()\n",
    "        return resolve_pair_guess(model, guess, P=P,PQ=PQ)\n",
    "    pairs = [np.nan_to_num(_pair_func(s,F=F,P=P)) * c / s.bst.std\n",
    "             for s,c in zip(themodel.pair.specs,themodel.pair.coefs) if c!=0]\n",
    "    \n",
    "    solos = [np.nan_to_num((s.bst.predict(F[s.features])*2-1) * weight_map_multiplier[s.weight]) * c / s.bst.std\n",
    "             for s,c in zip(themodel.solo.specs,themodel.solo.coefs) if c!=0]\n",
    "    \n",
    "    return (sum(solos+pairs)/1000000).clip(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### last look at the model blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IKGCover, "
     ]
    }
   ],
   "source": [
    "[print((spec.__name__ if spec is not None else 'None'), end=', ') for spec in themodel.solo.specs];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# themodel.solo.coefs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pIKGCoverHomo, "
     ]
    }
   ],
   "source": [
    "[print((spec.__name__ if spec is not None else 'None'), end=', ') for spec in themodel.pair.specs];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# themodel.pair.coefs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the holdout results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pair) len(F.columns) = 1259\n",
      "(pair) generating [350]0"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 2014 but corresponding boolean dimension is 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             return self._constructor(self._data.get_slice(indexer),\n\u001b[0m\u001b[1;32m    878\u001b[0m                                      fastpath=True).__finalize__(self)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget_slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   4705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4706\u001b[0;31m         return self.__class__(self._block._slice(slobj),\n\u001b[0m\u001b[1;32m   4707\u001b[0m                               self.index[slobj], fastpath=True)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;34m\"\"\" return a slice of my values \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 2014 but corresponding boolean dimension is 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-927f7213cfad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrade\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mview_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-161-927f7213cfad>\u001b[0m in \u001b[0;36mview_results\u001b[0;34m(ho, F, P)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mview_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mho\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mho\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'guess'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthemodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguess\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-160-aca802f47ac3>\u001b[0m in \u001b[0;36mguess\u001b[0;34m(F, P)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresolve_pair_guess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPQ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     pairs = [np.nan_to_num(_pair_func(s,F=F,P=P)) * c / s.bst.std\n\u001b[0;32m---> 11\u001b[0;31m              for s,c in zip(themodel.pair.specs,themodel.pair.coefs) if c!=0]\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     solos = [np.nan_to_num((s.bst.predict(F[s.features])*2-1) * weight_map_multiplier[s.weight]) * c / s.bst.std\n",
      "\u001b[0;32m<ipython-input-160-aca802f47ac3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresolve_pair_guess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPQ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     pairs = [np.nan_to_num(_pair_func(s,F=F,P=P)) * c / s.bst.std\n\u001b[0;32m---> 11\u001b[0;31m              for s,c in zip(themodel.pair.specs,themodel.pair.coefs) if c!=0]\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     solos = [np.nan_to_num((s.bst.predict(F[s.features])*2-1) * weight_map_multiplier[s.weight]) * c / s.bst.std\n",
      "\u001b[0;32m<ipython-input-160-aca802f47ac3>\u001b[0m in \u001b[0;36m_pair_func\u001b[0;34m(model, F, P)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pair_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mFG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pair_F_P\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFG\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mFG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPQ\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-cf6792b3580f>\u001b[0m in \u001b[0;36mmake_pair_F_P\u001b[0;34m(model, F, P)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mrepeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-154-3d41b661d6d7>\u001b[0m in \u001b[0;36mmake_CC_G_Q_from_Dl_F_P_W\u001b[0;34m(Dl, F, P, W, lo, hi, repeat, roll_corr)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mroll_corr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_periods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#TODO hard coded min_periods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0munic_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mweight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_roll_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munic_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    844\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mkey_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m    878\u001b[0m                                      fastpath=True).__finalize__(self)\n\u001b[1;32m    879\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 2014 but corresponding boolean dimension is 1"
     ]
    }
   ],
   "source": [
    "ho = P.time == P.time.iloc[-1]\n",
    "SEE = print\n",
    "def view_results(ho, *, F, P):\n",
    "    F, P = F[ho], P[ho]\n",
    "    P['guess'] = themodel.guess(F=F,P=P)\n",
    "    P.guess = P.guess*(np.abs(P.guess)>=0.0)\n",
    "\n",
    "    P['trade'] = P.guess*P.upDown*P.flat_weight\n",
    "\n",
    "    daily = P[ho].groupby('time').trade.sum()\n",
    "    print(daily.mean()/daily.std(ddof=0))\n",
    "    plt.hist(daily, bins=80);\n",
    "    \n",
    "    time = P[ho].groupby('time').time.first()\n",
    "    market = F[ho].groupby(P.time).m_oo1.first()\n",
    "    trade = P[ho].groupby('time').trade.sum()\n",
    "    \n",
    "    %matplotlib inline\n",
    "    canvas(12,6)\n",
    "    plt.plot(time, market/market.std(ddof=0), linewidth=.2);\n",
    "    plt.plot(time, trade/trade.std(ddof=0), linewidth=1);\n",
    "\n",
    "view_results(ho, F=F,P=P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>assetCode</th>\n",
       "      <th>assetName</th>\n",
       "      <th>universe</th>\n",
       "      <th>returnsOpenNextMktres10</th>\n",
       "      <th>quarter</th>\n",
       "      <th>y</th>\n",
       "      <th>target</th>\n",
       "      <th>upDown</th>\n",
       "      <th>absVal</th>\n",
       "      <th>flat_weight</th>\n",
       "      <th>vp1_weight</th>\n",
       "      <th>vp5_weight</th>\n",
       "      <th>vp10_weight</th>\n",
       "      <th>always_weight</th>\n",
       "      <th>assetCodeId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>732812</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>A.N</td>\n",
       "      <td>Agilent Technologies Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>0.008491</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732814</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>AAP.N</td>\n",
       "      <td>Advance Auto Parts Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029782</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.029782</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029782</td>\n",
       "      <td>0.029782</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732815</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>AAPL.O</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.026166</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.026166</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.026166</td>\n",
       "      <td>0.026166</td>\n",
       "      <td>0.060380</td>\n",
       "      <td>0.053807</td>\n",
       "      <td>0.055439</td>\n",
       "      <td>0.026166</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732816</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>AB.N</td>\n",
       "      <td>AllianceBernstein Holding LP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.046983</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.046983</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046983</td>\n",
       "      <td>0.046983</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732817</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ABB.N</td>\n",
       "      <td>ABB Ltd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.009046</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.009046</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.009046</td>\n",
       "      <td>0.009046</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.009046</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732818</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ABC.N</td>\n",
       "      <td>AmerisourceBergen Corp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.057848</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.057848</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.057848</td>\n",
       "      <td>0.057848</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.057848</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732821</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ABT.N</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.026621</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.026621</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.026621</td>\n",
       "      <td>0.026621</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.026621</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732822</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ABV.N</td>\n",
       "      <td>Companhia de Bebidas das Americas Ambev</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.039785</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.039785</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039785</td>\n",
       "      <td>0.039785</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732824</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ACC.N</td>\n",
       "      <td>American Campus Communities Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047610</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.047610</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047610</td>\n",
       "      <td>0.047610</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732825</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ACE.N</td>\n",
       "      <td>Chubb Ltd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.046250</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.046250</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.046250</td>\n",
       "      <td>0.046250</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732826</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ACF.N</td>\n",
       "      <td>General Motors Financial Company Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732827</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ACGL.O</td>\n",
       "      <td>Arch Capital Group Ltd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732828</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ACH.N</td>\n",
       "      <td>Aluminum Corp of China Ltd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732831</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ACM.N</td>\n",
       "      <td>AECOM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.014116</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.014116</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.014116</td>\n",
       "      <td>0.014116</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732833</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ACS.N</td>\n",
       "      <td>Affiliated Computer Services Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.006331</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.006331</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732835</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ADBE.O</td>\n",
       "      <td>Adobe Systems Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038831</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.038831</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038831</td>\n",
       "      <td>0.038831</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>0.038831</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732837</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ADI.N</td>\n",
       "      <td>Analog Devices Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067412</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.067412</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067412</td>\n",
       "      <td>0.067412</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732838</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ADM.N</td>\n",
       "      <td>Archer Daniels Midland Co</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.001282</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.001282</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732839</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ADP.O</td>\n",
       "      <td>Automatic Data Processing Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029259</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.029259</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029259</td>\n",
       "      <td>0.029259</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.004931</td>\n",
       "      <td>0.029259</td>\n",
       "      <td>2126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732840</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ADS.N</td>\n",
       "      <td>Alliance Data Systems Corp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021419</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.021419</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732841</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ADSK.O</td>\n",
       "      <td>Autodesk Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732842</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>ADTN.O</td>\n",
       "      <td>ADTRAN Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.078998</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.078998</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078998</td>\n",
       "      <td>0.078998</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732844</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>AEE.N</td>\n",
       "      <td>Ameren Corp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732845</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>AEG.N</td>\n",
       "      <td>Aegon NV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.034479</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.034479</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.034479</td>\n",
       "      <td>0.034479</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732848</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>AEO.N</td>\n",
       "      <td>American Eagle Outfitters Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.075995</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.075995</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075995</td>\n",
       "      <td>0.075995</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732849</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>AEP.N</td>\n",
       "      <td>American Electric Power Company Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.007791</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.007791</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732850</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>AES.N</td>\n",
       "      <td>AES Corp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100145</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.100145</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100145</td>\n",
       "      <td>0.100145</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.100145</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732851</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>AET.N</td>\n",
       "      <td>Aetna Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045586</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.045586</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045586</td>\n",
       "      <td>0.045586</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.045586</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732852</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>AF.N</td>\n",
       "      <td>Astoria Financial Corp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.075946</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>-0.075946</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.075946</td>\n",
       "      <td>0.075946</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732854</th>\n",
       "      <td>2009-01-02 22:00:00+00:00</td>\n",
       "      <td>AFG.N</td>\n",
       "      <td>American Financial Group Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072908</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>WSM.N</td>\n",
       "      <td>Williams-Sonoma Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072911</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>WTR.N</td>\n",
       "      <td>Aqua America Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072912</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>WU.N</td>\n",
       "      <td>Western Union Co</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072913</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>WUBA.N</td>\n",
       "      <td>58.com Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053127</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.053127</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053127</td>\n",
       "      <td>0.053127</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072914</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>WWAV.N</td>\n",
       "      <td>WhiteWave Foods Co</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.004719</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.004719</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072918</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>WY.N</td>\n",
       "      <td>Weyerhaeuser Co</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072919</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>WYN.N</td>\n",
       "      <td>Wyndham Worldwide Corp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.022542</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.022542</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072920</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>WYNN.O</td>\n",
       "      <td>Wynn Resorts Ltd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.081718</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.081718</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.081718</td>\n",
       "      <td>0.081718</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.081718</td>\n",
       "      <td>1399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072921</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>X.N</td>\n",
       "      <td>United States Steel Corp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.052809</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.052809</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.052809</td>\n",
       "      <td>0.052809</td>\n",
       "      <td>0.029039</td>\n",
       "      <td>0.018651</td>\n",
       "      <td>0.022589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072923</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>XEL.N</td>\n",
       "      <td>Xcel Energy Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.001117</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.001117</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072925</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>XL.N</td>\n",
       "      <td>XL Group Ltd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.006919</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.006919</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072926</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>XLNX.O</td>\n",
       "      <td>Xilinx Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.072078</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.072078</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.072078</td>\n",
       "      <td>0.072078</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>0.072078</td>\n",
       "      <td>1403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072929</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>XOG.O</td>\n",
       "      <td>Extraction Oil &amp; Gas Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.080657</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.080657</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.080657</td>\n",
       "      <td>0.080657</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072930</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>XOM.N</td>\n",
       "      <td>Exxon Mobil Corp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.057035</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.057035</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.057035</td>\n",
       "      <td>0.057035</td>\n",
       "      <td>0.046818</td>\n",
       "      <td>0.032775</td>\n",
       "      <td>0.043778</td>\n",
       "      <td>0.057035</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072931</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>XON.N</td>\n",
       "      <td>Intrexon Corp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072932</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>XPO.N</td>\n",
       "      <td>XPO Logistics Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.010168</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.010168</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072933</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>XRAY.O</td>\n",
       "      <td>Dentsply Sirona Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.014616</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.014616</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.014616</td>\n",
       "      <td>0.014616</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072935</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>XYL.N</td>\n",
       "      <td>Xylem Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.030040</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.030040</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.030040</td>\n",
       "      <td>0.030040</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072936</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>YELP.N</td>\n",
       "      <td>Yelp Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.072670</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.072670</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072670</td>\n",
       "      <td>0.072670</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.007987</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072937</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>YHOO.O</td>\n",
       "      <td>Altaba Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087102</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.087102</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087102</td>\n",
       "      <td>0.087102</td>\n",
       "      <td>0.021695</td>\n",
       "      <td>0.015597</td>\n",
       "      <td>0.034808</td>\n",
       "      <td>0.087102</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072938</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>YNDX.O</td>\n",
       "      <td>Yandex NV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.056161</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.056161</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056161</td>\n",
       "      <td>0.056161</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072939</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>YPF.N</td>\n",
       "      <td>YPF SA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.288102</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.288102</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.288102</td>\n",
       "      <td>0.288102</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072941</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>YUM.N</td>\n",
       "      <td>Yum! Brands Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072942</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>YUMC.N</td>\n",
       "      <td>Yum China Holdings Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072944</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>Z.O</td>\n",
       "      <td>Zillow Group Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019932</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.019932</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072945</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>ZAYO.N</td>\n",
       "      <td>Zayo Group Holdings Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031742</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.031742</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.031742</td>\n",
       "      <td>0.031742</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072946</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>ZBH.N</td>\n",
       "      <td>Zimmer Biomet Holdings Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115330</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.115330</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115330</td>\n",
       "      <td>0.115330</td>\n",
       "      <td>0.011603</td>\n",
       "      <td>0.011331</td>\n",
       "      <td>0.015246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072950</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>ZION.O</td>\n",
       "      <td>Zions Bancorp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.045221</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.045221</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.045221</td>\n",
       "      <td>0.045221</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.045221</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072954</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>ZTO.N</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083367</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>0.083367</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083367</td>\n",
       "      <td>0.083367</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072955</th>\n",
       "      <td>2016-12-30 22:00:00+00:00</td>\n",
       "      <td>ZTS.N</td>\n",
       "      <td>Zoetis Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.016220</td>\n",
       "      <td>2016.75</td>\n",
       "      <td>-0.016220</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.016220</td>\n",
       "      <td>0.016220</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1979459 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             time assetCode  \\\n",
       "732812  2009-01-02 22:00:00+00:00       A.N   \n",
       "732814  2009-01-02 22:00:00+00:00     AAP.N   \n",
       "732815  2009-01-02 22:00:00+00:00    AAPL.O   \n",
       "732816  2009-01-02 22:00:00+00:00      AB.N   \n",
       "732817  2009-01-02 22:00:00+00:00     ABB.N   \n",
       "732818  2009-01-02 22:00:00+00:00     ABC.N   \n",
       "732821  2009-01-02 22:00:00+00:00     ABT.N   \n",
       "732822  2009-01-02 22:00:00+00:00     ABV.N   \n",
       "732824  2009-01-02 22:00:00+00:00     ACC.N   \n",
       "732825  2009-01-02 22:00:00+00:00     ACE.N   \n",
       "732826  2009-01-02 22:00:00+00:00     ACF.N   \n",
       "732827  2009-01-02 22:00:00+00:00    ACGL.O   \n",
       "732828  2009-01-02 22:00:00+00:00     ACH.N   \n",
       "732831  2009-01-02 22:00:00+00:00     ACM.N   \n",
       "732833  2009-01-02 22:00:00+00:00     ACS.N   \n",
       "732835  2009-01-02 22:00:00+00:00    ADBE.O   \n",
       "732837  2009-01-02 22:00:00+00:00     ADI.N   \n",
       "732838  2009-01-02 22:00:00+00:00     ADM.N   \n",
       "732839  2009-01-02 22:00:00+00:00     ADP.O   \n",
       "732840  2009-01-02 22:00:00+00:00     ADS.N   \n",
       "732841  2009-01-02 22:00:00+00:00    ADSK.O   \n",
       "732842  2009-01-02 22:00:00+00:00    ADTN.O   \n",
       "732844  2009-01-02 22:00:00+00:00     AEE.N   \n",
       "732845  2009-01-02 22:00:00+00:00     AEG.N   \n",
       "732848  2009-01-02 22:00:00+00:00     AEO.N   \n",
       "732849  2009-01-02 22:00:00+00:00     AEP.N   \n",
       "732850  2009-01-02 22:00:00+00:00     AES.N   \n",
       "732851  2009-01-02 22:00:00+00:00     AET.N   \n",
       "732852  2009-01-02 22:00:00+00:00      AF.N   \n",
       "732854  2009-01-02 22:00:00+00:00     AFG.N   \n",
       "...                           ...       ...   \n",
       "4072908 2016-12-30 22:00:00+00:00     WSM.N   \n",
       "4072911 2016-12-30 22:00:00+00:00     WTR.N   \n",
       "4072912 2016-12-30 22:00:00+00:00      WU.N   \n",
       "4072913 2016-12-30 22:00:00+00:00    WUBA.N   \n",
       "4072914 2016-12-30 22:00:00+00:00    WWAV.N   \n",
       "4072918 2016-12-30 22:00:00+00:00      WY.N   \n",
       "4072919 2016-12-30 22:00:00+00:00     WYN.N   \n",
       "4072920 2016-12-30 22:00:00+00:00    WYNN.O   \n",
       "4072921 2016-12-30 22:00:00+00:00       X.N   \n",
       "4072923 2016-12-30 22:00:00+00:00     XEL.N   \n",
       "4072925 2016-12-30 22:00:00+00:00      XL.N   \n",
       "4072926 2016-12-30 22:00:00+00:00    XLNX.O   \n",
       "4072929 2016-12-30 22:00:00+00:00     XOG.O   \n",
       "4072930 2016-12-30 22:00:00+00:00     XOM.N   \n",
       "4072931 2016-12-30 22:00:00+00:00     XON.N   \n",
       "4072932 2016-12-30 22:00:00+00:00     XPO.N   \n",
       "4072933 2016-12-30 22:00:00+00:00    XRAY.O   \n",
       "4072935 2016-12-30 22:00:00+00:00     XYL.N   \n",
       "4072936 2016-12-30 22:00:00+00:00    YELP.N   \n",
       "4072937 2016-12-30 22:00:00+00:00    YHOO.O   \n",
       "4072938 2016-12-30 22:00:00+00:00    YNDX.O   \n",
       "4072939 2016-12-30 22:00:00+00:00     YPF.N   \n",
       "4072941 2016-12-30 22:00:00+00:00     YUM.N   \n",
       "4072942 2016-12-30 22:00:00+00:00    YUMC.N   \n",
       "4072944 2016-12-30 22:00:00+00:00       Z.O   \n",
       "4072945 2016-12-30 22:00:00+00:00    ZAYO.N   \n",
       "4072946 2016-12-30 22:00:00+00:00     ZBH.N   \n",
       "4072950 2016-12-30 22:00:00+00:00    ZION.O   \n",
       "4072954 2016-12-30 22:00:00+00:00     ZTO.N   \n",
       "4072955 2016-12-30 22:00:00+00:00     ZTS.N   \n",
       "\n",
       "                                       assetName  universe  \\\n",
       "732812                  Agilent Technologies Inc       1.0   \n",
       "732814                    Advance Auto Parts Inc       1.0   \n",
       "732815                                 Apple Inc       1.0   \n",
       "732816              AllianceBernstein Holding LP       1.0   \n",
       "732817                                   ABB Ltd       1.0   \n",
       "732818                    AmerisourceBergen Corp       1.0   \n",
       "732821                       Abbott Laboratories       1.0   \n",
       "732822   Companhia de Bebidas das Americas Ambev       1.0   \n",
       "732824           American Campus Communities Inc       1.0   \n",
       "732825                                 Chubb Ltd       1.0   \n",
       "732826      General Motors Financial Company Inc       1.0   \n",
       "732827                    Arch Capital Group Ltd       1.0   \n",
       "732828                Aluminum Corp of China Ltd       1.0   \n",
       "732831                                     AECOM       1.0   \n",
       "732833          Affiliated Computer Services Inc       1.0   \n",
       "732835                         Adobe Systems Inc       1.0   \n",
       "732837                        Analog Devices Inc       1.0   \n",
       "732838                 Archer Daniels Midland Co       1.0   \n",
       "732839             Automatic Data Processing Inc       1.0   \n",
       "732840                Alliance Data Systems Corp       1.0   \n",
       "732841                              Autodesk Inc       1.0   \n",
       "732842                                ADTRAN Inc       1.0   \n",
       "732844                               Ameren Corp       1.0   \n",
       "732845                                  Aegon NV       1.0   \n",
       "732848             American Eagle Outfitters Inc       1.0   \n",
       "732849       American Electric Power Company Inc       1.0   \n",
       "732850                                  AES Corp       1.0   \n",
       "732851                                 Aetna Inc       1.0   \n",
       "732852                    Astoria Financial Corp       1.0   \n",
       "732854              American Financial Group Inc       1.0   \n",
       "...                                          ...       ...   \n",
       "4072908                      Williams-Sonoma Inc       1.0   \n",
       "4072911                         Aqua America Inc       1.0   \n",
       "4072912                         Western Union Co       1.0   \n",
       "4072913                               58.com Inc       1.0   \n",
       "4072914                       WhiteWave Foods Co       1.0   \n",
       "4072918                          Weyerhaeuser Co       1.0   \n",
       "4072919                   Wyndham Worldwide Corp       1.0   \n",
       "4072920                         Wynn Resorts Ltd       1.0   \n",
       "4072921                 United States Steel Corp       1.0   \n",
       "4072923                          Xcel Energy Inc       1.0   \n",
       "4072925                             XL Group Ltd       1.0   \n",
       "4072926                               Xilinx Inc       1.0   \n",
       "4072929                 Extraction Oil & Gas Inc       1.0   \n",
       "4072930                         Exxon Mobil Corp       1.0   \n",
       "4072931                            Intrexon Corp       1.0   \n",
       "4072932                        XPO Logistics Inc       1.0   \n",
       "4072933                      Dentsply Sirona Inc       1.0   \n",
       "4072935                                Xylem Inc       1.0   \n",
       "4072936                                 Yelp Inc       1.0   \n",
       "4072937                               Altaba Inc       1.0   \n",
       "4072938                                Yandex NV       1.0   \n",
       "4072939                                   YPF SA       1.0   \n",
       "4072941                          Yum! Brands Inc       1.0   \n",
       "4072942                   Yum China Holdings Inc       1.0   \n",
       "4072944                         Zillow Group Inc       1.0   \n",
       "4072945                  Zayo Group Holdings Inc       1.0   \n",
       "4072946               Zimmer Biomet Holdings Inc       1.0   \n",
       "4072950                            Zions Bancorp       1.0   \n",
       "4072954                                  Unknown       1.0   \n",
       "4072955                               Zoetis Inc       1.0   \n",
       "\n",
       "         returnsOpenNextMktres10  quarter         y  target  upDown    absVal  \\\n",
       "732812                  0.179633  2009.00  0.179633    True       1  0.179633   \n",
       "732814                  0.029782  2009.00  0.029782    True       1  0.029782   \n",
       "732815                 -0.026166  2009.00 -0.026166   False      -1  0.026166   \n",
       "732816                  0.046983  2009.00  0.046983    True       1  0.046983   \n",
       "732817                 -0.009046  2009.00 -0.009046   False      -1  0.009046   \n",
       "732818                  0.057848  2009.00  0.057848    True       1  0.057848   \n",
       "732821                 -0.026621  2009.00 -0.026621   False      -1  0.026621   \n",
       "732822                  0.039785  2009.00  0.039785    True       1  0.039785   \n",
       "732824                  0.047610  2009.00  0.047610    True       1  0.047610   \n",
       "732825                 -0.046250  2009.00 -0.046250   False      -1  0.046250   \n",
       "732826                  0.018940  2009.00  0.018940    True       1  0.018940   \n",
       "732827                  0.013688  2009.00  0.013688    True       1  0.013688   \n",
       "732828                  0.006138  2009.00  0.006138    True       1  0.006138   \n",
       "732831                 -0.014116  2009.00 -0.014116   False      -1  0.014116   \n",
       "732833                 -0.006331  2009.00 -0.006331   False      -1  0.006331   \n",
       "732835                  0.038831  2009.00  0.038831    True       1  0.038831   \n",
       "732837                  0.067412  2009.00  0.067412    True       1  0.067412   \n",
       "732838                 -0.001282  2009.00 -0.001282   False      -1  0.001282   \n",
       "732839                  0.029259  2009.00  0.029259    True       1  0.029259   \n",
       "732840                 -0.021419  2009.00 -0.021419   False      -1  0.021419   \n",
       "732841                 -0.005836  2009.00 -0.005836   False      -1  0.005836   \n",
       "732842                  0.078998  2009.00  0.078998    True       1  0.078998   \n",
       "732844                 -0.001675  2009.00 -0.001675   False      -1  0.001675   \n",
       "732845                 -0.034479  2009.00 -0.034479   False      -1  0.034479   \n",
       "732848                  0.075995  2009.00  0.075995    True       1  0.075995   \n",
       "732849                 -0.007791  2009.00 -0.007791   False      -1  0.007791   \n",
       "732850                  0.100145  2009.00  0.100145    True       1  0.100145   \n",
       "732851                  0.045586  2009.00  0.045586    True       1  0.045586   \n",
       "732852                 -0.075946  2009.00 -0.075946   False      -1  0.075946   \n",
       "732854                  0.013208  2009.00  0.013208    True       1  0.013208   \n",
       "...                          ...      ...       ...     ...     ...       ...   \n",
       "4072908                 0.006167  2016.75  0.006167    True       1  0.006167   \n",
       "4072911                 0.008290  2016.75  0.008290    True       1  0.008290   \n",
       "4072912                 0.005685  2016.75  0.005685    True       1  0.005685   \n",
       "4072913                 0.053127  2016.75  0.053127    True       1  0.053127   \n",
       "4072914                -0.004719  2016.75 -0.004719   False      -1  0.004719   \n",
       "4072918                 0.010887  2016.75  0.010887    True       1  0.010887   \n",
       "4072919                -0.022542  2016.75 -0.022542   False      -1  0.022542   \n",
       "4072920                 0.081718  2016.75  0.081718    True       1  0.081718   \n",
       "4072921                -0.052809  2016.75 -0.052809   False      -1  0.052809   \n",
       "4072923                -0.001117  2016.75 -0.001117   False      -1  0.001117   \n",
       "4072925                -0.006919  2016.75 -0.006919   False      -1  0.006919   \n",
       "4072926                -0.072078  2016.75 -0.072078   False      -1  0.072078   \n",
       "4072929                -0.080657  2016.75 -0.080657   False      -1  0.080657   \n",
       "4072930                -0.057035  2016.75 -0.057035   False      -1  0.057035   \n",
       "4072931                 0.003620  2016.75  0.003620    True       1  0.003620   \n",
       "4072932                -0.010168  2016.75 -0.010168   False      -1  0.010168   \n",
       "4072933                -0.014616  2016.75 -0.014616   False      -1  0.014616   \n",
       "4072935                -0.030040  2016.75 -0.030040   False      -1  0.030040   \n",
       "4072936                 0.072670  2016.75  0.072670    True       1  0.072670   \n",
       "4072937                 0.087102  2016.75  0.087102    True       1  0.087102   \n",
       "4072938                 0.056161  2016.75  0.056161    True       1  0.056161   \n",
       "4072939                 0.288102  2016.75  0.288102    True       1  0.288102   \n",
       "4072941                 0.012008  2016.75  0.012008    True       1  0.012008   \n",
       "4072942                 0.018680  2016.75  0.018680    True       1  0.018680   \n",
       "4072944                -0.019932  2016.75 -0.019932   False      -1  0.019932   \n",
       "4072945                -0.031742  2016.75 -0.031742   False      -1  0.031742   \n",
       "4072946                 0.115330  2016.75  0.115330    True       1  0.115330   \n",
       "4072950                -0.045221  2016.75 -0.045221   False      -1  0.045221   \n",
       "4072954                 0.083367  2016.75  0.083367    True       1  0.083367   \n",
       "4072955                -0.016220  2016.75 -0.016220   False      -1  0.016220   \n",
       "\n",
       "         flat_weight  vp1_weight  vp5_weight  vp10_weight  always_weight  \\\n",
       "732812      0.179633    0.008491    0.011776     0.015845       0.179633   \n",
       "732814      0.029782    0.000803    0.000745     0.001058       0.000000   \n",
       "732815      0.026166    0.060380    0.053807     0.055439       0.026166   \n",
       "732816      0.046983    0.000652    0.000559     0.000546       0.000000   \n",
       "732817      0.009046    0.000455    0.000386     0.000484       0.009046   \n",
       "732818      0.057848    0.004098    0.002195     0.002336       0.057848   \n",
       "732821      0.026621    0.009000    0.006653     0.008801       0.026621   \n",
       "732822      0.039785    0.000898    0.000927     0.001215       0.000000   \n",
       "732824      0.047610    0.000747    0.000604     0.000850       0.000000   \n",
       "732825      0.046250    0.002150    0.002674     0.003556       0.000000   \n",
       "732826      0.018940    0.000084    0.000087     0.000089       0.000000   \n",
       "732827      0.013688    0.000367    0.000347     0.000400       0.000000   \n",
       "732828      0.006138    0.000226    0.000100     0.000100       0.000000   \n",
       "732831      0.014116    0.000659    0.000670     0.000532       0.000000   \n",
       "732833      0.006331    0.000186    0.000142     0.000190       0.000000   \n",
       "732835      0.038831    0.005470    0.003674     0.004209       0.038831   \n",
       "732837      0.067412    0.004182    0.003202     0.004054       0.000000   \n",
       "732838      0.001282    0.000216    0.000153     0.000171       0.001282   \n",
       "732839      0.029259    0.004093    0.002818     0.004931       0.029259   \n",
       "732840      0.021419    0.001041    0.000807     0.000832       0.000000   \n",
       "732841      0.005836    0.000325    0.000278     0.000284       0.005836   \n",
       "732842      0.078998    0.000827    0.000566     0.000590       0.000000   \n",
       "732844      0.001675    0.000043    0.000053     0.000060       0.001675   \n",
       "732845      0.034479    0.000195    0.000188     0.000185       0.000000   \n",
       "732848      0.075995    0.002454    0.002853     0.003204       0.000000   \n",
       "732849      0.007791    0.000584    0.000578     0.000824       0.007791   \n",
       "732850      0.100145    0.004034    0.003542     0.004777       0.100145   \n",
       "732851      0.045586    0.005449    0.004372     0.004899       0.045586   \n",
       "732852      0.075946    0.001639    0.001104     0.001079       0.000000   \n",
       "732854      0.013208    0.000180    0.000144     0.000160       0.000000   \n",
       "...              ...         ...         ...          ...            ...   \n",
       "4072908     0.006167    0.000299    0.000444     0.000523       0.000000   \n",
       "4072911     0.008290    0.000230    0.000115     0.000153       0.000000   \n",
       "4072912     0.005685    0.000317    0.000304     0.000368       0.005685   \n",
       "4072913     0.053127    0.000901    0.001708     0.002067       0.000000   \n",
       "4072914     0.004719    0.000225    0.000198     0.000282       0.000000   \n",
       "4072918     0.010887    0.000940    0.000844     0.001185       0.010887   \n",
       "4072919     0.022542    0.000909    0.000730     0.001064       0.022542   \n",
       "4072920     0.081718    0.013442    0.010453     0.016966       0.081718   \n",
       "4072921     0.052809    0.029039    0.018651     0.022589       0.000000   \n",
       "4072923     0.001117    0.000087    0.000057     0.000084       0.001117   \n",
       "4072925     0.006919    0.000249    0.000297     0.000494       0.000000   \n",
       "4072926     0.072078    0.009302    0.007366     0.010188       0.072078   \n",
       "4072929     0.080657    0.000963    0.001202     0.002052       0.000000   \n",
       "4072930     0.057035    0.046818    0.032775     0.043778       0.057035   \n",
       "4072931     0.003620    0.000106    0.000116     0.000129       0.000000   \n",
       "4072932     0.010168    0.000295    0.000257     0.000518       0.000000   \n",
       "4072933     0.014616    0.000809    0.000650     0.000825       0.000000   \n",
       "4072935     0.030040    0.000971    0.000918     0.001454       0.000000   \n",
       "4072936     0.072670    0.006963    0.007987     0.007975       0.000000   \n",
       "4072937     0.087102    0.021695    0.015597     0.034808       0.087102   \n",
       "4072938     0.056161    0.000892    0.001214     0.001567       0.000000   \n",
       "4072939     0.288102    0.004539    0.004071     0.004026       0.000000   \n",
       "4072941     0.012008    0.001449    0.001202     0.001311       0.012008   \n",
       "4072942     0.018680    0.000475    0.000611     0.000971       0.000000   \n",
       "4072944     0.019932    0.000653    0.000608     0.000778       0.000000   \n",
       "4072945     0.031742    0.001921    0.001371     0.002171       0.000000   \n",
       "4072946     0.115330    0.011603    0.011331     0.015246       0.000000   \n",
       "4072950     0.045221    0.003776    0.002712     0.004308       0.045221   \n",
       "4072954     0.083367    0.003279    0.002330     0.001919       0.000000   \n",
       "4072955     0.016220    0.001480    0.001264     0.001742       0.000000   \n",
       "\n",
       "         assetCodeId  \n",
       "732812             0  \n",
       "732814             2  \n",
       "732815             3  \n",
       "732816          1564  \n",
       "732817             4  \n",
       "732818             5  \n",
       "732821             8  \n",
       "732822             9  \n",
       "732824          1948  \n",
       "732825          2087  \n",
       "732826            11  \n",
       "732827          1655  \n",
       "732828            12  \n",
       "732831          1690  \n",
       "732833            14  \n",
       "732835            18  \n",
       "732837            20  \n",
       "732838            21  \n",
       "732839          2126  \n",
       "732840            23  \n",
       "732841            24  \n",
       "732842            25  \n",
       "732844            27  \n",
       "732845            28  \n",
       "732848          1501  \n",
       "732849            32  \n",
       "732850            34  \n",
       "732851            35  \n",
       "732852            36  \n",
       "732854            38  \n",
       "...              ...  \n",
       "4072908         1386  \n",
       "4072911         1390  \n",
       "4072912         1393  \n",
       "4072913         3282  \n",
       "4072914         3041  \n",
       "4072918         1397  \n",
       "4072919         1398  \n",
       "4072920         1399  \n",
       "4072921         1400  \n",
       "4072923         1402  \n",
       "4072925         3685  \n",
       "4072926         1403  \n",
       "4072929         3750  \n",
       "4072930         1405  \n",
       "4072931         3099  \n",
       "4072932         3177  \n",
       "4072933         3612  \n",
       "4072935         2748  \n",
       "4072936         2814  \n",
       "4072937         1407  \n",
       "4072938         2668  \n",
       "4072939         2618  \n",
       "4072941         1408  \n",
       "4072942         3753  \n",
       "4072944         2800  \n",
       "4072945         3417  \n",
       "4072946         3457  \n",
       "4072950         1411  \n",
       "4072954         3767  \n",
       "4072955         2998  \n",
       "\n",
       "[1979459 rows x 16 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUG.P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +-+-+-+-+-+-+-+-+-+-+-+-+-+-+- Prediction and submission +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the rest of the administrative pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__env__ = _make_env() #TODO #KILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.........10.........20.........30.........40.........50.........60.........70.........80.........90.........100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........500.........510.........520.........530.........540.........550.........560.........570.........580.........590.........600.........610.........620.........630........CPU times: user 57min 32s, sys: 2min, total: 59min 33s\n",
      "Wall time: 18min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def do_submission_loop():\n",
    "    feat_iter = iter_features_templates(__env__.get_prediction_days(), U_=(U_,longterm), V_=(V_,longterm))\n",
    "    for i, (f, p) in enumerate(feat_iter):\n",
    "        print_progress(i)\n",
    "        p_ = p.reset_index()\n",
    "        p_['time'] = 0\n",
    "        p_['pair_weight']\n",
    "        p.confidenceValue = ans = themodel.guess(F=f,P=p_)\n",
    "        if np.isnan(ans).any() or (ans<-1).any() or (ans>1).any():\n",
    "            BUG.i, BUG.f, BUG.p, BUG.ans = i, f, p, ans\n",
    "            assert False\n",
    "        __env__.predict(p)\n",
    "        gc.collect()\n",
    "do_submission_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved. Once you `Commit` your Kernel and it finishes running, you can submit the file to the competition from the Kernel Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "__env__.write_submission_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ LOCAL TESTING ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
