{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "import json, copy, operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST = True; PROD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I = lambda x: x\n",
    "logavg = lambda x,y: math.expm1((math.log1p(x)+math.log1p(y))/2)\n",
    "keepSigFig = lambda n: lambda x: round(x, -int(math.floor(math.log10(abs(x)))) + (n - 1)) if x else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frzset = lambda x: x if isinstance(x, frozenset) else frozenset(x)\n",
    "pydict = lambda x: O.pycopy(x) if isinstance(x, O) else copy.deepcopy(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #!#!#!#!#!#!#!#!#!#!#! Save System #!#!#!#!#!#!#!#!#!#!#!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IndexFileSystem():\n",
    "    def __init__(self, directory, key):\n",
    "        self.dir = directory if isinstance(directory, Path) else Path(directory)\n",
    "        self.dir.mkdir(exist_ok=True, parents=True)\n",
    "        assert isinstance(key, str), \"key must be string\"\n",
    "        self.key = key\n",
    "        self.io = O()\n",
    "\n",
    "    def iterIndices(self):\n",
    "        for dot_params in self.dir.glob('*.' + self.key):\n",
    "            yield int(dot_params.stem)\n",
    "\n",
    "    def getFilePath(self, name, *, i):\n",
    "        return self.dir / (str(i) + '.' + name)\n",
    "\n",
    "    @staticmethod\n",
    "    def readWrapper(read):\n",
    "        '''wraps io read operations to safely return None if file does not exist'''\n",
    "        @wraps(read)\n",
    "        def read_safely(*a, **k):\n",
    "            try:\n",
    "                return read(*a, **k)\n",
    "            except FileNotFoundError:\n",
    "                return None\n",
    "        return read_safely\n",
    "\n",
    "    def assignIO(self, name, *, read, write, format='custom'):\n",
    "        assert format in ['bytes', 'text', 'custom'], \"argument `format` must be one of 'bytes' or 'text' or 'custom'\"\n",
    "        if format in ['bytes', 'text']:\n",
    "            self.io[name] = O(\n",
    "                read = self.readWrapper( lambda *,i: read(getattr(self.getFilePath(name, i=i), 'read_'+format)()) ),\n",
    "                write = lambda x,*,i: getattr(self.getFilePath(name, i=i), 'write_'+format)(write(x))\n",
    "            )\n",
    "        elif format == 'custom':\n",
    "            def readCustom(*, i):\n",
    "                file = self.getFilePath(name, i=i)\n",
    "                if not file.exists():\n",
    "                    return None\n",
    "                try:\n",
    "                    return read(file)\n",
    "                except Exception:\n",
    "                    return read(str(file))\n",
    "            def writeCustom(*, i):\n",
    "                file = self.getFilePath(name, i=i)\n",
    "                try:\n",
    "                    write(x, file=file)\n",
    "                except Exception:\n",
    "                    write(x, file=str(file))\n",
    "            self.io[name] = O(read=readCustom, write=writeCustom)\n",
    "\n",
    "class IndexDataStore():    \n",
    "    def __init__(self, file, _factory_=False):\n",
    "        if not _factory_:\n",
    "            assert False, \"Cannot instantiate IndexDataStore normally. Please use factory static method.\"\n",
    "        self.file = file\n",
    "        self.op = O()\n",
    "        self.lists = O()\n",
    "        self.key = None\n",
    "        self.keyFunc = lambda keyVal, *, client=False: object()\n",
    "        self.tbl = {}\n",
    "        self.nextIndex = 0\n",
    "        \n",
    "    def load(self):\n",
    "        indices = sorted(self.file.iterIndices())\n",
    "        n = self.nextIndex = (max(indices) if indices else -1) + 1\n",
    "        for name, _ in dict.items(self.lists):\n",
    "            self.lists[name] = [None] * self.nextIndex\n",
    "        \n",
    "        for i in indices:\n",
    "            for name in self.lists:\n",
    "                if self.op[name].load:\n",
    "                    self.op[name].load(i=i)\n",
    "                \n",
    "        if self.key is not None:\n",
    "            self.assignKey(self.key, self.keyFunc)\n",
    "            \n",
    "    def i(self, key, dry=False, client=True, keep=True, save=True):\n",
    "        keyVal = self.keyFunc(key, client=client)\n",
    "        \n",
    "        if keyVal not in self.tbl and not dry:\n",
    "            for name in self.lists:\n",
    "                assert len(self.lists[name]) == self.nextIndex, \"idk internal error\"\n",
    "                self.lists[name].append(None)\n",
    "            self.tbl[keyVal] = self.nextIndex\n",
    "            if save and self.op[self.key].save:\n",
    "                self.op[self.key].save(key, i=self.nextIndex, keep=keep)\n",
    "            elif keep and self.op[self.key].keep:\n",
    "                self.op[self.key].keep(key, i=self.nextIndex, client=client)\n",
    "            self.nextIndex += 1\n",
    "        elif keyVal not in self.tbl and dry:\n",
    "            return None\n",
    "        \n",
    "        return self.tbl[keyVal]\n",
    "            \n",
    "    def save(self, keep=True, **kwargs):\n",
    "        '''`client` is always True'''\n",
    "        assert ('i' in kwargs) ^ (self.key in kwargs), \"call to `save` must include exactly one of i= or the key name =\"\n",
    "        if 'i' in kwargs:\n",
    "            i = kwargs['i']\n",
    "            del kwargs['i']\n",
    "        else:\n",
    "            i = self.i(kwargs[self.key])\n",
    "        \n",
    "        for name in kwargs:\n",
    "            if name == self.key: # already saved in `self.i(save=True)` above\n",
    "                continue\n",
    "            if name not in self.op:\n",
    "                raise AssertionError(f\"given save item '{name}' does not have data store ops initialized\")\n",
    "            if self.op[name].save:\n",
    "                self.op[name].save(kwargs[name], i=i, keep=keep)\n",
    "            \n",
    "    def get(self, name, **kwargs):\n",
    "        assert len(kwargs) == 1 and ('i' in kwargs or self.key in kwargs), \"must give assigned 'key' or i\"\n",
    "        if 'i' in kwargs:\n",
    "            i = kwargs['i']\n",
    "            del kwargs['i']\n",
    "        else:\n",
    "            i = self.i(kwargs[self.key], dry=True)\n",
    "        if i is None:\n",
    "            return None\n",
    "        got = self.lists[name][i]\n",
    "        if got is None and self.op[name].load:\n",
    "            got = self.op[name].load(i=i)\n",
    "        return got\n",
    "        \n",
    "    ##################### INSTANCE BUILDING METHODS ##################### : \n",
    "    def assignKey(self, name, func):\n",
    "        assert name in self.lists, \"key name must first be assigned ops\"\n",
    "        self.key = name\n",
    "        self.keyFunc = func\n",
    "        self.tbl = {self.keyFunc(x): i for i,x in enumerate(self.lists[self.key]) if x is not None}\n",
    "        \n",
    "    def assignOperations(self, name, *, load=I, save=I, keep=I, keepSaved=None, keepClient=None):\n",
    "        if keepClient is None:\n",
    "            keepClient = keep\n",
    "            \n",
    "        #NOTE #TODE? the method names below conflict with the local vars up here, and current Python syntax takes\n",
    "        # the variables up here. Should this change the code below will stop working. But this is the \"nicest\" way to do it\n",
    "        class the(O()):\n",
    "            def load(*, i, keep=True):\n",
    "                if not load:\n",
    "                    return None\n",
    "                read = self.file.io[name].read(i=i)\n",
    "                x = load(read) if read is not None else None\n",
    "                if keep and self.op[name].keep:\n",
    "                    self.lists[name][i] = self.op[name].keep(x, i=i)\n",
    "                return x\n",
    "            \n",
    "            def save(x, *, i, keep=True):\n",
    "                if not save:\n",
    "                    return\n",
    "                saved_x = save(x)\n",
    "                self.file.io[name].write(saved_x, i=i)\n",
    "                if keep and self.op[name].keep:\n",
    "                    try:\n",
    "                        self.lists[name][i] = self.op[name].keep(saved_x, i=i, saved=True)\n",
    "                        assert self.lists[name][i] is not None\n",
    "                    except (TypeError, AssertionError):\n",
    "                        self.lists[name][i] = self.op[name].keep(x, i=i, client=True)\n",
    "                \n",
    "            def keep(x, *, i, saved=False, client=False):\n",
    "                if x is None:\n",
    "                    return None\n",
    "                assert not (saved and client), \"only one of `saved` and `client` can be specified\"\n",
    "                if not any([keep, keepSaved, keepClient]):\n",
    "                    return None\n",
    "                kept = None\n",
    "                if saved and keepSaved:\n",
    "                    kept = keepSaved(x)\n",
    "                elif client and keepClient:\n",
    "                    kept = keepClient(x)\n",
    "                elif not saved and not client and keep:\n",
    "                    kept = keep(x)\n",
    "                if kept is not None:\n",
    "                    self.lists[name][i] = kept\n",
    "                return kept\n",
    "            \n",
    "        if not load:\n",
    "            the.load = False\n",
    "        if not save:\n",
    "            the.save = False\n",
    "        if not any([keep, keepSaved, keepClient]):\n",
    "            the.keep = False\n",
    "            \n",
    "        self.op[name] = the\n",
    "        if name not in self.lists:\n",
    "            self.lists[name] = [None] * self.nextIndex\n",
    "    \n",
    "    \n",
    "@staticmethod\n",
    "def __IndexDataStore__from_specs(specs, **kwargs):\n",
    "    for k, v in kwargs.items():\n",
    "        specs[k] = v\n",
    "    \n",
    "    f = IndexFileSystem(specs.dir, specs.key)\n",
    "    d = IndexDataStore(f, _factory_=True)\n",
    "    \n",
    "    _readwriteformat = {'read', 'write', 'format'}\n",
    "    _loadsavekeep = {'load', 'save', 'keep', 'keepSaved', 'keepClient'}\n",
    "    for name, val in dict.items(specs.op):\n",
    "        f.assignIO(name, **{a: b for a,b in dict.items(val) if a in _readwriteformat})\n",
    "        d.assignOperations(name, **{a: b for a,b in dict.items(val) if a in _loadsavekeep})\n",
    "        \n",
    "    keyFuncClient = specs.keyFuncClient if 'keyFuncClient' in specs else specs.keyFunc\n",
    "    keyFunc = lambda keyVal, *, client=False: keyFuncClient(keyVal) if client else specs.keyFunc(keyVal)\n",
    "    d.assignKey(specs.key, keyFunc)\n",
    "    \n",
    "    d.load()\n",
    "    return d\n",
    "IndexDataStore.from_specs = __IndexDataStore__from_specs\n",
    "\n",
    "\n",
    "def json_default(o):\n",
    "    if isinstance(o, np.int64):\n",
    "        return int(o)  \n",
    "    raise TypeError\n",
    "    \n",
    "class __IndexDataStore__SpecsHelper(metaclass=staticclass):\n",
    "    def json(op):\n",
    "        op.format = 'text'\n",
    "        op.read = json.loads\n",
    "        op.write = lambda x: json.dumps(x, default=json_default)\n",
    "        return op\n",
    "    def pickle(op):\n",
    "        op.format = 'bytes'\n",
    "        op.read = pickle.loads\n",
    "        op.write = pickle.dumps\n",
    "        return op\n",
    "IndexDataStore.SpecsHelper = __IndexDataStore__SpecsHelper\n",
    "IDSSH = IndexDataStore.SpecsHelper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelManager():\n",
    "    features_dir = '.features'\n",
    "    samples_dir = '.samples'\n",
    "    models_dir = 'models'\n",
    "    \n",
    "    def __init__(self, directory, f_specs=None, s_specs=None, p_specs=None): #GLOBAL FDS SDS PDS\n",
    "        global FDS, SDS, PDS\n",
    "        if f_specs is None:\n",
    "            f_specs = FDS\n",
    "        if s_specs is None:\n",
    "            s_specs = SDS\n",
    "        if p_specs is None:\n",
    "            p_specs = PDS\n",
    "        self.p_specs = p_specs\n",
    "        self.dir = directory if isinstance(directory, Path) else Path(directory)\n",
    "        self.dir.mkdir(exist_ok=True) # no parents because this is user facing and enabling parents could get gnarly\n",
    "        self.F = IndexDataStore.from_specs(f_specs, dir=self.dir/self.features_dir)\n",
    "        self.S = IndexDataStore.from_specs(s_specs, dir=self.dir/self.samples_dir)\n",
    "        (self.dir/self.models_dir).mkdir(exist_ok=True)\n",
    "        self.load()\n",
    "        \n",
    "    def load(self):\n",
    "        self.pms = {}\n",
    "        for fi, si in self.iterIndices():\n",
    "            self.make_params_manager(i=(fi, si))\n",
    "        \n",
    "    def iterIndices(self):\n",
    "        for fdir in (self.dir/self.models_dir).iterdir():\n",
    "            try:\n",
    "                fi = int(fdir.name)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            assert fdir.is_dir(), \"folder in models folder whose name is just a number must be a folder\"\n",
    "            assert fi < self.F.nextIndex, \"features folder found with greater index than what has been labelled\"\n",
    "            for sdir in fdir.iterdir():\n",
    "                try:\n",
    "                    si = int(sdir.name)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                assert sdir.is_dir(), \"folder in models folder 1 layer down whose name is just a number must be a folder\"\n",
    "                assert si < self.S.nextIndex, \"samples folder found with greater index than what has been labelled\"\n",
    "                yield (fi, si)\n",
    "        \n",
    "    def make_params_manager(self, features=None, samples=None, i=None):\n",
    "        assert (\n",
    "            not ((features is None) ^ (samples is None)) and\n",
    "            ((features is not None and samples is not None) ^ (i is not None)),\n",
    "            \"invalid arguments to `make_param_manager`\"\n",
    "        )\n",
    "        if i is None:\n",
    "            i = self.F.i(features), self.S.i(samples)\n",
    "        fi, si = i\n",
    "        assert 0 <= fi < self.F.nextIndex and 0 <= si < self.S.nextIndex, \"bad arguments to `make_params_manager`\"\n",
    "        pm = IndexDataStore.from_specs(self.p_specs, dir=self.dir/self.models_dir/str(fi)/str(si))\n",
    "        self.pms[fi, si] = pm\n",
    "        return pm\n",
    "    \n",
    "    def i(features, samples): # purely convenience public interface\n",
    "        return self.F.i(features), self.S.i(samples)\n",
    "        \n",
    "    def PM(self, features, samples, get_i=False):\n",
    "        fi, si = self.F.i(features), self.S.i(samples)\n",
    "        if get_i:\n",
    "            return self.iPM(fi, si), (fi, si)\n",
    "        else:\n",
    "            return self.iPM(fi, si)\n",
    "        \n",
    "    def iPM(self, fi, si):\n",
    "        if (fi, si) not in self.pms:\n",
    "            self.make_params_manager(i=(fi, si))\n",
    "        return self.pms[fi, si]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specs for managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbNullDataset = lgb.Dataset(pd.DataFrame({'_a_': np.arange(88), '_b_': np.arange(88)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param search $\\textbf{SAVING}$ specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PDS(O()):\n",
    "    '''data transformation code inside `op` object:\n",
    "\n",
    "    client --save(+write)--> disk; client --keep--> memory; disk --load(+read)--> memory\n",
    "\n",
    "    read = text/bytes stream -> as-is object read from file\n",
    "    write = object to save as is to file -> text/bytes stream\n",
    "    load = as-is object read from file -> object to be loaded in memory\n",
    "    save = raw object given by client -> object to save as-is to file\n",
    "    keep = as-is object read from file -> object to keep in memory\n",
    "    keepClient = raw object given by client -> object to keep in memory\n",
    "    '''\n",
    "\n",
    "    key = 'Params'\n",
    "    keyFunc = lambda params: tuple(sorted(dict.items(params)))\n",
    "\n",
    "    class op(O()):\n",
    "        @IDSSH.json\n",
    "        class Params(O()):\n",
    "            '''just a dict of the parameter value assignments'''\n",
    "            keepClient = dict\n",
    "            \n",
    "        @IDSSH.json\n",
    "        class Results(O()):\n",
    "            '''should be a dict-like of various things, most importantly including \"score\"'''\n",
    "            load = lambda x: O(**x)\n",
    "            save = pydict\n",
    "            keepClient = lambda x: O.mycopy(x) if isinstance(x, O) else O(**x)\n",
    "            \n",
    "        @IDSSH.pickle\n",
    "        class Training(O()):\n",
    "            '''tuple (aligning with samples training/cv split tuple) of LightGBM training eval DataFrames'''\n",
    "            keep = False\n",
    "            \n",
    "        @IDSSH.pickle\n",
    "        class Boosters(O()):\n",
    "            '''the actual lgb.Booster model. well, a tuple of them, one for each cv set'''\n",
    "            #read = lambda file: lgb.Booster(model_file=file)\n",
    "            load = lambda x: tuple(lgb.Booster(train_set=lgbNullDataset).model_from_string(s, verbose=False) for s in x)\n",
    "            #write = lambda x, file: x.save_model(file)\n",
    "            save = lambda x: tuple(b.model_to_string() for b in x)\n",
    "            keep = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature selection / days sampling $\\textbf{SAVING}$ specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FDS(O()):\n",
    "    key = 'Feats'\n",
    "    keyFunc = lambda features: features # internally already coverted to immutable\n",
    "    keyFuncClient = frzset\n",
    "    class op(O()):\n",
    "        '''container of feature name strings'''\n",
    "        @IDSSH.json\n",
    "        class Feats(O()):\n",
    "            load = frozenset\n",
    "            save = sorted\n",
    "            keepClient = frozenset\n",
    "        @IDSSH.json\n",
    "        class Ctor(O()):\n",
    "            '''should be just a string, the query string of the FFF object'''\n",
    "    \n",
    "class SDS(O()):\n",
    "    key = 'Samps'\n",
    "    keyFunc = lambda samples: samples # internally already converted immutable\n",
    "    keyFuncClient = lambda samples: tuple((frzset(tr), frzset(cv)) for tr, cv in samples)\n",
    "    class op(O()):\n",
    "        @IDSSH.json\n",
    "        class Samps(O()):\n",
    "            '''tuple (num samples) of 2-tuples of tr/cv containers of the canonical index values for the split'''\n",
    "            load = lambda samples: tuple((frzset(tr), frzset(cv)) for tr, cv in samples)\n",
    "            save = lambda samples: [[sorted(tr), sorted(cv)] for tr, cv in samples]\n",
    "            keepClient = load\n",
    "        @IDSSH.json\n",
    "        class Ctor(O()):\n",
    "            '''should be O specs object'''\n",
    "            save = pydict\n",
    "            keepClient = save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~!~!~!~!~!~! Model (features/samples/parameters) Search ~!~!~!~!~!~!~!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter search logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ParamSearch():\n",
    "    mix = staticmethod(logavg)\n",
    "    \n",
    "    def __init__(self, specs):\n",
    "        self.specs = O.mycopy(specs)\n",
    "        self.setup_specs()\n",
    "        \n",
    "    def setup_specs(self):\n",
    "        dsc = self.specs.Discrete\n",
    "        dsc.keys = list(flatten( dsc.enc.keys() ))\n",
    "        dsc.assigns = [list(flatten(x)) for x in product(* dsc.enc.values() )]\n",
    "        obo = self.specs.OneByOne\n",
    "        for k,v in dict.items(obo.data):\n",
    "            for i,x in dict.items(obo.default):\n",
    "                if i not in v:\n",
    "                    v[i] = x\n",
    "    \n",
    "    def search(self):\n",
    "        dsc, obo = self.specs.Discrete, self.specs.OneByOne\n",
    "        for assign in dsc.assigns:\n",
    "            params = dict(zip(dsc.keys, assign))\n",
    "            coroutine = self.one_by_one()\n",
    "            for addon in coroutine:\n",
    "                params.update(addon)\n",
    "                coroutine.send((yield copy.deepcopy(params))); assert (yield) is None\n",
    "        \n",
    "        \n",
    "    def one_by_one(self):\n",
    "        obod = self.specs.OneByOne.data\n",
    "        \n",
    "        #! main algorithm ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        \n",
    "        # initialize loop variables\n",
    "        params = {k: (v.b if 'b' in v else v.a[1]) for k,v in dict.items(obod)}\n",
    "        ranges = {k: v.a for k,v in dict.items(obod)}\n",
    "        scores = {k: [-np.inf, -np.inf] for k in params}\n",
    "        isdone = {k: False for k in params}\n",
    "        \n",
    "        # pre loop one-off work\n",
    "        base_score = yield params; assert (yield) is None\n",
    "        \n",
    "        # loop\n",
    "        for i in range(999_999_999):\n",
    "            #! try new parameter values ############################## part A of loop work\n",
    "            \n",
    "            # initialize local loop variable\n",
    "            new_scores = {k: [-np.inf, -np.inf] for k in params}\n",
    "            new_params = {k: ( obod[k].cast(self.mix(v[0], v[1])),\n",
    "                               obod[k].cast(self.mix(v[1], v[2])) ) for k,v in dict.items(ranges)}\n",
    "            \n",
    "            # finish condition check\n",
    "            isdone = {k: v or i>=obod[k].lim for k,v in dict.items(isdone)}\n",
    "            if all(isdone.values()):\n",
    "                break\n",
    "                \n",
    "            # try new parameter values for all parameters\n",
    "            for key in list(params):\n",
    "                if i >= obod[key].lim:\n",
    "                    continue\n",
    "                orig = params[key]\n",
    "                params[key] = new_params[key][0]\n",
    "                scores[key][0] = yield params; assert (yield) is None\n",
    "                params[key] = new_params[key][1]\n",
    "                scores[key][1] = yield params; assert (yield) is None\n",
    "                params[key] = orig\n",
    "            \n",
    "            #! start setting up values for next loop ######################## part B of loop work\n",
    "            \n",
    "            # set params to the best found and see if it betters score, updating ranges also\n",
    "            #CODE num_nochange = 0\n",
    "            for key in list(params):\n",
    "                if scores[key][0] > base_score and scores[key][0] >= scores[key][1]:\n",
    "                    params[key] = new_params[key][0]\n",
    "                    ranges[key] = [ranges[key][0], params[key], ranges[key][1]]\n",
    "                elif scores[key][1] > base_score and scores[key][1] >= scores[key][0]:\n",
    "                    params[key] = new_params[key][1]\n",
    "                    ranges[key] = [ranges[key][1], params[key], ranges[key][2]]\n",
    "                else:\n",
    "                    ranges[key] = [new_params[key][0], ranges[key][1], new_params[key][1]]\n",
    "                    #num_nochange += 1\n",
    "                \n",
    "            # send out new params\n",
    "            #CODE if num_nochange < len(params):\n",
    "            base_score = yield params; assert (yield) is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features / Samples(train/cv split) search logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the Kaggle metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KaggleMetric():\n",
    "    def __init__(self, incr=0):\n",
    "        self.incr = incr\n",
    "    \n",
    "    def attach(self, ms):\n",
    "        L, s = ms._L, ms._s\n",
    "        for Ltr, Lcv, tr, cv in zip(L.tr, L.cv, s.tr, s.cv):\n",
    "            Ltr.timeFactor = ms.Y.time[tr].factorize()[0]\n",
    "            Lcv.timeFactor = ms.Y.time[cv].factorize()[0]\n",
    "            Ltr.value = (ms.Y.upDown1*ms.Y.absVal1)[tr]\n",
    "            Lcv.value = (ms.Y.upDown1*ms.Y.absVal1)[cv]\n",
    "            Ltr.i = 0\n",
    "            Lcv.i = 0\n",
    "    \n",
    "    def __call__(self, preds, valid_data):\n",
    "        df_time = valid_data.timeFactor\n",
    "        #labels = valid_data.get_label()\n",
    "        values = valid_data.value\n",
    "        #assert len(labels) == len(df_time)\n",
    "\n",
    "        preds = preds*2-1\n",
    "        #labels = labels*2-1\n",
    "        x_t = preds * values\n",
    "\n",
    "        # Here we take advantage of the fact that `labels` (used to calculate `x_t`)\n",
    "        # is a pd.Series and call `group_by`\n",
    "        x_t_sum = x_t.groupby(df_time).sum()\n",
    "        score = x_t_sum.mean() / x_t_sum.std()\n",
    "\n",
    "        valid_data.i += self.incr\n",
    "        return 'kaggle', score+valid_data.i, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model searching logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold\n",
    "        \n",
    "class ModelSearch():\n",
    "    \n",
    "    def __init__(self, specs, mm, *, X, Y, log=None):\n",
    "        self.specs = specs\n",
    "        global LOG\n",
    "        self.log = log if log is not None else LOG\n",
    "        self.mm = mm\n",
    "        assert (X.index == Y.index).all()\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.setup_specs()\n",
    "        \n",
    "    def setup_specs(self):\n",
    "        self.specs.Samples.data = []\n",
    "        for code in self.specs.Samples.enc:\n",
    "            if code.method == 'group.2':\n",
    "                tr, cv = set(code.data[0]), set(code.data[1])\n",
    "                tr, cv = self.Y[code.groups].isin(tr), self.Y[code.groups].isin(cv)\n",
    "                tr, cv = self.Y.index[tr], self.Y.index[cv]\n",
    "                self.specs.Samples.data += [((tr, cv), (cv, tr))]\n",
    "            elif code.method == 'GroupShuffleSplit.2':\n",
    "                tr, cv = next(GroupShuffleSplit(**code.kwargs).split(self.X, self.Y, groups=self.Y[code.groups]))\n",
    "                tr, cv = self.Y.index[tr], self.Y.index[cv]\n",
    "                self.specs.Samples.data += [((tr, cv), (cv, tr))]\n",
    "#             elif code.method == 'GroupKFold':\n",
    "#                 self.specs.Samples.data.append(tuple(GroupKFold(**code.kwargs)\n",
    "#                                                      .split(self.X, self.Y, groups=self.Y[code.groups])))\n",
    "            else:\n",
    "                assert False, f'sampling method \"{code.method}\" not implemented'\n",
    "        \n",
    "    def iter_feats_samps(self):\n",
    "        for i in range(99999999):\n",
    "            featsObj = self.specs.Features.func(i)\n",
    "            sampsObj = self.specs.Samples.func(i)\n",
    "            if featsObj is None or sampsObj is None:\n",
    "                break\n",
    "            self.mm.F.save(**featsObj)\n",
    "            self.mm.S.save(**sampsObj)\n",
    "            yield featsObj['Feats'], sampsObj['Samps']\n",
    "        \n",
    "    def walk(self):\n",
    "        for feats, samps in self.iter_feats_samps():\n",
    "            best_score = -np.inf\n",
    "            pm, i = self.mm.PM(feats, samps, get_i=True) # this also saves feats and samps\n",
    "            self._pm = pm\n",
    "            \n",
    "            self.setup_training(feats, samps, i=i)\n",
    "            search = ParamSearch(self.specs.search)\n",
    "            loop = search.search()\n",
    "            for params in loop: # params are deepcopied out, so can safely save them as-is!\n",
    "                paramsUse = dict(**self.specs.Params.data, **params)\n",
    "                results = pm.get('Results', Params=params)\n",
    "                if not results:\n",
    "                    self.log('training...')\n",
    "                    self.train(paramsUse) # sets some state attributes in self: self._save\n",
    "                    results = self._save.Results\n",
    "                    if results['score'] > best_score:\n",
    "                        self._best = (dict(**params), O(**self._save)) #TODO I still copy params here to be safe (needed)?\n",
    "                    del self._save.Training, self._save.Boosters\n",
    "                    pm.save(Params=params, **self._save)\n",
    "                loop.send(results['score'])\n",
    "                yield i, results\n",
    "                #del self._save #TODO probably wanna uncomment this in production\n",
    "            pm.save(Params=self._best[0], **self._best[1])\n",
    "                \n",
    "    def run(self):\n",
    "        for _ in self.walk():\n",
    "            pass\n",
    "                \n",
    "    def setup_training(self, feats, samps, *, i=None):\n",
    "        samps = self.mm.S.get('Samps', i=i[1]) # this `samps` is a tuple of tuple of frozensets\n",
    "        _X = self.X[feats]\n",
    "        #_dummy = pd.Series(range(len(_X)), index=_X.index)\n",
    "        _s = self._s = O()\n",
    "        _s.tr, _s.cv = tuple(_X.index.isin(s[0]) for s in samps), tuple(_X.index.isin(s[1]) for s in samps)\n",
    "        lgb_data_info = dict(\n",
    "            feature_name = list(_X.columns),\n",
    "            categorical_feature = list(_X.dtypes[_X.dtypes.isin([np.int64,np.int32])].index),\n",
    "            free_raw_data = False,\n",
    "        )\n",
    "        _L = self._L = O()\n",
    "        _L.tr = [lgb.Dataset(_X[tr], P[self.specs.model.target][tr], **lgb_data_info,\n",
    "                            **({'weight': P[self.specs.model.weight][tr]} if 'weight' in self.specs.model else {}))\n",
    "                for tr in _s.tr]\n",
    "        _L.cv = [lgb.Dataset(_X[cv], P[self.specs.model.target][cv], reference=Ltr, **lgb_data_info,\n",
    "                            **({'weight': P[self.specs.model.weight][cv]} if 'weight' in self.specs.model else {}))\n",
    "                for cv, Ltr in zip(_s.cv, _L.tr)]\n",
    "        m = self.specs.metric\n",
    "        if hasattr(m, 'attach'):\n",
    "            m.attach(self)\n",
    "        #TODO implement both logloss and Kaggle metric, and stop only when both don't improve in whatever num rounds\n",
    "        \n",
    "    def train(self, params):\n",
    "        def iter_samples():\n",
    "            for Ltr, Lcv in zip(self._L.tr, self._L.cv):\n",
    "                evals_result = {}\n",
    "                # fucking LightGBM deletes 'num_iterations' from `params` after training, like WTF???\n",
    "                bst = lgb.train(dict(params), Ltr, valid_sets=[Ltr, Lcv], valid_names=['tr', 'cv'],\n",
    "                          feval=self.specs.metric, evals_result=evals_result, verbose_eval=False)\n",
    "                df_results = (pd.DataFrame(evals_result['tr']), pd.DataFrame(evals_result['cv']))\n",
    "                yield bst, df_results\n",
    "        bsts, dfs = zip(*iter_samples())\n",
    "        \n",
    "        class save(O()):\n",
    "            Training = dfs\n",
    "            Boosters = bsts\n",
    "            class Results(O()):\n",
    "                train = tuple(dft[0].iloc[-1-params['early_stopping_round'], 0] for dft in dfs)\n",
    "                scores = tuple(dft[1].iloc[-1-params['early_stopping_round'], 0] for dft in dfs)\n",
    "                score = sum(scores) / len(scores)\n",
    "                nboost = tuple(len(dft[1])-params['early_stopping_round'] for dft in dfs)\n",
    "        self._save = save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specs for search logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### params searching specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LPS(O()):\n",
    "    class Discrete(O()):\n",
    "        enc = {\n",
    "            'learning_rate': [.05],\n",
    "            ('max_depth','num_leaves'): #10\n",
    "                [(6,1<<6),(8,1<<6),(8,1<<8),(10,1<<6),(10,1<<8),(10,1<<10),(12,1<<8),(12,1<<10),(12,1<<12),\n",
    "                 (-1,1<<8),(-1,1<<10),(-1,1<<12),(-1,1<<14)],\n",
    "            #('max','num'): #10\n",
    "            #    [(6,6),(9,7),(9,9),(12,8),(12,10),(12,12),(-1,8),(-1,10),(-1,12),(-1,14)],\n",
    "        }\n",
    "        \n",
    "    class OneByOne(O()):\n",
    "        class info(O()):\n",
    "            a = \"main [a]rray data of 3 values, [min mid max]\"\n",
    "            b =  \"[b]ack up value, i.e. default value if array doesn't give better results\"\n",
    "            cast = \"function to apply to values before using to cast to the right dtype\"\n",
    "            lim = \"maximum number of iterations of searching in this hyperparameter\"\n",
    "        class default(O()):\n",
    "            cast = keepSigFig(2)\n",
    "            lim = 2\n",
    "        data = {\n",
    "            'min_data_in_leaf': O(a=[1,60,375], cast=round),\n",
    "            'min_sum_hessian_in_leaf': O(a=[0,50,200]),\n",
    "            'lambda_l1': O(a=[0,.02,.2], b=0, lim=1),\n",
    "            'lambda_l2': O(a=[0,.02,.2], b=0, lim=1),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model search specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LMS(O()):\n",
    "    model = O(\n",
    "        time = 'time',\n",
    "        value = 'y',\n",
    "        target = 'target',\n",
    "        weight = 'weight1',\n",
    "    )\n",
    "    \n",
    "    metric = KaggleMetric()\n",
    "    search = LPS\n",
    "    \n",
    "    n_samps_per_feat = 8\n",
    "    \n",
    "    class Features(O()):\n",
    "        '''features selection groups'''\n",
    "        data = [\n",
    "            ['f1','f2','f3'],\n",
    "            ['f4','f5','f6'],\n",
    "        ]\n",
    "        func = lambda i: data[i//n_samps_per_feat] if i//n_samps_per_feat < len(data) else None\n",
    "    \n",
    "    class Samples(O()):\n",
    "        '''sample learning/cv split'''\n",
    "        # O(method='GroupShuffleSplit.2', kwargs=dict(n_splits=<(5)many>, test_size=.5, random_state=44), groups='quarter'),\n",
    "        enc = [\n",
    "            O(method='group.2', groups='quarter')\n",
    "        ]\n",
    "        \n",
    "    class Params(O()):\n",
    "        '''parameters constant settings'''\n",
    "        data = dict(\n",
    "            objective = 'binary',\n",
    "            num_iterations = 100000,\n",
    "            early_stopping_round = 50,\n",
    "            metric = 'None',\n",
    "            seed = 44,\n",
    "            bagging_seed = 45,\n",
    "            feature_fraction_seed = 46,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIVE TESTING WALK ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm = ModelManager('/big/data/search/fake')\n",
    "ms = ModelSearch(specs=LMS, mm=mm, X=F, Y=P)\n",
    "walk = ms.walk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, (1, 0), <>(train=[0.7214605834581501, 1.073667926072597], scores=[0.5675374430153964, 0.5639808673520671], score=0.5657591551837318, nboost=[245, 106]))\n",
      "CPU times: user 25 s, sys: 3.32 s, total: 28.3 s\n",
      "Wall time: 5.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i += 1\n",
    "print((i,) + next(walk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================= ACTUAL PRODUCTION RUN ===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Live Run Testing (still, just testing) ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### making test variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "ppf = norm.ppf\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_new_vars():\n",
    "    n = 1000\n",
    "    ##################RANDOMIZE#######################\n",
    "    while True:\n",
    "        try:\n",
    "            u = np.random.uniform(size=(5, n))\n",
    "            assert (u!=0).all()\n",
    "            break\n",
    "        except AssertionError:\n",
    "            continue\n",
    "    uu = u.copy()\n",
    "    uu[0][np.random.randint(252, size=n) == 0] = np.nan\n",
    "    uu[1][np.random.randint(173, size=n) == 0] = np.nan\n",
    "    uu[2][np.random.randint(81, size=n) == 0] = np.nan\n",
    "    uu[3][np.random.randint(27, size=n) == 0] = np.nan\n",
    "    #################ENDRANDOM######################\n",
    "    F = pd.DataFrame({'hax': np.arange(n)})\n",
    "    F['time'] = F.hax // 10\n",
    "    F['assetCodeId'] = F.hax % 10\n",
    "    F['quarter'] = F.hax // 100\n",
    "    P = F.copy()\n",
    "    F['alex'] = ppf(u[0]*5%.99+eps)*ppf(u[1]*7%.99+eps)\n",
    "    F['bob'] = ppf(.5+.49*uu[2]*np.sin(F.assetCodeId.values**10))*np.exp(uu[3])\n",
    "    F['carol'] = -np.log(u[0]) + 4 * np.sin(1/uu[1])\n",
    "    F['dean'] = u[1] + 2 * uu[2] - np.exp(-uu[3])\n",
    "    F['edgar'] = ppf( (uu[2]**2-2*u[1]+(u[0]-u[3])**3-.5*u[1]**2) % .99 + eps )\n",
    "    P['y'] = (ppf((u[0]+u[1])/2) + ppf((u[2]+u[3])/2) + .2*ppf(u[4])) * 1e-1\n",
    "    P['universe'] = (~np.isnan(uu[0])).astype(float)\n",
    "    return F, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F, P = make_new_vars()\n",
    "#Path('lighttest.pkl').write_bytes(pickle.dumps((F, P)))\n",
    "F, P = pickle.loads(Path('lighttest.pkl').read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P['target'] = P.y>0\n",
    "P['upDown'] = (P.target*2-1)\n",
    "P['upDown1'] = P.upDown*P.universe.astype(int)\n",
    "P['absVal'] = np.abs(P.y)\n",
    "P['absVal1'] = P.absVal*P.universe\n",
    "P['weight'] = P.absVal#.qtl()\n",
    "P['weight1'] = P.weight*P.universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hax</th>\n",
       "      <th>time</th>\n",
       "      <th>assetCodeId</th>\n",
       "      <th>quarter</th>\n",
       "      <th>alex</th>\n",
       "      <th>bob</th>\n",
       "      <th>carol</th>\n",
       "      <th>dean</th>\n",
       "      <th>edgar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.655924</td>\n",
       "      <td>1.336200</td>\n",
       "      <td>0.601672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.033782</td>\n",
       "      <td>1.139956</td>\n",
       "      <td>8.008799</td>\n",
       "      <td>1.244428</td>\n",
       "      <td>0.349115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034335</td>\n",
       "      <td>-0.333275</td>\n",
       "      <td>2.013295</td>\n",
       "      <td>1.549419</td>\n",
       "      <td>1.363992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.131567</td>\n",
       "      <td>-0.049046</td>\n",
       "      <td>5.325198</td>\n",
       "      <td>0.450859</td>\n",
       "      <td>0.940187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.636082</td>\n",
       "      <td>0.267445</td>\n",
       "      <td>4.698875</td>\n",
       "      <td>0.670703</td>\n",
       "      <td>-0.449314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hax  time  assetCodeId  quarter      alex       bob     carol      dean  \\\n",
       "0    0     0            0        0 -0.012198  0.000000  3.655924  1.336200   \n",
       "1    1     0            1        0 -0.033782  1.139956  8.008799  1.244428   \n",
       "2    2     0            2        0  0.034335 -0.333275  2.013295  1.549419   \n",
       "3    3     0            3        0 -2.131567 -0.049046  5.325198  0.450859   \n",
       "4    4     0            4        0  1.636082  0.267445  4.698875  0.670703   \n",
       "\n",
       "      edgar  \n",
       "0  0.601672  \n",
       "1  0.349115  \n",
       "2  1.363992  \n",
       "3  0.940187  \n",
       "4 -0.449314  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hax</th>\n",
       "      <th>time</th>\n",
       "      <th>assetCodeId</th>\n",
       "      <th>quarter</th>\n",
       "      <th>y</th>\n",
       "      <th>universe</th>\n",
       "      <th>target</th>\n",
       "      <th>upDown</th>\n",
       "      <th>upDown1</th>\n",
       "      <th>absVal</th>\n",
       "      <th>absVal1</th>\n",
       "      <th>weight</th>\n",
       "      <th>weight1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076738</td>\n",
       "      <td>0.076738</td>\n",
       "      <td>0.076738</td>\n",
       "      <td>0.076738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048210</td>\n",
       "      <td>0.048210</td>\n",
       "      <td>0.048210</td>\n",
       "      <td>0.048210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.089397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089397</td>\n",
       "      <td>0.089397</td>\n",
       "      <td>0.089397</td>\n",
       "      <td>0.089397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>0.028319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.103184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.103184</td>\n",
       "      <td>0.103184</td>\n",
       "      <td>0.103184</td>\n",
       "      <td>0.103184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hax  time  assetCodeId  quarter         y  universe  target  upDown  \\\n",
       "0    0     0            0        0  0.076738       1.0    True       1   \n",
       "1    1     0            1        0  0.048210       1.0    True       1   \n",
       "2    2     0            2        0  0.089397       1.0    True       1   \n",
       "3    3     0            3        0 -0.028319       1.0   False      -1   \n",
       "4    4     0            4        0 -0.103184       1.0   False      -1   \n",
       "\n",
       "   upDown1    absVal   absVal1    weight   weight1  \n",
       "0        1  0.076738  0.076738  0.076738  0.076738  \n",
       "1        1  0.048210  0.048210  0.048210  0.048210  \n",
       "2        1  0.089397  0.089397  0.089397  0.089397  \n",
       "3       -1  0.028319  0.028319  0.028319  0.028319  \n",
       "4       -1  0.103184  0.103184  0.103184  0.103184  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LPS(O()):\n",
    "    class Discrete(O()):\n",
    "        enc = {\n",
    "            'learning_rate': [.05],\n",
    "            ('max_depth','num_leaves'):\n",
    "                [(3,1<<3),(6,1<<6),(-1,1<<9)]\n",
    "        }\n",
    "        \n",
    "    class OneByOne(O()):\n",
    "        class info(O()):\n",
    "            a = \"main [a]rray data of 3 values, [min mid max]\"\n",
    "            b =  \"[b]ack up value, i.e. default value if array doesn't give better results\"\n",
    "            cast = \"function to apply to values before using to cast to the right dtype\"\n",
    "            lim = \"maximum number of iterations of searching in this hyperparameter\"\n",
    "        class default(O()):\n",
    "            cast = keepSigFig(2)\n",
    "            lim = 2\n",
    "        data = {\n",
    "            'min_data_in_leaf': O(a=[1,6,37], cast=round),\n",
    "            'min_sum_hessian_in_leaf': O(a=[0,5,20], b=0),\n",
    "            'lambda_l1': O(a=[0,.02,.2], b=0, lim=1),\n",
    "            'lambda_l2': O(a=[0,.02,.2], b=0, lim=1),\n",
    "        }\n",
    "\n",
    "\n",
    "class LMS(O()):\n",
    "    model = O(\n",
    "        time = 'time',\n",
    "        value = 'y',\n",
    "        target = 'target',\n",
    "        weight = 'weight1',\n",
    "    )\n",
    "    \n",
    "    metric = KaggleMetric()\n",
    "    search = LPS\n",
    "    \n",
    "    class Features(O()):\n",
    "        '''features selection groups'''\n",
    "        data = [\n",
    "            ['alex', 'bob', 'carol'],\n",
    "            ['bob', 'dean', 'edgar'],\n",
    "            ['alex', 'carol', 'edgar']\n",
    "        ]\n",
    "    \n",
    "    class Samples(O()):\n",
    "        '''sample learning/cv split'''\n",
    "        enc = [\n",
    "            O(method='group.2', groups='quarter', data=[\n",
    "                [0, 1, 2, 3, 4],\n",
    "                [5, 6, 7, 8, 9]\n",
    "            ]),\n",
    "        ]\n",
    "        \n",
    "    class Params(O()):\n",
    "        '''parameters constant settings'''\n",
    "        data = dict(\n",
    "            objective = 'binary',\n",
    "            num_iterations = 100000,\n",
    "            early_stopping_round = 50,\n",
    "            metric = 'None',\n",
    "            seed = 44,\n",
    "            bagging_seed = 45,\n",
    "            feature_fraction_seed = 46,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm = ModelManager('/big/data/search/test')\n",
    "ms = ModelSearch(specs=LMS, mm=mm, X=F, Y=P)\n",
    "walk = ms.walk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "(3, (0, 0), <>(train=(1.9117454484505862, 1.8610316178296742), scores=(1.7104576224320605, 1.7875447679802607), score=1.7490011952061606, nboost=(93, 128)))\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print((i,) + next(walk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -.-.-.-.-.-.-.-.-.-.-.-.-.- old shit / testing -.-.-.-.-.-.-.-.-.-.-.-.-.-.-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'What' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-dc92f66a5036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mYo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mWhat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mderp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-dc92f66a5036>\u001b[0m in \u001b[0;36mYo\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mWhat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mderp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mclass\u001b[0m \u001b[0mAnother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0myep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mYo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-dc92f66a5036>\u001b[0m in \u001b[0;36mAnother\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mderp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mAnother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0myep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mYo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'What' is not defined"
     ]
    }
   ],
   "source": [
    "# PUREL TESTING\n",
    "class HI(O()):\n",
    "    class DERP():\n",
    "        val = -99\n",
    "        dir = Path('.')\n",
    "        def yo(x):\n",
    "            def y(a):\n",
    "                return x(a) + 1000\n",
    "            return y\n",
    "        my = O(what=yo(lambda a: a ** 2))\n",
    "        hm = O(func=lambda x: x * __class__.val, goto=lambda x: __class__.dir/x)\n",
    "        class WHAT(O()):\n",
    "            dude = lambda x: x + 10\n",
    "        class YES(O()):\n",
    "            dude = WHAT.dude\n",
    "HI.DERP.my.what(5)\n",
    "HI.DERP.hm.func(5)\n",
    "HI.DERP.dir = Path('what')\n",
    "HI.DERP.hm.goto('.git')\n",
    "HI.DERP.WHAT.dude(0)\n",
    "\n",
    "# ANOTHER PURE TESTING\n",
    "def dothe(self):\n",
    "    self.val = 4\n",
    "    top = 100\n",
    "    class Derp(O()):\n",
    "        def func(x):\n",
    "            return x + self.val\n",
    "        def top(y):\n",
    "            return y * top\n",
    "    self.derp = Derp\n",
    "item = Stop()\n",
    "dothe(item)\n",
    "item.derp.top(3)\n",
    "\n",
    "class Yo(O()):\n",
    "    class What(O()):\n",
    "        derp = 5\n",
    "    class Another(O()):\n",
    "        yep = What.derp\n",
    "Yo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
