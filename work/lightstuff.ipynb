{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "import json, copy, operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST = True; PROD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I = lambda x: x\n",
    "logavg = lambda x,y: math.expm1((math.log1p(x)+math.log1p(y))/2)\n",
    "keepSigFig = lambda n: lambda x: round(x, -int(math.floor(math.log10(abs(x)))) + (n - 1)) if x else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frzset = lambda x: x if isinstance(x, frozenset) else frozenset(x)\n",
    "pydict = lambda x: O.pycopy(x) if isinstance(x, O) else copy.deepcopy(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #!#!#!#!#!#!#!#!#!#!#! Save System #!#!#!#!#!#!#!#!#!#!#!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IndexFileSystem():\n",
    "    def __init__(self, directory, key):\n",
    "        self.dir = directory if isinstance(directory, Path) else Path(directory)\n",
    "        self.dir.mkdir(exist_ok=True, parents=True)\n",
    "        assert isinstance(key, str), \"key must be string\"\n",
    "        self.key = key\n",
    "        self.io = O()\n",
    "\n",
    "    def iterIndices(self):\n",
    "        for dot_params in self.dir.glob('*.' + self.key):\n",
    "            yield int(dot_params.stem)\n",
    "\n",
    "    def getFilePath(self, name, *, i):\n",
    "        return self.dir / (str(i) + '.' + name)\n",
    "\n",
    "    @staticmethod\n",
    "    def readWrapper(read):\n",
    "        '''wraps io read operations to safely return None if file does not exist'''\n",
    "        @wraps(read)\n",
    "        def read_safely(*a, **k):\n",
    "            try:\n",
    "                return read(*a, **k)\n",
    "            except FileNotFoundError:\n",
    "                return None\n",
    "        return read_safely\n",
    "\n",
    "    def assignIO(self, name, *, read, write, format='custom'):\n",
    "        assert format in ['bytes', 'text', 'custom'], \"argument `format` must be one of 'bytes' or 'text' or 'custom'\"\n",
    "        if format in ['bytes', 'text']:\n",
    "            self.io[name] = O(\n",
    "                read = self.readWrapper( lambda *,i: read(getattr(self.getFilePath(name, i=i), 'read_'+format)()) ),\n",
    "                write = lambda x,*,i: getattr(self.getFilePath(name, i=i), 'write_'+format)(write(x))\n",
    "            )\n",
    "        elif format == 'custom':\n",
    "            def readCustom(*, i):\n",
    "                file = self.getFilePath(name, i=i)\n",
    "                if not file.exists():\n",
    "                    return None\n",
    "                try:\n",
    "                    return read(file)\n",
    "                except Exception:\n",
    "                    return read(str(file))\n",
    "            def writeCustom(*, i):\n",
    "                file = self.getFilePath(name, i=i)\n",
    "                try:\n",
    "                    write(x, file=file)\n",
    "                except Exception:\n",
    "                    write(x, file=str(file))\n",
    "            self.io[name] = O(read=readCustom, write=writeCustom)\n",
    "\n",
    "class IndexDataStore():    \n",
    "    def __init__(self, file, _factory_=False):\n",
    "        if not _factory_:\n",
    "            assert False, \"Cannot instantiate IndexDataStore normally. Please use factory static method.\"\n",
    "        self.file = file\n",
    "        self.op = O()\n",
    "        self.lists = O()\n",
    "        self.key = None\n",
    "        self.keyFunc = lambda keyVal, *, client=False: object()\n",
    "        self.tbl = {}\n",
    "        self.nextIndex = 0\n",
    "        \n",
    "    def load(self):\n",
    "        indices = sorted(self.file.iterIndices())\n",
    "        n = self.nextIndex = (max(indices) if indices else -1) + 1\n",
    "        for name, _ in dict.items(self.lists):\n",
    "            self.lists[name] = [None] * self.nextIndex\n",
    "        \n",
    "        for i in indices:\n",
    "            for name in self.lists:\n",
    "                if self.op[name].load:\n",
    "                    self.op[name].load(i=i)\n",
    "                \n",
    "        if self.key is not None:\n",
    "            self.assignKey(self.key, self.keyFunc)\n",
    "            \n",
    "    def i(self, key, dry=False, client=True, keep=True, save=True):\n",
    "        keyVal = self.keyFunc(key, client=client)\n",
    "        \n",
    "        if keyVal not in self.tbl and not dry:\n",
    "            for name in self.lists:\n",
    "                assert len(self.lists[name]) == self.nextIndex, \"idk internal error\"\n",
    "                self.lists[name].append(None)\n",
    "            self.tbl[keyVal] = self.nextIndex\n",
    "            if save and self.op[self.key].save:\n",
    "                self.op[self.key].save(key, i=self.nextIndex, keep=keep)\n",
    "            elif keep and self.op[self.key].keep:\n",
    "                self.op[self.key].keep(key, i=self.nextIndex, client=client)\n",
    "            self.nextIndex += 1\n",
    "        elif keyVal not in self.tbl and dry:\n",
    "            return None\n",
    "        \n",
    "        return self.tbl[keyVal]\n",
    "            \n",
    "    def save(self, keep=True, **kwargs):\n",
    "        '''`client` is always True'''\n",
    "        assert ('i' in kwargs) ^ (self.key in kwargs), \"call to `save` must include exactly one of i= or the key name =\"\n",
    "        if 'i' in kwargs:\n",
    "            i = kwargs['i']\n",
    "            del kwargs['i']\n",
    "        else:\n",
    "            i = self.i(kwargs[self.key])\n",
    "        \n",
    "        for name in kwargs:\n",
    "            if name == self.key: # already saved in `self.i(save=True)` above\n",
    "                continue\n",
    "            if name not in self.op:\n",
    "                raise AssertionError(f\"given save item '{name}' does not have data store ops initialized\")\n",
    "            if self.op[name].save:\n",
    "                self.op[name].save(kwargs[name], i=i, keep=keep)\n",
    "            \n",
    "    def get(self, name, **kwargs):\n",
    "        assert len(kwargs) == 1 and ('i' in kwargs or self.key in kwargs), \"must give assigned 'key' or i\"\n",
    "        if 'i' in kwargs:\n",
    "            i = kwargs['i']\n",
    "            del kwargs['i']\n",
    "        else:\n",
    "            i = self.i(kwargs[self.key], dry=True)\n",
    "        if i is None:\n",
    "            return None\n",
    "        got = self.lists[name][i]\n",
    "        if got is None and self.op[name].load:\n",
    "            got = self.op[name].load(i=i)\n",
    "        return got\n",
    "        \n",
    "    ##################### INSTANCE BUILDING METHODS ##################### : \n",
    "    def assignKey(self, name, func):\n",
    "        assert name in self.lists, \"key name must first be assigned ops\"\n",
    "        self.key = name\n",
    "        self.keyFunc = func\n",
    "        self.tbl = {self.keyFunc(x): i for i,x in enumerate(self.lists[self.key]) if x is not None}\n",
    "        \n",
    "    def assignOperations(self, name, *, load=I, save=I, keep=I, keepSaved=None, keepClient=None):\n",
    "        if keepClient is None:\n",
    "            keepClient = keep\n",
    "            \n",
    "        #NOTE #TODE? the method names below conflict with the local vars up here, and current Python syntax takes\n",
    "        # the variables up here. Should this change the code below will stop working. But this is the \"nicest\" way to do it\n",
    "        class the(O()):\n",
    "            def load(*, i, keep=True):\n",
    "                if not load:\n",
    "                    return None\n",
    "                read = self.file.io[name].read(i=i)\n",
    "                x = load(read) if read is not None else None\n",
    "                if keep and self.op[name].keep:\n",
    "                    self.lists[name][i] = self.op[name].keep(x, i=i)\n",
    "                return x\n",
    "            \n",
    "            def save(x, *, i, keep=True):\n",
    "                if not save:\n",
    "                    return\n",
    "                saved_x = save(x)\n",
    "                self.file.io[name].write(saved_x, i=i)\n",
    "                if keep and self.op[name].keep:\n",
    "                    try:\n",
    "                        self.lists[name][i] = self.op[name].keep(saved_x, i=i, saved=True)\n",
    "                        assert self.lists[name][i] is not None\n",
    "                    except (TypeError, AssertionError):\n",
    "                        self.lists[name][i] = self.op[name].keep(x, i=i, client=True)\n",
    "                \n",
    "            def keep(x, *, i, saved=False, client=False):\n",
    "                if x is None:\n",
    "                    return None\n",
    "                assert not (saved and client), \"only one of `saved` and `client` can be specified\"\n",
    "                if not any([keep, keepSaved, keepClient]):\n",
    "                    return None\n",
    "                kept = None\n",
    "                if saved and keepSaved:\n",
    "                    kept = keepSaved(x)\n",
    "                elif client and keepClient:\n",
    "                    kept = keepClient(x)\n",
    "                elif not saved and not client and keep:\n",
    "                    kept = keep(x)\n",
    "                if kept is not None:\n",
    "                    self.lists[name][i] = kept\n",
    "                return kept\n",
    "            \n",
    "        if not load:\n",
    "            the.load = False\n",
    "        if not save:\n",
    "            the.save = False\n",
    "        if not any([keep, keepSaved, keepClient]):\n",
    "            the.keep = False\n",
    "            \n",
    "        self.op[name] = the\n",
    "        if name not in self.lists:\n",
    "            self.lists[name] = [None] * self.nextIndex\n",
    "    \n",
    "    \n",
    "@staticmethod\n",
    "def __IndexDataStore__from_specs(specs, **kwargs):\n",
    "    for k, v in kwargs.items():\n",
    "        specs[k] = v\n",
    "    \n",
    "    f = IndexFileSystem(specs.dir, specs.key)\n",
    "    d = IndexDataStore(f, _factory_=True)\n",
    "    \n",
    "    _readwriteformat = {'read', 'write', 'format'}\n",
    "    _loadsavekeep = {'load', 'save', 'keep', 'keepSaved', 'keepClient'}\n",
    "    for name, val in dict.items(specs.op):\n",
    "        f.assignIO(name, **{a: b for a,b in dict.items(val) if a in _readwriteformat})\n",
    "        d.assignOperations(name, **{a: b for a,b in dict.items(val) if a in _loadsavekeep})\n",
    "        \n",
    "    keyFuncClient = specs.keyFuncClient if 'keyFuncClient' in specs else specs.keyFunc\n",
    "    keyFunc = lambda keyVal, *, client=False: keyFuncClient(keyVal) if client else specs.keyFunc(keyVal)\n",
    "    d.assignKey(specs.key, keyFunc)\n",
    "    \n",
    "    d.load()\n",
    "    return d\n",
    "IndexDataStore.from_specs = __IndexDataStore__from_specs\n",
    "\n",
    "\n",
    "def json_default(o):\n",
    "    if isinstance(o, np.int64):\n",
    "        return int(o)  \n",
    "    raise TypeError\n",
    "    \n",
    "class __IndexDataStore__SpecsHelper(metaclass=staticclass):\n",
    "    def json(op):\n",
    "        op.format = 'text'\n",
    "        op.read = json.loads\n",
    "        op.write = lambda x: json.dumps(x, default=json_default)\n",
    "        return op\n",
    "    def pickle(op):\n",
    "        op.format = 'bytes'\n",
    "        op.read = pickle.loads\n",
    "        op.write = pickle.dumps\n",
    "        return op\n",
    "IndexDataStore.SpecsHelper = __IndexDataStore__SpecsHelper\n",
    "IDSSH = IndexDataStore.SpecsHelper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelManager():\n",
    "    features_dir = '.features'\n",
    "    samples_dir = '.samples'\n",
    "    models_dir = 'models'\n",
    "    \n",
    "    def __init__(self, directory, f_specs=None, s_specs=None, p_specs=None): #GLOBAL FDS SDS PDS\n",
    "        global FDS, SDS, PDS\n",
    "        if f_specs is None:\n",
    "            f_specs = FDS\n",
    "        if s_specs is None:\n",
    "            s_specs = SDS\n",
    "        if p_specs is None:\n",
    "            p_specs = PDS\n",
    "        self.p_specs = p_specs\n",
    "        self.dir = directory if isinstance(directory, Path) else Path(directory)\n",
    "        self.dir.mkdir(exist_ok=True) # no parents because this is user facing and enabling parents could get gnarly\n",
    "        self.F = IndexDataStore.from_specs(f_specs, dir=self.dir/self.features_dir)\n",
    "        self.S = IndexDataStore.from_specs(s_specs, dir=self.dir/self.samples_dir)\n",
    "        (self.dir/self.models_dir).mkdir(exist_ok=True)\n",
    "        self.load()\n",
    "        \n",
    "    def load(self):\n",
    "        self.pms = {}\n",
    "        for fi, si in self.iterIndices():\n",
    "            self.make_params_manager(i=(fi, si))\n",
    "        \n",
    "    def iterIndices(self):\n",
    "        for fdir in (self.dir/self.models_dir).iterdir():\n",
    "            try:\n",
    "                fi = int(fdir.name)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            assert fdir.is_dir(), \"folder in models folder whose name is just a number must be a folder\"\n",
    "            assert fi < self.F.nextIndex, \"features folder found with greater index than what has been labelled\"\n",
    "            for sdir in fdir.iterdir():\n",
    "                try:\n",
    "                    si = int(sdir.name)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                assert sdir.is_dir(), \"folder in models folder 1 layer down whose name is just a number must be a folder\"\n",
    "                assert si < self.S.nextIndex, \"samples folder found with greater index than what has been labelled\"\n",
    "                yield (fi, si)\n",
    "        \n",
    "    def make_params_manager(self, features=None, samples=None, i=None):\n",
    "        assert (\n",
    "            not ((features is None) ^ (samples is None)) and\n",
    "            ((features is not None and samples is not None) ^ (i is not None)),\n",
    "            \"invalid arguments to `make_param_manager`\"\n",
    "        )\n",
    "        if i is None:\n",
    "            i = self.F.i(features), self.S.i(samples)\n",
    "        fi, si = i\n",
    "        assert 0 <= fi < self.F.nextIndex and 0 <= si < self.S.nextIndex, \"bad arguments to `make_params_manager`\"\n",
    "        pm = IndexDataStore.from_specs(self.p_specs, dir=self.dir/self.models_dir/str(fi)/str(si))\n",
    "        self.pms[fi, si] = pm\n",
    "        return pm\n",
    "    \n",
    "    def i(features, samples): # purely convenience public interface\n",
    "        return self.F.i(features), self.S.i(samples)\n",
    "        \n",
    "    def PM(self, features, samples, get_i=False):\n",
    "        fi, si = self.F.i(features), self.S.i(samples)\n",
    "        if get_i:\n",
    "            return self.iPM(fi, si), (fi, si)\n",
    "        else:\n",
    "            return self.iPM(fi, si)\n",
    "        \n",
    "    def iPM(self, fi, si):\n",
    "        if (fi, si) not in self.pms:\n",
    "            self.make_params_manager(i=(fi, si))\n",
    "        return self.pms[fi, si]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specs for managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbNullDataset = lgb.Dataset(pd.DataFrame({'_a_': np.arange(88), '_b_': np.arange(88)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param search $\\textbf{SAVING}$ specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PDS(O()):\n",
    "    '''data transformation code inside `op` object:\n",
    "\n",
    "    client --save(+write)--> disk; client --keep--> memory; disk --load(+read)--> memory\n",
    "\n",
    "    read = text/bytes stream -> as-is object read from file\n",
    "    write = object to save as is to file -> text/bytes stream\n",
    "    load = as-is object read from file -> object to be loaded in memory\n",
    "    save = raw object given by client -> object to save as-is to file\n",
    "    keep = as-is object read from file -> object to keep in memory\n",
    "    keepClient = raw object given by client -> object to keep in memory\n",
    "    '''\n",
    "\n",
    "    key = 'Params'\n",
    "    keyFunc = lambda params: tuple(sorted(dict.items(params)))\n",
    "\n",
    "    class op(O()):\n",
    "        @IDSSH.json\n",
    "        class Params(O()):\n",
    "            '''just a dict of the parameter value assignments'''\n",
    "            keepClient = dict\n",
    "            \n",
    "        @IDSSH.json\n",
    "        class Results(O()):\n",
    "            '''should be a dict-like of various things, most importantly including \"score\"'''\n",
    "            load = lambda x: O(**x)\n",
    "            save = pydict\n",
    "            keepClient = lambda x: O.mycopy(x) if isinstance(x, O) else O(**x)\n",
    "            \n",
    "        @IDSSH.pickle\n",
    "        class Training(O()):\n",
    "            '''tuple (aligning with samples training/cv split tuple) of LightGBM training eval DataFrames'''\n",
    "            keep = False\n",
    "            \n",
    "        @IDSSH.pickle\n",
    "        class Boosters(O()):\n",
    "            '''the actual lgb.Booster model. well, a tuple of them, one for each cv set'''\n",
    "            #read = lambda file: lgb.Booster(model_file=file)\n",
    "            load = lambda x: tuple(lgb.Booster(train_set=lgbNullDataset).model_from_string(s, verbose=False) for s in x)\n",
    "            #write = lambda x, file: x.save_model(file)\n",
    "            save = lambda x: tuple(b.model_to_string() for b in x)\n",
    "            keep = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature selection / days sampling $\\textbf{SAVING}$ specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FDS(O()):\n",
    "    key = 'Feats'\n",
    "    keyFunc = lambda features: features # internally already coverted to immutable\n",
    "    keyFuncClient = frzset\n",
    "    class op(O()):\n",
    "        '''container of feature name strings'''\n",
    "        @IDSSH.json\n",
    "        class Feats(O()):\n",
    "            load = frozenset\n",
    "            save = sorted\n",
    "            keepClient = frozenset\n",
    "    \n",
    "class SDS(O()):\n",
    "    key = 'Samps'\n",
    "    keyFunc = lambda samples: samples # internally already converted immutable\n",
    "    keyFuncClient = lambda samples: tuple((frzset(tr), frzset(cv)) for tr, cv in samples)\n",
    "    class op(O()):\n",
    "        @IDSSH.json\n",
    "        class Samps(O()):\n",
    "            '''tuple (num samples) of 2-tuples of tr/cv containers of the canonical index values for the split'''\n",
    "            load = lambda samples: tuple((frzset(tr), frzset(cv)) for tr, cv in samples)\n",
    "            save = lambda samples: [[sorted(tr), sorted(cv)] for tr, cv in samples]\n",
    "            keepClient = load\n",
    "        @IDSSH.json\n",
    "        class Ctor(O()):\n",
    "            '''should be O specs object'''\n",
    "            save = pydict\n",
    "            keepClient = save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~!~!~!~!~!~! Model (features/samples/parameters) Search ~!~!~!~!~!~!~!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter search logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ParamSearch():\n",
    "    mix = staticmethod(logavg)\n",
    "    \n",
    "    def __init__(self, specs):\n",
    "        self.specs = O.mycopy(specs)\n",
    "        self.setup_specs()\n",
    "        \n",
    "    def setup_specs(self):\n",
    "        dsc = self.specs.Discrete\n",
    "        dsc.keys = list(flatten( dsc.enc.keys() ))\n",
    "        dsc.assigns = [list(flatten(x)) for x in product(* dsc.enc.values() )]\n",
    "        obo = self.specs.OneByOne\n",
    "        for k,v in dict.items(obo.data):\n",
    "            for i,x in dict.items(obo.default):\n",
    "                if i not in v:\n",
    "                    v[i] = x\n",
    "    \n",
    "    def search(self):\n",
    "        dsc, obo = self.specs.Discrete, self.specs.OneByOne\n",
    "        for assign in dsc.assigns:\n",
    "            params = dict(zip(dsc.keys, assign))\n",
    "            coroutine = self.one_by_one()\n",
    "            for addon in coroutine:\n",
    "                params.update(addon)\n",
    "                coroutine.send((yield copy.deepcopy(params))); assert (yield) is None\n",
    "        \n",
    "        \n",
    "    def one_by_one(self):\n",
    "        obod = self.specs.OneByOne.data\n",
    "        \n",
    "        #! main algorithm ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        \n",
    "        # initialize loop variables\n",
    "        params = {k: (v.b if 'b' in v else v.a[1]) for k,v in dict.items(obod)}\n",
    "        ranges = {k: v.a for k,v in dict.items(obod)}\n",
    "        scores = {k: [-np.inf, -np.inf] for k in params}\n",
    "        isdone = {k: False for k in params}\n",
    "        \n",
    "        # pre loop one-off work\n",
    "        base_score = yield params; assert (yield) is None\n",
    "        \n",
    "        # loop\n",
    "        for i in range(999_999_999):\n",
    "            #! try new parameter values ############################## part A of loop work\n",
    "            \n",
    "            # initialize local loop variable\n",
    "            new_scores = {k: [-np.inf, -np.inf] for k in params}\n",
    "            new_params = {k: ( obod[k].cast(self.mix(v[0], v[1])),\n",
    "                               obod[k].cast(self.mix(v[1], v[2])) ) for k,v in dict.items(ranges)}\n",
    "            \n",
    "            # finish condition check\n",
    "            isdone = {k: v or i>=obod[k].lim for k,v in dict.items(isdone)}\n",
    "            if all(isdone.values()):\n",
    "                break\n",
    "                \n",
    "            # try new parameter values for all parameters\n",
    "            for key in list(params):\n",
    "                if i >= obod[key].lim:\n",
    "                    continue\n",
    "                orig = params[key]\n",
    "                params[key] = new_params[key][0]\n",
    "                scores[key][0] = yield params; assert (yield) is None\n",
    "                params[key] = new_params[key][1]\n",
    "                scores[key][1] = yield params; assert (yield) is None\n",
    "                params[key] = orig\n",
    "            \n",
    "            #! start setting up values for next loop ######################## part B of loop work\n",
    "            \n",
    "            # set params to the best found and see if it betters score, updating ranges also\n",
    "            #CODE num_nochange = 0\n",
    "            for key in list(params):\n",
    "                if scores[key][0] > base_score and scores[key][0] >= scores[key][1]:\n",
    "                    params[key] = new_params[key][0]\n",
    "                    ranges[key] = [ranges[key][0], params[key], ranges[key][1]]\n",
    "                elif scores[key][1] > base_score and scores[key][1] >= scores[key][0]:\n",
    "                    params[key] = new_params[key][1]\n",
    "                    ranges[key] = [ranges[key][1], params[key], ranges[key][2]]\n",
    "                else:\n",
    "                    ranges[key] = [new_params[key][0], ranges[key][1], new_params[key][1]]\n",
    "                    #num_nochange += 1\n",
    "                \n",
    "            # send out new params\n",
    "            #CODE if num_nochange < len(params):\n",
    "            base_score = yield params; assert (yield) is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features / Samples(train/cv split) search logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the Kaggle metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KaggleMetric():\n",
    "    def __init__(self, incr=0):\n",
    "        self.incr = incr\n",
    "    \n",
    "    def attach(self, ms):\n",
    "        L, s = ms._L, ms._s\n",
    "        for Ltr, Lcv, tr, cv in zip(L.tr, L.cv, s.tr, s.cv):\n",
    "            Ltr.timeFactor = ms.Y.time[tr].factorize()[0]\n",
    "            Lcv.timeFactor = ms.Y.time[cv].factorize()[0]\n",
    "            Ltr.value = (ms.Y.upDown1*ms.Y.absVal1)[tr]\n",
    "            Lcv.value = (ms.Y.upDown1*ms.Y.absVal1)[cv]\n",
    "            Ltr.i = 0\n",
    "            Lcv.i = 0\n",
    "    \n",
    "    def __call__(self, preds, valid_data):\n",
    "        df_time = valid_data.timeFactor\n",
    "        #labels = valid_data.get_label()\n",
    "        values = valid_data.value\n",
    "        #assert len(labels) == len(df_time)\n",
    "\n",
    "        preds = preds*2-1\n",
    "        #labels = labels*2-1\n",
    "        x_t = preds * values\n",
    "\n",
    "        # Here we take advantage of the fact that `labels` (used to calculate `x_t`)\n",
    "        # is a pd.Series and call `group_by`\n",
    "        x_t_sum = x_t.groupby(df_time).sum()\n",
    "        score = x_t_sum.mean() / x_t_sum.std()\n",
    "\n",
    "        valid_data.i += self.incr\n",
    "        return 'kaggle', score+valid_data.i, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model searching logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold\n",
    "        \n",
    "class ModelSearch():\n",
    "    \n",
    "    def __init__(self, specs, mm, *, X, Y, log=None):\n",
    "        self.specs = specs\n",
    "        global LOG\n",
    "        self.log = log if log is not None else LOG\n",
    "        self.mm = mm\n",
    "        assert (X.index == Y.index).all()\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.setup_specs()\n",
    "        \n",
    "    def setup_specs(self):\n",
    "        self.specs.Samples.data = []\n",
    "        for code in self.specs.Samples.enc:\n",
    "            if code.method == 'group.2':\n",
    "                tr, cv = set(code.data[0]), set(code.data[1])\n",
    "                tr, cv = self.Y[code.groups].isin(tr), self.Y[code.groups].isin(cv)\n",
    "                tr, cv = self.Y.index[tr], self.Y.index[cv]\n",
    "                self.specs.Samples.data += [((tr, cv), (cv, tr))]\n",
    "            elif code.method == 'GroupShuffleSplit.2':\n",
    "                tr, cv = next(GroupShuffleSplit(**code.kwargs).split(self.X, self.Y, groups=self.Y[code.groups]))\n",
    "                tr, cv = self.Y.index[tr], self.Y.index[cv]\n",
    "                self.specs.Samples.data += [((tr, cv), (cv, tr))]\n",
    "#             elif code.method == 'GroupKFold':\n",
    "#                 self.specs.Samples.data.append(tuple(GroupKFold(**code.kwargs)\n",
    "#                                                      .split(self.X, self.Y, groups=self.Y[code.groups])))\n",
    "            else:\n",
    "                assert False, f'sampling method \"{code.method}\" not implemented'\n",
    "        \n",
    "    def walk(self):\n",
    "        for feats, (samps, sampsEnc) in product(self.specs.Features.data,\n",
    "                                                zip(self.specs.Samples.data, self.specs.Samples.enc)):\n",
    "            best_score = -np.inf\n",
    "            pm, i = self.mm.PM(feats, samps, get_i=True) # this also saves feats and samps\n",
    "            self._pm = pm\n",
    "            self.mm.S.save(Samps=samps, Ctor=sampsEnc) #TODO maybe refactor this saving Ctor part out to somewhere better?\n",
    "            \n",
    "            self.setup_training(feats, samps, i=i)\n",
    "            search = ParamSearch(self.specs.search)\n",
    "            loop = search.search()\n",
    "            for params in loop: # params are deepcopied out, so can safely save them as-is!\n",
    "                paramsUse = dict(**self.specs.Params.data, **params)\n",
    "                results = pm.get('Results', Params=params)\n",
    "                if not results:\n",
    "                    self.log('training...')\n",
    "                    self.train(paramsUse) # sets some state attributes in self: self._save\n",
    "                    results = self._save.Results\n",
    "                    if results['score'] > best_score:\n",
    "                        self._best = (dict(**params), O(**self._save)) #TODO I still copy params here to be safe (needed)?\n",
    "                    del self._save.Training, self._save.Boosters\n",
    "                    pm.save(Params=params, **self._save)\n",
    "                loop.send(results['score'])\n",
    "                yield i, results\n",
    "                #del self._save #TODO probably wanna uncomment this in production\n",
    "            pm.save(Params=self._best[0], **self._best[1])\n",
    "                \n",
    "    def run(self):\n",
    "        for _ in self.walk():\n",
    "            pass\n",
    "                \n",
    "    def setup_training(self, feats, samps, *, i=None):\n",
    "        samps = self.mm.S.get('Samps', i=i[1]) # this `samps` is a tuple of tuple of frozensets\n",
    "        _X = self.X[feats]\n",
    "        #_dummy = pd.Series(range(len(_X)), index=_X.index)\n",
    "        _s = self._s = O()\n",
    "        _s.tr, _s.cv = tuple(_X.index.isin(s[0]) for s in samps), tuple(_X.index.isin(s[1]) for s in samps)\n",
    "        lgb_data_info = dict(\n",
    "            feature_name = list(_X.columns),\n",
    "            categorical_feature = list(_X.dtypes[_X.dtypes.isin([np.int64,np.int32])].index),\n",
    "            free_raw_data = False,\n",
    "        )\n",
    "        _L = self._L = O()\n",
    "        _L.tr = [lgb.Dataset(_X[tr], P[self.specs.model.target][tr], **lgb_data_info,\n",
    "                            **({'weight': P[self.specs.model.weight][tr]} if 'weight' in self.specs.model else {}))\n",
    "                for tr in _s.tr]\n",
    "        _L.cv = [lgb.Dataset(_X[cv], P[self.specs.model.target][cv], reference=Ltr, **lgb_data_info,\n",
    "                            **({'weight': P[self.specs.model.weight][cv]} if 'weight' in self.specs.model else {}))\n",
    "                for cv, Ltr in zip(_s.cv, _L.tr)]\n",
    "        m = self.specs.metric\n",
    "        if hasattr(m, 'attach'):\n",
    "            m.attach(self)\n",
    "        #TODO implement both logloss and Kaggle metric, and stop only when both don't improve in whatever num rounds\n",
    "        \n",
    "    def train(self, params):\n",
    "        def iter_samples():\n",
    "            for Ltr, Lcv in zip(self._L.tr, self._L.cv):\n",
    "                evals_result = {}\n",
    "                # fucking LightGBM deletes 'num_iterations' from `params` after training, like WTF???\n",
    "                bst = lgb.train(dict(params), Ltr, valid_sets=[Ltr, Lcv], valid_names=['tr', 'cv'],\n",
    "                          feval=self.specs.metric, evals_result=evals_result, verbose_eval=False)\n",
    "                df_results = (pd.DataFrame(evals_result['tr']), pd.DataFrame(evals_result['cv']))\n",
    "                yield bst, df_results\n",
    "        bsts, dfs = zip(*iter_samples())\n",
    "        \n",
    "        class save(O()):\n",
    "            Training = dfs\n",
    "            Boosters = bsts\n",
    "            class Results(O()):\n",
    "                train = tuple(dft[0].iloc[-1-params['early_stopping_round'], 0] for dft in dfs)\n",
    "                scores = tuple(dft[1].iloc[-1-params['early_stopping_round'], 0] for dft in dfs)\n",
    "                score = sum(scores) / len(scores)\n",
    "                nboost = tuple(len(dft[1])-params['early_stopping_round'] for dft in dfs)\n",
    "        self._save = save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specs for search logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### params searching specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class LPS(O()):\n",
    "#     class Discrete(O()):\n",
    "#         enc = {\n",
    "#             'learning_rate': [.05],\n",
    "#             ('max_depth','num_leaves'): #10\n",
    "#                 [(6,1<<6),(8,1<<6),(8,1<<8),(10,1<<6),(10,1<<8),(10,1<<10),(12,1<<8),(12,1<<10),(12,1<<12),\n",
    "#                  (-1,1<<8),(-1,1<<10),(-1,1<<12),(-1,1<<14)],\n",
    "#             #('max','num'): #10\n",
    "#             #    [(6,6),(9,7),(9,9),(12,8),(12,10),(12,12),(-1,8),(-1,10),(-1,12),(-1,14)],\n",
    "#         }\n",
    "        \n",
    "#     class OneByOne(O()):\n",
    "#         class info(O()):\n",
    "#             a = \"main [a]rray data of 3 values, [min mid max]\"\n",
    "#             b =  \"[b]ack up value, i.e. default value if array doesn't give better results\"\n",
    "#             cast = \"function to apply to values before using to cast to the right dtype\"\n",
    "#             lim = \"maximum number of iterations of searching in this hyperparameter\"\n",
    "#         class default(O()):\n",
    "#             cast = keepSigFig(2)\n",
    "#             lim = 2\n",
    "#         data = {\n",
    "#             'min_data_in_leaf': O(a=[1,60,375], cast=round),\n",
    "#             'min_sum_hessian_in_leaf': O(a=[0,50,200]),\n",
    "#             'lambda_l1': O(a=[0,.02,.2], b=0, lim=1),\n",
    "#             'lambda_l2': O(a=[0,.02,.2], b=0, lim=1),\n",
    "#         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model search specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class LMS(O()):\n",
    "#     model = O(\n",
    "#         time = 'time',\n",
    "#         value = 'y',\n",
    "#         target = 'target',\n",
    "#         weight = 'weight1',\n",
    "#     )\n",
    "    \n",
    "#     metric = KaggleMetric()\n",
    "#     search = LPS\n",
    "    \n",
    "#     class Features(O()):\n",
    "#         '''features selection groups'''\n",
    "#         data = [\n",
    "#             ['f1','f2','f3'],\n",
    "#             ['f4','f5','f6'],\n",
    "#         ]\n",
    "    \n",
    "#     class Samples(O()):\n",
    "#         '''sample learning/cv split'''\n",
    "#         # O(method='GroupShuffleSplit.2', kwargs=dict(n_splits=<(5)many>, test_size=.5, random_state=44), groups='quarter'),\n",
    "#         enc = [\n",
    "#             O(method='group.2', groups='quarter', data=[\n",
    "#                 [2009.0,2009.75,2010.75,2011.5,2012.25,2012.5,2012.75,2013.0,2013.25,2013.75,2014.0,2014.25,2015.0],\n",
    "#                 [2009.25,2009.5,2010.0,2010.25,2010.5,2011.0,2011.25,2011.75,2012.0,2013.5,2014.5,2014.75,2015.25]\n",
    "#             ]),\n",
    "#             O(method='group.2', groups='quarter', data=[\n",
    "#                 [2009.25,2009.5,2011.0,2011.25,2011.5,2011.75,2012.0,2012.25,2013.0,2013.5,2014.5,2014.75,2015.0],\n",
    "#                 [2009.0,2009.75,2010.0,2010.25,2010.5,2010.75,2012.5,2012.75,2013.25,2013.75,2014.0,2014.25,2015.25]\n",
    "#             ]),\n",
    "#             O(method='group.2', groups='quarter', data=[\n",
    "#                 [2011.0,2011.75,2012.0,2012.25,2012.75,2013.25,2013.5,2014.0,2014.25,2014.5,2014.75,2015.0,2015.25],\n",
    "#                 [2009.0,2009.25,2009.5,2009.75,2010.0,2010.25,2010.5,2010.75,2011.25,2011.5,2012.5,2013.0,2013.75]\n",
    "#             ]),\n",
    "#             O(method='group.2', groups='quarter', data=[\n",
    "#                 [2009.5,2010.0,2010.25,2010.5,2011.0,2011.75,2012.25,2012.5,2013.0,2013.5,2014.25,2014.75,2015.25],\n",
    "#                 [2009.0,2009.25,2009.75,2010.75,2011.25,2011.5,2012.0,2012.75,2013.25,2013.75,2014.0,2014.5,2015.0]\n",
    "#             ]),\n",
    "#             O(method='group.2', groups='quarter', data=[\n",
    "#                 [2009.75,2010.0,2010.25,2010.75,2011.75,2012.0,2012.25,2012.5,2013.0,2013.5,2013.75,2014.5,2015.0],\n",
    "#                 [2009.0,2009.25,2009.5,2010.5,2011.0,2011.25,2011.5,2012.75,2013.25,2014.0,2014.25,2014.75,2015.25]\n",
    "#             ]),\n",
    "#             O(method='group.2', groups='quarter', data=[\n",
    "#                 [2009.25,2009.5,2010.0,2010.25,2010.5,2010.75,2011.5,2013.0,2013.5,2014.0,2014.5,2014.75,2015.25],\n",
    "#                 [2009.0,2009.75,2011.0,2011.25,2011.75,2012.0,2012.25,2012.5,2012.75,2013.25,2013.75,2014.25,2015.0]\n",
    "#             ]),\n",
    "#         ]\n",
    "        \n",
    "#     class Params(O()):\n",
    "#         '''parameters constant settings'''\n",
    "#         data = dict(\n",
    "#             objective = 'binary',\n",
    "#             num_iterations = 100000,\n",
    "#             early_stopping_round = 50,\n",
    "#             metric = 'None',\n",
    "#             seed = 44,\n",
    "#             bagging_seed = 45,\n",
    "#             feature_fraction_seed = 46,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -=#=-=#=-=#=-=#=-=#=- Features selection logic -=#=-=#=-=#=-=#=-=#=-=#=-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=- Abstract Function datatype -=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def item_check(a):\n",
    "    if not isinstance(a, tuple):\n",
    "        a = (a,)\n",
    "    return a\n",
    "\n",
    "class Itemgetter():\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "    def __getitem__(self, a):\n",
    "        return self.func(item_check(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "if TEST:\n",
    "    guy = Itemgetter(lambda *a: SEE(*a))\n",
    "    guy[5.7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing yo!\n",
    "if TEST:\n",
    "    class Yo():\n",
    "        def __call__(self, x):\n",
    "            SEE(x, '!')\n",
    "    yo = Yo()\n",
    "    yo.__call__ = lambda x: SEE('fuck', x)\n",
    "    yo(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function super useful datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Function(type):\n",
    "    def __new__(self, *args, **kw):\n",
    "        noattach = '_noattach_' in kw\n",
    "        if len(args) == 1:\n",
    "            if isinstance(args[0], __class__):\n",
    "                return args[0]\n",
    "            assert callable(args[0])\n",
    "            name = args[0].__qualname__\n",
    "            parents = ()\n",
    "            attrs = {'__call__': args[0]}\n",
    "            noattach = True\n",
    "        else:\n",
    "            name, parents, attrs = args\n",
    "        for k, v in list(dict.items(attrs)):\n",
    "            if not isinstance(v, classmethod) and callable(v) and not isinstance(v, __class__) and not noattach:\n",
    "                attrs[k] = classmethod(v)\n",
    "            \n",
    "        return super().__new__(self, name, parents, attrs)\n",
    "    \n",
    "    def __init__(self, *args, **kw):\n",
    "        #SEE('init', args, kw)\n",
    "        if len(args) == 1:\n",
    "            return\n",
    "        name, parents, attrs = args\n",
    "        for k in attrs:\n",
    "            v = getattr(self, k)\n",
    "            #SEE('init ->', k, v)\n",
    "            if k[:2] != '__' and callable(v):\n",
    "                setattr(self, k, __class__(v, _noattach_=True))\n",
    "        \n",
    "    def __call__(self, *a, **k):\n",
    "        return self.__call__(*a, **k)\n",
    "        \n",
    "    def __getitem__(self, *a, **k):\n",
    "        return self.__getitem__(*a, **k)\n",
    "    \n",
    "    __inv__ = lambda f: __class__(lambda *a, **k: ~f(*a,**k))\n",
    "    __and__ = lambda f, g: __class__(lambda *a, **k: f(*a,**k) & g(*a,**k))\n",
    "    __or__ = lambda f, g: __class__(lambda *a, **k: f(*a,**k) | g(*a,**k))\n",
    "    __xor__ = lambda f, g: __class__(lambda *a, **k: f(*a,**k) ^ g(*a,**k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "if TEST:\n",
    "    class What(metaclass=Function):\n",
    "        def __call__(self, x, y):\n",
    "            return np.sqrt(x**2 + y**2)\n",
    "        def hi(self, *s):\n",
    "            SEE('hi, ' + s[0])\n",
    "        __getitem__ = lambda self, a: lambda arg: SEE(arg, arg*a)\n",
    "    What.hi('u')\n",
    "    What.hi#.__call__\n",
    "    What[5](3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function query language implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scan(s):\n",
    "    s = s.replace(' ','').replace('\\n','').replace('\\t','').replace('\\r','') + '\\0'\n",
    "    i0, i = 0, 0\n",
    "    while i0 < len(s)-1 and i < len(s):\n",
    "        c = s[i]\n",
    "        if 'a' <= c <= 'z' or 'A' <= c <= 'Z' or '0' <= c <= '9' or c == '_':\n",
    "            i += 1\n",
    "            continue\n",
    "        elif c == '\\0':\n",
    "            yield s[i0:i]\n",
    "            break\n",
    "        elif c in '~&|^()':\n",
    "            if i0 < i:\n",
    "                yield s[i0:i]\n",
    "            yield c\n",
    "            i0 = i = i+1\n",
    "        elif c in '[{':\n",
    "            if i0 < i:\n",
    "                yield s[i0:i]\n",
    "            i0 = i\n",
    "            match = ']' if c=='[' else '}'\n",
    "            while s[i] != match:\n",
    "                i += 1\n",
    "            i += 1\n",
    "            yield s[i0:i]\n",
    "            i0 = i\n",
    "        else:\n",
    "            raise AssertionError('bad syntax in input to scanner')\n",
    "\n",
    "            \n",
    "Token = namedtuple('Token', 'type value')\n",
    "\n",
    "def tokenize(s):\n",
    "    prevIsField = False\n",
    "    for w in s:\n",
    "        a = w[0]\n",
    "        if 'a' <= a <= 'z' or 'A' <= a <= 'Z' or '0' <= a <= '9' or a == '_':\n",
    "            yield Token('field', w)\n",
    "            prevIsField = True\n",
    "            continue\n",
    "        elif w in ['&','^','|']:\n",
    "            yield Token('op2', w)\n",
    "        elif w in ['~']:\n",
    "            yield Token('op1', w)\n",
    "        elif w in ['(']:\n",
    "            yield Token('_group', w)\n",
    "        elif w in [')']:\n",
    "            yield Token('group_', w)\n",
    "        elif a == '{':\n",
    "            assert prevIsField, '{} section must have been preceded by a field name'\n",
    "            yield Token('op2', 'query')\n",
    "            yield Token('raw', w)\n",
    "        elif a == '[':\n",
    "            if not prevIsField:\n",
    "                yield Token('self', '')\n",
    "            yield Token('op2', 'getitem')\n",
    "            yield Token('raw', w)\n",
    "        else:\n",
    "            assert False, f'invalid word encountered in tokenizer input: {w}'\n",
    "        prevIsField = False\n",
    "        \n",
    "class TokenInfo(O()):\n",
    "    self = 'self, the owning Function instance'\n",
    "    field = 'field name of Function instance'\n",
    "    op2 = 'binary operator (look in the map)'\n",
    "    op1 = 'unary operator (look in the map)'\n",
    "    _group = \"open grouping (just '(')\"\n",
    "    group_ = \"close grouping (just ')')\"\n",
    "    raw = \"raw data to be fed to operator\"\n",
    "\n",
    "\n",
    "def parse(s):\n",
    "    stack = []\n",
    "    for t in s:\n",
    "        if t.type in ['field', 'self', 'raw']:\n",
    "            yield t\n",
    "        elif t.type in ['op2', 'op1']:\n",
    "            while stack and stack[-1].type in ['op2', 'op1'] and parse.order[t.value] >= parse.order[stack[-1].value]:\n",
    "                yield stack.pop()\n",
    "            stack.append(t)\n",
    "        elif t.type == '_group':\n",
    "            stack.append(t)\n",
    "        elif t.type == 'group_':\n",
    "            while True:\n",
    "                if not stack:\n",
    "                    raise AssertionError('too many close parentheses')\n",
    "                x = stack.pop()\n",
    "                if x.type == '_group':\n",
    "                    break\n",
    "                else:\n",
    "                    assert x.type in ['op2', 'op1'], 'internal error'\n",
    "                    yield x\n",
    "    while stack:\n",
    "        x = stack.pop()\n",
    "        if x.type == '_group':\n",
    "            raise AssertionError('too many open parentheses')\n",
    "        assert x.type in ['op2', 'op1'], 'internal error'\n",
    "        yield x\n",
    "parse.order = {'query': 0, 'getitem': 0, '~': 1, '&': 2, '^': 3, '|': 4}\n",
    "\n",
    "    \n",
    "def query(self, qs):\n",
    "    revpol = list(parse(tokenize(scan(qs))))\n",
    "    stack = []\n",
    "    for t in revpol:\n",
    "        if t.type == 'self':\n",
    "            stack.append(self)\n",
    "        elif t.type == 'field':\n",
    "            stack.append(getattr(self, t.value))\n",
    "        elif t.type == 'raw':\n",
    "            stack.append(t.value)\n",
    "        elif t.type == 'op1':\n",
    "            a = stack.pop()\n",
    "            x = query.opTbl[t.value](a)\n",
    "            stack.append(x)\n",
    "        elif t.type == 'op2':\n",
    "            b, a = stack.pop(), stack.pop()\n",
    "            x = query.opTbl[t.value](a, b)\n",
    "            stack.append(x)\n",
    "    return stack.pop()\n",
    "\n",
    "class GetItemHelper(metaclass=Singleton):\n",
    "    def __getitem__(self, a):\n",
    "        return a\n",
    "\n",
    "query.opTbl = {\n",
    "    '~': operator.__inv__,\n",
    "    '&': operator.__and__,\n",
    "    '^': operator.__xor__,\n",
    "    '|': operator.__or__,\n",
    "    'query': lambda f, q: f.query(q[1:-1]), #TODO can only go one level deep\n",
    "    'getitem': lambda f, a: f[eval(f'GetItemHelper()[{a[1:-1]}]')]\n",
    "}\n",
    "\n",
    "Function.query = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing function query\n",
    "if TEST:\n",
    "    qs = 'what2{f_ck} & no_[5,62,6:6]  |  [9] & ~(ho_10|[3,5:9])'\n",
    "    scanned = list(scan(qs))\n",
    "    assert (scanned == ['what2','{f_ck}','&','no_','[5,62,6:6]','|','[9]','&','~','(','ho_10','|','[3,5:9]',')']), (\n",
    "            'Unit test fail for scanner')    \n",
    "    tokens = list(tokenize(scanned)) #TODO make unit test\n",
    "    parsed = list(parse(tokens)) # TODO make unit test\n",
    "    SEE(qs)\n",
    "    SEE('-'*99)\n",
    "    SEE(scanned)\n",
    "    SEE('-'*99)\n",
    "    for line in tokens:\n",
    "        SEE(line)\n",
    "    SEE('-'*99)\n",
    "    for line in parsed:\n",
    "        SEE(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .!.!.!.!.!.!.!.!.!.!.!.!.!.!.!.!.!. The actual Features subsets definitions!!!! .!.!.!.!.!.!.!.!.!.!.!.!.!.!.!.!.!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FFF__returns_range(x, e):\n",
    "    if e == 0:\n",
    "        ret = x in 'oo oo0 cc cc0 (oo-oo0) (cc-cc0) (cc-cc0){0} (oo-oo0){0} (oo0-cc0) it af'.split()\n",
    "        ret |= '(it,af,it{1},oo0,cc0)' in x\n",
    "        return ret\n",
    "    elif e == 1 and '(it{1},af{1},it{2},oo0{1},cc0{1})' in x:\n",
    "        return True\n",
    "    elif isinstance(e, int):\n",
    "        suf = '{' + str(e) + '}'\n",
    "        return x[-len(suf):] == suf\n",
    "    elif isinstance(e, slice):\n",
    "        start, stop = e.start if e.start is not None else 0, e.stop if e.stop is not None else 0\n",
    "        assert start >= 0 and stop >= 0\n",
    "        sml, lrg = min(start, stop), max(start, stop)\n",
    "        ret = ('(it,af,it{1},oo0,cc0){0/1}' not in x and '(it{1},af{1},it{2},oo0{1},cc0{1})' not in x and\n",
    "            '({}..{})'.format(sml,lrg-1) in x or '{{{}/{}}}'.format(sml,lrg-1) in x)\n",
    "        suf1, suf2 = 'Since'+str(lrg), '_'+str(lrg)\n",
    "        ret |= x[-len(suf1):] == suf1 and sml == 0\n",
    "        ret |= x[-len(suf2):] == suf2 and sml == 0\n",
    "        return ret\n",
    "    return False\n",
    "    \n",
    "def FFF__returns_span(x, e):\n",
    "    if isinstance(e, int):\n",
    "        assert e > 0\n",
    "    suf1, suf2 = 'Since'+str(e), '_'+str(e)\n",
    "    if x[-len(suf1):] == suf1 or x[-len(suf2):] == suf2:\n",
    "        return True\n",
    "    if e == 1:\n",
    "        return any(FFF__returns_range(x, r) for r in [0,1,2,3,4,5])\n",
    "    elif e == 2:\n",
    "        return (x[-5:] == '{0/1}' or x[-5:] == '{1/2}') and ',' not in x\n",
    "    elif e == 3:\n",
    "        return x[-5:] == '{0/2}' and ',' not in x\n",
    "    elif e == 5:\n",
    "        return '(0..4)' in x or '(5..9)' in x or '(10..14)' in x or '(15..19)' in x\n",
    "    elif e == 10:\n",
    "        return '(0..9)' in x or '(5..14)' in x or '(10..19)' in x\n",
    "    elif e == 15:\n",
    "        return '(0..14)' in x or '(5..19)' in x\n",
    "    elif e == 20:\n",
    "        return '(0..19)' in x\n",
    "    elif isinstance(e, slice):\n",
    "        start, stop = e.start if e.start is not None else 0, e.stop if e.stop is not None else 0\n",
    "        assert start >= 0 and stop >= 0\n",
    "        sml, lrg = min(start, stop), max(start, stop)\n",
    "        for i in [1,2,3,4,5,10,15,20,21,40,60,62,120,125,250]:\n",
    "            if sml < i <= lrg and FFF__returns_span(x, i):\n",
    "                return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "class FFF(metaclass=Function):\n",
    "    #class Basic(metaclass=Function):\n",
    "    #    pass\n",
    "    \n",
    "    class AssetEnc(metaclass=Function):\n",
    "        __call__ = lambda f, x: 'assetCode' in x or 'assetName' in x\n",
    "        Ids = lambda f, x: x in ['assetCodeId', 'assetNameId']\n",
    "        \n",
    "        class RandMap(metaclass=Function):\n",
    "            __call__ = lambda f, x: 'randMap32' in x\n",
    "            squared = Itemgetter(lambda a: lambda x:\n",
    "                any(x[::-1].find(('randMap32_' + str(e**2))[::-1]) == 0 for e in item_check(a)))\n",
    "            __getitem__ = (lambda f, a: lambda x:\n",
    "                any(x[::-1].find(('randMap32_' + str(e))[::-1]) == 0 for e in item_check(a)))\n",
    "        \n",
    "        WTFF = lambda f, x: 'WTFF' in x\n",
    "        InUni = lambda f, x: 'inUniCount' in x\n",
    "    \n",
    "    class Time(metaclass=Function):\n",
    "        __call__ = lambda f, x: x in ['dayOfYear', 'dayOfWeek']\n",
    "        \n",
    "    class Volatility(metaclass=Function):\n",
    "        __call__ = lambda f, x: 'volatility' in x or 'Volatility' in x\n",
    "        __getitem__ = lambda f, a: lambda x: any('olatility'+str(e) in x for e in item_check(a))\n",
    "        \n",
    "    class Adjustment(metaclass=Function):\n",
    "        __call__ = lambda f, x: 'adjustmentMean' in x\n",
    "        __getitem__ = lambda f, a: lambda x: any('adjustmentMean'+str(e) in x for e in item_check(a))\n",
    "    \n",
    "    class Drawdown(metaclass=Function):\n",
    "        __call__ = lambda f, x: 'drawdown' in x or 'Drawdown' in x\n",
    "        __getitem__ = lambda f, a: lambda x: (\n",
    "            any((\n",
    "                 'rawdown'+str(e) in x if isinstance(e, int) else\n",
    "                 'rawdown({}-{})'.format(max(e.start,e.stop),min(e.start,e.stop)) in x if isinstance(e, slice) else\n",
    "                 1/0\n",
    "                ) for e in item_check(a))\n",
    "        )\n",
    "    \n",
    "    class Drawup(metaclass=Function):\n",
    "        __call__ = lambda f, x: 'drawup' in x or 'Drawup' in x\n",
    "        __getitem__ = lambda f, a: lambda x: any(\n",
    "            (\n",
    "                'rawup'+str(e) in x if isinstance(e, int) else\n",
    "                'rawup({}-{})'.format(max(e.start,e.stop),min(e.start,e.stop)) in x if isinstance(e, slice) else\n",
    "                1/0\n",
    "            ) for e in item_check(a)\n",
    "        )\n",
    "    \n",
    "    class Price(metaclass=Function):\n",
    "        __call__ = lambda f, x: x in ['open', 'close']\n",
    "    \n",
    "    class Level(metaclass=Function):\n",
    "        __call__ = lambda f, x: x in ['open', 'close', 'volume']\n",
    "    \n",
    "    class Return(metaclass=Function):\n",
    "        allow = lambda f, x: all(b not in x for b in\n",
    "                                 ['MinSince','MaxSince','rawdown','rawup','ecordedDays','assetCode','volume','olatility'])\n",
    "        __call__ = lambda f, x: 'oo' in x or 'cc' in x or x[:2] in ['it', 'af']\n",
    "        oo = lambda f, x: 'oo' in x and not any(['oo0' in x, '-oo' in x, 'oo-' in x, ',oo' in x, 'oo,' in x])\n",
    "        oo0 = lambda f, x: 'oo0' in x and not any(['-oo0' in x, 'oo0-' in x, ',oo0' in x, 'oo0,' in x])\n",
    "        cc = lambda f, x: 'cc' in x and not any(['cc0' in x, '-cc' in x, 'cc-' in x, ',cc' in x, 'cc,' in x])\n",
    "        cc0 = lambda f, x: 'cc0' in x and not any(['-cc0' in x, 'cc0-' in x, ',cc0' in x, 'cc0,' in x])\n",
    "        doo = lambda f, x: '(oo-oo0)' in x\n",
    "        dcc = lambda f, x: '(cc-cc0)' in x\n",
    "        doc0 = lambda f, x: '(oo0-cc0)' in x\n",
    "        it = lambda f, x: x[:3] in ['it', 'it{']\n",
    "        af = lambda f, x: x[:3] in ['af', 'af{']\n",
    "        mix = lambda f, x: x[:3] == '(it'\n",
    "        \n",
    "        def __getitem__(f, a):\n",
    "            return lambda x: any(FFF__returns_range(x, e) for e in item_check(a))\n",
    "        \n",
    "        span = Itemgetter(lambda a: lambda x: any(FFF__returns_span(x, e) for e in item_check(a)))\n",
    "                \n",
    "    class Since(metaclass=Function):\n",
    "        __call__ = lambda f, x: 'Since' in x\n",
    "        __getitem__ = lambda f, a: lambda x: any('Since' + str(e) in x for e in item_check(a))\n",
    "    \n",
    "    class Volume(metaclass=Function):\n",
    "        __call__ = lambda f, x: x == 'volume'\n",
    "    \n",
    "    class VolumeRatioMean(metaclass=Function):\n",
    "        '''~Back2 ~Back2{1} ~5 ~10 ~10{5} ~5ByMean20'''\n",
    "        __call__ = lambda f, x: 'olumeRatioMean' in x\n",
    "        __getitem__ = lambda f, a: lambda x: x in ['volumeRatioMean'+str(e) for e in item_check(a)]\n",
    "        \n",
    "    class FracRec(metaclass=Function):\n",
    "        __call__ = lambda f, x: 'fracRecordedDays' in x\n",
    "        __getitem__ = lambda f, a: lambda x: any(x == 'fracRecordedDaysSince'+str(e) for e in item_check(a))\n",
    "\n",
    "FFF.Global = FFF.Volatility | FFF.Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.to_pickle((F,P), '/big/data/saves/train_5searchbase.32.pkl')\n",
    "F,P = pd.read_pickle('/big/data/saves/train_5searchbase.32.pkl')\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.dump(list(F.columns), open('feats.json', 'w'))\n",
    "feats = json.load(open('feats.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing my operators and query language\n",
    "#pd.Series(F.columns.map(FFF.FracRec[125]), index=F.columns)\n",
    "#pd.Series(F.columns.map(FFF.query('Return{allow} & Return{span[10:]}')), index=F.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adjustment',\n",
       " 'AssetEnc',\n",
       " 'Drawdown',\n",
       " 'Drawup',\n",
       " 'FracRec',\n",
       " 'Global',\n",
       " 'Level',\n",
       " 'Price',\n",
       " 'Return',\n",
       " 'Since',\n",
       " 'Time',\n",
       " 'Volatility',\n",
       " 'Volume',\n",
       " 'VolumeRatioMean']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x[:2]!='__', dir(FFF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "fffList = [\n",
    "    FFF.Return & FFF.Return.oo0,\n",
    "    FFF.Drawdown\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LPS(O()):\n",
    "    class Discrete(O()):\n",
    "        enc = {\n",
    "            'learning_rate': [.05],\n",
    "            ('max_depth','num_leaves'): #10\n",
    "                [(6,1<<6),(8,1<<6),(8,1<<8),(10,1<<6),(10,1<<8)],\n",
    "                 #,(10,1<<10),(12,1<<8),(12,1<<10),(12,1<<12),\n",
    "                 #(-1,1<<8),(-1,1<<10),(-1,1<<12),(-1,1<<14)],\n",
    "            #('max','num'): #10\n",
    "            #    [(6,6),(9,7),(9,9),(12,8),(12,10),(12,12),(-1,8),(-1,10),(-1,12),(-1,14)],\n",
    "        }\n",
    "        \n",
    "    class OneByOne(O()):\n",
    "        class info(O()):\n",
    "            a = \"main [a]rray data of 3 values, [min mid max]\"\n",
    "            b =  \"[b]ack up value, i.e. default value if array doesn't give better results\"\n",
    "            cast = \"function to apply to values before using to cast to the right dtype\"\n",
    "            lim = \"maximum number of iterations of searching in this hyperparameter\"\n",
    "        class default(O()):\n",
    "            cast = keepSigFig(2)\n",
    "            lim = 1\n",
    "        data = {\n",
    "            'min_data_in_leaf': O(a=[1,60,375], cast=round),\n",
    "            'min_sum_hessian_in_leaf': O(a=[0,50,200]),\n",
    "            'lambda_l1': O(a=[0,.02,.2], b=0, lim=0),\n",
    "            'lambda_l2': O(a=[0,.02,.2], b=0, lim=0),\n",
    "        }\n",
    "\n",
    "class LMS(O()):\n",
    "    model = O(\n",
    "        time = 'time',\n",
    "        value = 'y',\n",
    "        target = 'target',\n",
    "        weight = 'weight1',\n",
    "    )\n",
    "    \n",
    "    metric = KaggleMetric()\n",
    "    search = LPS\n",
    "    \n",
    "    class Features(O()):\n",
    "        '''features selection groups'''\n",
    "        data = [list(filter(fff, feats)) for fff in fffList]\n",
    "    \n",
    "    class Samples(O()):\n",
    "        '''sample learning/cv split'''\n",
    "        # O(method='GroupShuffleSplit.2', kwargs=dict(n_splits=<(5)many>, test_size=.5, random_state=44), groups='quarter'),\n",
    "        enc = [\n",
    "            O(method='group.2', groups='quarter', data=[\n",
    "                [2009.0,2009.75,2010.75,2011.5,2012.25,2012.5,2012.75,2013.0,2013.25,2013.75,2014.0,2014.25,2015.0],\n",
    "                [2009.25,2009.5,2010.0,2010.25,2010.5,2011.0,2011.25,2011.75,2012.0,2013.5,2014.5,2014.75,2015.25]\n",
    "            ]),\n",
    "            O(method='group.2', groups='quarter', data=[\n",
    "                [2009.25,2009.5,2011.0,2011.25,2011.5,2011.75,2012.0,2012.25,2013.0,2013.5,2014.5,2014.75,2015.0],\n",
    "                [2009.0,2009.75,2010.0,2010.25,2010.5,2010.75,2012.5,2012.75,2013.25,2013.75,2014.0,2014.25,2015.25]\n",
    "            ]),\n",
    "#             O(method='group.2', groups='quarter', data=[\n",
    "#                 [2011.0,2011.75,2012.0,2012.25,2012.75,2013.25,2013.5,2014.0,2014.25,2014.5,2014.75,2015.0,2015.25],\n",
    "#                 [2009.0,2009.25,2009.5,2009.75,2010.0,2010.25,2010.5,2010.75,2011.25,2011.5,2012.5,2013.0,2013.75]\n",
    "#             ]),\n",
    "#             O(method='group.2', groups='quarter', data=[\n",
    "#                 [2009.5,2010.0,2010.25,2010.5,2011.0,2011.75,2012.25,2012.5,2013.0,2013.5,2014.25,2014.75,2015.25],\n",
    "#                 [2009.0,2009.25,2009.75,2010.75,2011.25,2011.5,2012.0,2012.75,2013.25,2013.75,2014.0,2014.5,2015.0]\n",
    "#             ]),\n",
    "#             O(method='group.2', groups='quarter', data=[\n",
    "#                 [2009.75,2010.0,2010.25,2010.75,2011.75,2012.0,2012.25,2012.5,2013.0,2013.5,2013.75,2014.5,2015.0],\n",
    "#                 [2009.0,2009.25,2009.5,2010.5,2011.0,2011.25,2011.5,2012.75,2013.25,2014.0,2014.25,2014.75,2015.25]\n",
    "#             ]),\n",
    "#             O(method='group.2', groups='quarter', data=[\n",
    "#                 [2009.25,2009.5,2010.0,2010.25,2010.5,2010.75,2011.5,2013.0,2013.5,2014.0,2014.5,2014.75,2015.25],\n",
    "#                 [2009.0,2009.75,2011.0,2011.25,2011.75,2012.0,2012.25,2012.5,2012.75,2013.25,2013.75,2014.25,2015.0]\n",
    "#             ]),\n",
    "        ]\n",
    "        \n",
    "    class Params(O()):\n",
    "        '''parameters constant settings'''\n",
    "        data = dict(\n",
    "            objective = 'binary',\n",
    "            num_iterations = 100000,\n",
    "            early_stopping_round = 50,\n",
    "            metric = 'None',\n",
    "            seed = 44,\n",
    "            bagging_seed = 45,\n",
    "            feature_fraction_seed = 46,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = ModelManager('/big/data/search/fake')\n",
    "ms = ModelSearch(specs=LMS, mm=mm, X=F, Y=P)\n",
    "walk = ms.walk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, (1, 0), <>(train=[0.7214605834581501, 1.073667926072597], scores=[0.5675374430153964, 0.5639808673520671], score=0.5657591551837318, nboost=[245, 106]))\n",
      "CPU times: user 25 s, sys: 3.32 s, total: 28.3 s\n",
      "Wall time: 5.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i += 1\n",
    "print((i,) + next(walk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================= ACTUAL PRODUCTION RUN ===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Live Run Testing (still, just testing) ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### making test variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "ppf = norm.ppf\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_new_vars():\n",
    "    n = 1000\n",
    "    ##################RANDOMIZE#######################\n",
    "    while True:\n",
    "        try:\n",
    "            u = np.random.uniform(size=(5, n))\n",
    "            assert (u!=0).all()\n",
    "            break\n",
    "        except AssertionError:\n",
    "            continue\n",
    "    uu = u.copy()\n",
    "    uu[0][np.random.randint(252, size=n) == 0] = np.nan\n",
    "    uu[1][np.random.randint(173, size=n) == 0] = np.nan\n",
    "    uu[2][np.random.randint(81, size=n) == 0] = np.nan\n",
    "    uu[3][np.random.randint(27, size=n) == 0] = np.nan\n",
    "    #################ENDRANDOM######################\n",
    "    F = pd.DataFrame({'hax': np.arange(n)})\n",
    "    F['time'] = F.hax // 10\n",
    "    F['assetCodeId'] = F.hax % 10\n",
    "    F['quarter'] = F.hax // 100\n",
    "    P = F.copy()\n",
    "    F['alex'] = ppf(u[0]*5%.99+eps)*ppf(u[1]*7%.99+eps)\n",
    "    F['bob'] = ppf(.5+.49*uu[2]*np.sin(F.assetCodeId.values**10))*np.exp(uu[3])\n",
    "    F['carol'] = -np.log(u[0]) + 4 * np.sin(1/uu[1])\n",
    "    F['dean'] = u[1] + 2 * uu[2] - np.exp(-uu[3])\n",
    "    F['edgar'] = ppf( (uu[2]**2-2*u[1]+(u[0]-u[3])**3-.5*u[1]**2) % .99 + eps )\n",
    "    P['y'] = (ppf((u[0]+u[1])/2) + ppf((u[2]+u[3])/2) + .2*ppf(u[4])) * 1e-1\n",
    "    P['universe'] = (~np.isnan(uu[0])).astype(float)\n",
    "    return F, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F, P = make_new_vars()\n",
    "#Path('lighttest.pkl').write_bytes(pickle.dumps((F, P)))\n",
    "F, P = pickle.loads(Path('lighttest.pkl').read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P['target'] = P.y>0\n",
    "P['upDown'] = (P.target*2-1)\n",
    "P['upDown1'] = P.upDown*P.universe.astype(int)\n",
    "P['absVal'] = np.abs(P.y)\n",
    "P['absVal1'] = P.absVal*P.universe\n",
    "P['weight'] = P.absVal#.qtl()\n",
    "P['weight1'] = P.weight*P.universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hax</th>\n",
       "      <th>time</th>\n",
       "      <th>assetCodeId</th>\n",
       "      <th>quarter</th>\n",
       "      <th>alex</th>\n",
       "      <th>bob</th>\n",
       "      <th>carol</th>\n",
       "      <th>dean</th>\n",
       "      <th>edgar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.655924</td>\n",
       "      <td>1.336200</td>\n",
       "      <td>0.601672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.033782</td>\n",
       "      <td>1.139956</td>\n",
       "      <td>8.008799</td>\n",
       "      <td>1.244428</td>\n",
       "      <td>0.349115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034335</td>\n",
       "      <td>-0.333275</td>\n",
       "      <td>2.013295</td>\n",
       "      <td>1.549419</td>\n",
       "      <td>1.363992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.131567</td>\n",
       "      <td>-0.049046</td>\n",
       "      <td>5.325198</td>\n",
       "      <td>0.450859</td>\n",
       "      <td>0.940187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.636082</td>\n",
       "      <td>0.267445</td>\n",
       "      <td>4.698875</td>\n",
       "      <td>0.670703</td>\n",
       "      <td>-0.449314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hax  time  assetCodeId  quarter      alex       bob     carol      dean  \\\n",
       "0    0     0            0        0 -0.012198  0.000000  3.655924  1.336200   \n",
       "1    1     0            1        0 -0.033782  1.139956  8.008799  1.244428   \n",
       "2    2     0            2        0  0.034335 -0.333275  2.013295  1.549419   \n",
       "3    3     0            3        0 -2.131567 -0.049046  5.325198  0.450859   \n",
       "4    4     0            4        0  1.636082  0.267445  4.698875  0.670703   \n",
       "\n",
       "      edgar  \n",
       "0  0.601672  \n",
       "1  0.349115  \n",
       "2  1.363992  \n",
       "3  0.940187  \n",
       "4 -0.449314  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hax</th>\n",
       "      <th>time</th>\n",
       "      <th>assetCodeId</th>\n",
       "      <th>quarter</th>\n",
       "      <th>y</th>\n",
       "      <th>universe</th>\n",
       "      <th>target</th>\n",
       "      <th>upDown</th>\n",
       "      <th>upDown1</th>\n",
       "      <th>absVal</th>\n",
       "      <th>absVal1</th>\n",
       "      <th>weight</th>\n",
       "      <th>weight1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076738</td>\n",
       "      <td>0.076738</td>\n",
       "      <td>0.076738</td>\n",
       "      <td>0.076738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048210</td>\n",
       "      <td>0.048210</td>\n",
       "      <td>0.048210</td>\n",
       "      <td>0.048210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.089397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089397</td>\n",
       "      <td>0.089397</td>\n",
       "      <td>0.089397</td>\n",
       "      <td>0.089397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>0.028319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.103184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.103184</td>\n",
       "      <td>0.103184</td>\n",
       "      <td>0.103184</td>\n",
       "      <td>0.103184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hax  time  assetCodeId  quarter         y  universe  target  upDown  \\\n",
       "0    0     0            0        0  0.076738       1.0    True       1   \n",
       "1    1     0            1        0  0.048210       1.0    True       1   \n",
       "2    2     0            2        0  0.089397       1.0    True       1   \n",
       "3    3     0            3        0 -0.028319       1.0   False      -1   \n",
       "4    4     0            4        0 -0.103184       1.0   False      -1   \n",
       "\n",
       "   upDown1    absVal   absVal1    weight   weight1  \n",
       "0        1  0.076738  0.076738  0.076738  0.076738  \n",
       "1        1  0.048210  0.048210  0.048210  0.048210  \n",
       "2        1  0.089397  0.089397  0.089397  0.089397  \n",
       "3       -1  0.028319  0.028319  0.028319  0.028319  \n",
       "4       -1  0.103184  0.103184  0.103184  0.103184  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LPS(O()):\n",
    "    class Discrete(O()):\n",
    "        enc = {\n",
    "            'learning_rate': [.05],\n",
    "            ('max_depth','num_leaves'):\n",
    "                [(3,1<<3),(6,1<<6),(-1,1<<9)]\n",
    "        }\n",
    "        \n",
    "    class OneByOne(O()):\n",
    "        class info(O()):\n",
    "            a = \"main [a]rray data of 3 values, [min mid max]\"\n",
    "            b =  \"[b]ack up value, i.e. default value if array doesn't give better results\"\n",
    "            cast = \"function to apply to values before using to cast to the right dtype\"\n",
    "            lim = \"maximum number of iterations of searching in this hyperparameter\"\n",
    "        class default(O()):\n",
    "            cast = keepSigFig(2)\n",
    "            lim = 2\n",
    "        data = {\n",
    "            'min_data_in_leaf': O(a=[1,6,37], cast=round),\n",
    "            'min_sum_hessian_in_leaf': O(a=[0,5,20], b=0),\n",
    "            'lambda_l1': O(a=[0,.02,.2], b=0, lim=1),\n",
    "            'lambda_l2': O(a=[0,.02,.2], b=0, lim=1),\n",
    "        }\n",
    "\n",
    "\n",
    "class LMS(O()):\n",
    "    model = O(\n",
    "        time = 'time',\n",
    "        value = 'y',\n",
    "        target = 'target',\n",
    "        weight = 'weight1',\n",
    "    )\n",
    "    \n",
    "    metric = KaggleMetric()\n",
    "    search = LPS\n",
    "    \n",
    "    class Features(O()):\n",
    "        '''features selection groups'''\n",
    "        data = [\n",
    "            ['alex', 'bob', 'carol'],\n",
    "            ['bob', 'dean', 'edgar'],\n",
    "            ['alex', 'carol', 'edgar']\n",
    "        ]\n",
    "    \n",
    "    class Samples(O()):\n",
    "        '''sample learning/cv split'''\n",
    "        enc = [\n",
    "            O(method='group.2', groups='quarter', data=[\n",
    "                [0, 1, 2, 3, 4],\n",
    "                [5, 6, 7, 8, 9]\n",
    "            ]),\n",
    "        ]\n",
    "        \n",
    "    class Params(O()):\n",
    "        '''parameters constant settings'''\n",
    "        data = dict(\n",
    "            objective = 'binary',\n",
    "            num_iterations = 100000,\n",
    "            early_stopping_round = 50,\n",
    "            metric = 'None',\n",
    "            seed = 44,\n",
    "            bagging_seed = 45,\n",
    "            feature_fraction_seed = 46,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm = ModelManager('/big/data/search/test')\n",
    "ms = ModelSearch(specs=LMS, mm=mm, X=F, Y=P)\n",
    "walk = ms.walk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "(3, (0, 0), <>(train=(1.9117454484505862, 1.8610316178296742), scores=(1.7104576224320605, 1.7875447679802607), score=1.7490011952061606, nboost=(93, 128)))\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print((i,) + next(walk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -.-.-.-.-.-.-.-.-.-.-.-.-.- old shit / testing -.-.-.-.-.-.-.-.-.-.-.-.-.-.-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'What' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-dc92f66a5036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mYo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mWhat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mderp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-dc92f66a5036>\u001b[0m in \u001b[0;36mYo\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mWhat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mderp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mclass\u001b[0m \u001b[0mAnother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0myep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mYo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-dc92f66a5036>\u001b[0m in \u001b[0;36mAnother\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mderp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mAnother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0myep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mYo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'What' is not defined"
     ]
    }
   ],
   "source": [
    "# PUREL TESTING\n",
    "class HI(O()):\n",
    "    class DERP():\n",
    "        val = -99\n",
    "        dir = Path('.')\n",
    "        def yo(x):\n",
    "            def y(a):\n",
    "                return x(a) + 1000\n",
    "            return y\n",
    "        my = O(what=yo(lambda a: a ** 2))\n",
    "        hm = O(func=lambda x: x * __class__.val, goto=lambda x: __class__.dir/x)\n",
    "        class WHAT(O()):\n",
    "            dude = lambda x: x + 10\n",
    "        class YES(O()):\n",
    "            dude = WHAT.dude\n",
    "HI.DERP.my.what(5)\n",
    "HI.DERP.hm.func(5)\n",
    "HI.DERP.dir = Path('what')\n",
    "HI.DERP.hm.goto('.git')\n",
    "HI.DERP.WHAT.dude(0)\n",
    "\n",
    "# ANOTHER PURE TESTING\n",
    "def dothe(self):\n",
    "    self.val = 4\n",
    "    top = 100\n",
    "    class Derp(O()):\n",
    "        def func(x):\n",
    "            return x + self.val\n",
    "        def top(y):\n",
    "            return y * top\n",
    "    self.derp = Derp\n",
    "item = Stop()\n",
    "dothe(item)\n",
    "item.derp.top(3)\n",
    "\n",
    "class Yo(O()):\n",
    "    class What(O()):\n",
    "        derp = 5\n",
    "    class Another(O()):\n",
    "        yep = What.derp\n",
    "Yo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
