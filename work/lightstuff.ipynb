{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common import *\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class staticclass(type):\n",
    "    class InstantiationError(Exception):\n",
    "        pass\n",
    "    def __init__(cls, name, parents, attrs):\n",
    "        for k, v in dict.items(attrs):\n",
    "            if callable(v):\n",
    "                attrs[k] = staticmethod(v)\n",
    "    def __call__(cls, *a, **k):\n",
    "        raise __class__.InstantiationError('cannot instantiate a staticclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I = lambda x: x\n",
    "logavg = lambda x,y: math.expm1((math.log1p(x)+math.log1p(y))/2)\n",
    "keepSigFig = lambda n: lambda x: round(x, -int(math.floor(math.log10(abs(x)))) + (n - 1)) if x else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PSD(O()):\n",
    "    class Discrete(O()):\n",
    "        raw = {\n",
    "            ('max_depth','num_leaves'): #10\n",
    "                [(6,1<<6),(9,1<<7),(9,1<<9),(12,1<<8),(12,1<<10),(12,1<<12),(-1,1<<8),(-1,1<<10),(-1,1<<12),(-1,1<<14)],\n",
    "            #('max','num'): #10\n",
    "            #    [(6,6),(9,7),(9,9),(12,8),(12,10),(12,12),(-1,8),(-1,10),(-1,12),(-1,14)],\n",
    "        }\n",
    "        \n",
    "    class OneByOne(O()):\n",
    "        class info(O()):\n",
    "            a = \"main [a]rray data of 3 values, [min mid max]\"\n",
    "            b =  \"[b]ack up value, i.e. default value if array doesn't give better results\"\n",
    "            cast = \"function to apply to values before using to cast to the right dtype\"\n",
    "            lim = \"maximum number of iterations of searching in this hyperparameter\"\n",
    "        class default(O()):\n",
    "            cast = keepSigFig(2)\n",
    "            lim = 2\n",
    "        data = {\n",
    "            'min_data_in_leaf': O(a=[1,60,375], cast=round),\n",
    "            'min_sum_hessian_in_leaf': O(a=[0,50,200]),\n",
    "            'lambda_l1': O(a=[0,.02,.2], b=0, lim=1),\n",
    "            'lambda_l2': O(a=[0,.02,.2], b=0, lim=1),\n",
    "        }\n",
    "\n",
    "class ParamSearch():\n",
    "    mix = staticmethod(logavg)\n",
    "    \n",
    "    def __init__(self, psd):\n",
    "        self.data = O.mycopy(psd)\n",
    "        self.setup_data()\n",
    "        \n",
    "    def setup_data(self):\n",
    "        dsc = self.data.Discrete\n",
    "        dsc.keys = list(flatten( dsc.raw.keys() ))\n",
    "        dsc.assigns = [list(flatten(x)) for x in product(* dsc.raw.values() )]\n",
    "        obo = self.data.OneByOne\n",
    "        for k,v in dict.items(obo.data):\n",
    "            for i,x in dict.items(obo.default):\n",
    "                if i not in v:\n",
    "                    v[i] = x\n",
    "    \n",
    "    def search(self):\n",
    "        dsc, obo = self.data.Discrete, self.data.OneByOne\n",
    "        for assign in dsc.assigns:\n",
    "            params = dict(zip(dsc.keys, assign))\n",
    "            coroutine = self.one_by_one()\n",
    "            for addon in coroutine:\n",
    "                params.update(addon)\n",
    "                coroutine.send((yield params)); assert (yield) == None\n",
    "        \n",
    "        \n",
    "    def one_by_one(self):\n",
    "        obod = self.data.OneByOne.data\n",
    "        \n",
    "        #! main algorithm ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        \n",
    "        # initialize loop variables\n",
    "        params = {k: (v.b if 'b' in v else v.a[1]) for k,v in dict.items(obod)}\n",
    "        ranges = {k: v.a for k,v in dict.items(obod)}\n",
    "        scores = {k: [-np.inf, -np.inf] for k in params}\n",
    "        isdone = {k: False for k in params}\n",
    "        \n",
    "        # pre loop one-off work\n",
    "        base_score = yield params; assert (yield) == None\n",
    "        \n",
    "        # loop\n",
    "        for i in range(9999999999):\n",
    "            #! try new parameter values ############################## part A of loop work\n",
    "            \n",
    "            # initialize local loop variable\n",
    "            new_scores = {k: [-np.inf, -np.inf] for k in params}\n",
    "            new_params = {k: ( obod[k].cast(self.mix(v[0], v[1])),\n",
    "                               obod[k].cast(self.mix(v[1], v[2])) ) for k,v in dict.items(ranges)}\n",
    "            \n",
    "            # finish condition check\n",
    "            isdone = {k: v or i>=obod[k].lim for k,v in dict.items(isdone)}\n",
    "            if all(isdone.values()):\n",
    "                break\n",
    "                \n",
    "            # try new parameter values for all parameters\n",
    "            for key in list(params):\n",
    "                if i >= obod[key].lim:\n",
    "                    continue\n",
    "                orig = params[key]\n",
    "                params[key] = new_params[key][0]\n",
    "                scores[key][0] = yield params; assert (yield) == None\n",
    "                params[key] = new_params[key][1]\n",
    "                scores[key][1] = yield params; assert (yield) == None\n",
    "                params[key] = orig\n",
    "            \n",
    "            #! start setting up values for next loop ######################## part B of loop work\n",
    "            \n",
    "            # set params to the best found and see if it betters score, updating ranges also\n",
    "            #num_nochange = 0\n",
    "            for key in list(params):\n",
    "                if scores[key][0] > base_score and scores[key][0] >= scores[key][1]:\n",
    "                    params[key] = new_params[key][0]\n",
    "                    ranges[key] = [ranges[key][0], params[key], ranges[key][1]]\n",
    "                elif scores[key][1] > base_score and scores[key][1] >= scores[key][0]:\n",
    "                    params[key] = new_params[key][1]\n",
    "                    ranges[key] = [ranges[key][1], params[key], ranges[key][2]]\n",
    "                else:\n",
    "                    ranges[key] = [new_params[key][0], ranges[key][1], new_params[key][1]]\n",
    "                    #num_nochange += 1\n",
    "                \n",
    "            # send out new params\n",
    "            #if num_nochange < len(params):\n",
    "            base_score = yield params; assert (yield) == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSD(O()):\n",
    "    class Features(O()):\n",
    "        '''features selection groups'''\n",
    "        data = [\n",
    "            ('f1','f2','f3'),\n",
    "            ('f4','f5','f6')\n",
    "        ]\n",
    "    \n",
    "    class Samples(O()):\n",
    "        '''sample learning/cv split'''\n",
    "        code = [\n",
    "            O(method='sklearn', key=44)\n",
    "        ]\n",
    "        \n",
    "    class Params(O()):\n",
    "        '''parameters constant settings'''\n",
    "        data = dict(\n",
    "            objective = 'binary',\n",
    "            num_iterations = 10000,\n",
    "            early_stopping_round = 50,\n",
    "            learning_rate = .05,\n",
    "            seed = 44,\n",
    "            bagging_seed = 45,\n",
    "            feature_fraction_seed = 46,\n",
    "        )\n",
    "\n",
    "class ModelSearch():\n",
    "    def __init__(self, msd):\n",
    "        # need:\n",
    "        self.data = msd\n",
    "    def what():\n",
    "        TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexFileSystem():\n",
    "    def __init__(self, directory, key):\n",
    "        self.dir = directory if isinstance(directory, Path) else Path(directory)\n",
    "        TODO # if not exists self.dir make it\n",
    "        assert isinstance(key, str), \"key must be string\"\n",
    "        self.key = key\n",
    "        self.io = O()\n",
    "\n",
    "    def iterIndices(self):\n",
    "        for dot_params in self.dir.glob('*.' + self.key):\n",
    "            yield int(dot_params.stem)\n",
    "\n",
    "    def getFilePath(self, *, i):\n",
    "        return self.dir / (str(i) + '.' + name)\n",
    "\n",
    "    @staticmethod\n",
    "    def readWrapper(read):\n",
    "        '''wraps io read operations to safely return None if file does not exist'''\n",
    "        @wraps(read)\n",
    "        def read_safely(*a, **k):\n",
    "            try:\n",
    "                return read(*a, **k)\n",
    "            except FileNotFoundError:\n",
    "                return None\n",
    "        return read_safely\n",
    "\n",
    "    def assignIO(self, name, *, read, write, format):\n",
    "        assert format in ['bytes', 'text'], \"argument `format` must be one of 'bytes' or 'text'\"\n",
    "        self.io[name] = O(\n",
    "            read = readWrapper( lambda *,i: read(getattr(self.getFilePath(name, i=i), 'read_'+format)()) ),\n",
    "            write = lambda x,*,i: getattr(self.getFilePath(name, i=i), 'write_'+format)(write(x))\n",
    "        )\n",
    "\n",
    "class IndexDataStore():    \n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.op = O()\n",
    "        self.lists = O()\n",
    "        self.key = None\n",
    "        self.keyFunc = lambda keyVal, *, client=False: object()\n",
    "        self.tbl = {}\n",
    "        self.nextIndex = 0\n",
    "        \n",
    "    def load(self):\n",
    "        indices = sorted(self.file.iterIndices())\n",
    "        n = self.nextIndex = max(indices) + 1\n",
    "        for name, _ in dict.items(self.lists):\n",
    "            self.lists[name] = [None] * self.nextIndex\n",
    "        \n",
    "        for i in indices:\n",
    "            for name in self.lists:\n",
    "                self.op[name].load(i)\n",
    "                \n",
    "        if self.key is not None:\n",
    "            self.assignKey(self.key, self.keyFunc)\n",
    "            \n",
    "    def save(self, **kwargs, keep=True):\n",
    "        assert self.key in kwargs, \"call to `save` must include a kwarg of the key name\"\n",
    "        keyVal = self.keyFunc(kwargs[self.key], client=True)\n",
    "        \n",
    "        if keyVal not in self.tbl:\n",
    "            for name in self.lists:\n",
    "                assert len(self.lists[name]) == self.nextIndex, \"Internal error\"\n",
    "                self.lists[name].append(None)\n",
    "            self.tbl[keyVal] = self.nextIndex\n",
    "            self.nextIndex += 1\n",
    "        \n",
    "        i = self.tbl[keyVal]\n",
    "        \n",
    "        for name in kwargs:\n",
    "            if name not in self.op:\n",
    "                raise AssertionError(f\"given save item '{name}' does not have data store ops initialized\")\n",
    "            self.op[name].save(kwargs[name], keep=keep)\n",
    "            \n",
    "    def get(self, name, **kwargs):\n",
    "        assert len(kwargs) == 1 and self.key in kwargs, \"must give assigned 'key' to get corresponing data\"\n",
    "        keyVal = self.keyFunc(kwargs[self.key], client=True)\n",
    "        if keyVal not in self.tbl:\n",
    "            return None\n",
    "        i = self.tbl[keyVal]\n",
    "        return self.lists[name][i]\n",
    "        \n",
    "    ##################### INSTANCE BUILDING METHODS ##################### : \n",
    "    def assignKey(self, name, func):\n",
    "        assert name is not None, \"name to be used as key cannot be None\"\n",
    "        self.key = name\n",
    "        self.keyFunc = func\n",
    "        self.tbl = {self.keyFunc(x): i for i,x in enumerate(self.lists[self.key]) if x is not None}\n",
    "        \n",
    "    def assignOperations(self, name, *, load, save, keep, keepClient):\n",
    "        class the(O()):\n",
    "            def load(*, i, keep=True):           \n",
    "                x = load(self.file.io[name].read(i=i)) if load else None\n",
    "                if self.op[name].keep:\n",
    "                    self.lists[name][i] = self.op[name].keep(x)\n",
    "                return x\n",
    "            \n",
    "            def save(x, *, i, keep=True):\n",
    "                self.file.io[name].write(save(x)) if save else None\n",
    "                if self.op[name].keepClient:\n",
    "                    self.lists[name][i] = self.op[name].keepClient(x)\n",
    "                \n",
    "            def keep(x, *, i, ):\n",
    "                kept = None\n",
    "                if keep:\n",
    "                    kept = keep(x)\n",
    "                    self.lists[name][i] = kept\n",
    "                return kept\n",
    "                \n",
    "            def keepClient(x, *, i, ):\n",
    "                kept = None\n",
    "                if keepClient:\n",
    "                    kept = keepClient(x)\n",
    "                    self.lists[name][i] = kept\n",
    "                return kept\n",
    "            \n",
    "        self.op[name] = the\n",
    "        if keep and name not in self.lists:\n",
    "            self.lists[name] = [None] * self.nextIndex\n",
    "    \n",
    "    \n",
    "@staticmethod\n",
    "def __IndexDataStore__from_specs(specs, **kwargs):\n",
    "    for k, v in kwargs.items():\n",
    "        specs[k] = v\n",
    "    f = IndexFileSystem(specs.dir, specs.key)\n",
    "    d = IndexDataStore(f)\n",
    "    d.assignKey(specs.key, specs.keyFunc)\n",
    "    for name, val in dict.items(specs):\n",
    "        f.assignIO(name, read=val.read, write=val.write, format=val.format)\n",
    "        d.assignOperations(name, load=val.load, save=val.save, keep=val.keep, keepClient=val.keepClient)\n",
    "    d.load()\n",
    "IndexDataStore.from_specs = __IndexDataStore__from_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PDS(O()):\n",
    "    '''data transformation code inside `op` object:\n",
    "\n",
    "    client --save(+write)--> disk; client --keep--> memory; disk --load(+read)--> memory\n",
    "\n",
    "    read = text/bytes stream -> as-is object read from file\n",
    "    write = object to save as is to file -> text/bytes stream\n",
    "    load = as-is object read from file -> object to be loaded in memory\n",
    "    save = raw object given by client -> object to save as-is to file\n",
    "    keep = as-is object read from file -> object to keep in memory\n",
    "    keepClient = raw object given by client -> object to keep in memory\n",
    "    '''\n",
    "\n",
    "    key = 'Params'\n",
    "    keyFunc = lambda params, *, client=False: tuple(sorted(dict.items(params)))\n",
    "\n",
    "    class op(O()):\n",
    "        class Params(O()):\n",
    "            format = 'text'\n",
    "            read = json.loads\n",
    "            write = json.dumps\n",
    "            load = I\n",
    "            save = I\n",
    "            keep = I\n",
    "            keepClient = dict\n",
    "\n",
    "        class Results(O()):\n",
    "            format = 'bytes'\n",
    "            read = pickle.loads\n",
    "            write = pickle.dumps\n",
    "            load = TODO\n",
    "            save = TODO\n",
    "            keep = TODO\n",
    "            keepClient = \n",
    "\n",
    "        class Extras(O()):\n",
    "            format = 'bytes'\n",
    "            read = pickle.loads\n",
    "            write = pickle.dumps\n",
    "            load = TODO\n",
    "            save = TODO\n",
    "            keep = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-129-50f47f83cf9e>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-129-50f47f83cf9e>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    class ModelManager():\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class FDS(O()):\n",
    "    key = 'Feat'\n",
    "    keyFunc = lambda features\n",
    "    TODO\n",
    "\n",
    "class ModelManager():\n",
    "    def __init__(self, directory):\n",
    "        self.dir = directory if isinstance(directory, Path) else Path(directory)\n",
    "        self.F = IndexDataStore.from_specs(FDS, dir=self.dir/'.features')\n",
    "        self.S = IndexDataStore.from_specs(SDS, dir=self.dir/'.samples')\n",
    "    \n",
    "    def make_param_manager(self, features, samples):\n",
    "        fset = features if isinstance(features, frozenset) else frozenset(features)\n",
    "        if fset not in self.fTbl: \n",
    "            self.init_features(fset)\n",
    "        stup = samples; assert isinstance(stup, tuple) and len(stup==3)\n",
    "        if stup not in self.sTbl:\n",
    "            self.init_samples(stup)\n",
    "        fs_ids = (self.fTbl[fset], self.sTbl[stup])\n",
    "        if fs_ids not in self.fsSet:\n",
    "            self.init_features_samples_with_ids(*fs_ids)\n",
    "        return ParamManager()\n",
    "        \n",
    "    def init_features(self, fset):\n",
    "        TODO\n",
    "    \n",
    "    def init_samples(self, stup):\n",
    "        TODO\n",
    "        \n",
    "    def init_features_samples_with_ids(fId, sId):\n",
    "        TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old shit / testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'What' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-dc92f66a5036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mYo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mWhat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mderp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-dc92f66a5036>\u001b[0m in \u001b[0;36mYo\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mWhat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mderp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mclass\u001b[0m \u001b[0mAnother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0myep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mYo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-dc92f66a5036>\u001b[0m in \u001b[0;36mAnother\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mderp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mAnother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0myep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mYo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'What' is not defined"
     ]
    }
   ],
   "source": [
    "# PUREL TESTING\n",
    "class HI(O()):\n",
    "    class DERP():\n",
    "        val = -99\n",
    "        dir = Path('.')\n",
    "        def yo(x):\n",
    "            def y(a):\n",
    "                return x(a) + 1000\n",
    "            return y\n",
    "        my = O(what=yo(lambda a: a ** 2))\n",
    "        hm = O(func=lambda x: x * __class__.val, goto=lambda x: __class__.dir/x)\n",
    "        class WHAT(O()):\n",
    "            dude = lambda x: x + 10\n",
    "        class YES(O()):\n",
    "            dude = WHAT.dude\n",
    "HI.DERP.my.what(5)\n",
    "HI.DERP.hm.func(5)\n",
    "HI.DERP.dir = Path('what')\n",
    "HI.DERP.hm.goto('.git')\n",
    "HI.DERP.WHAT.dude(0)\n",
    "\n",
    "# ANOTHER PURE TESTING\n",
    "def dothe(self):\n",
    "    self.val = 4\n",
    "    top = 100\n",
    "    class Derp(O()):\n",
    "        def func(x):\n",
    "            return x + self.val\n",
    "        def top(y):\n",
    "            return y * top\n",
    "    self.derp = Derp\n",
    "item = Stop()\n",
    "dothe(item)\n",
    "item.derp.top(3)\n",
    "\n",
    "class Yo(O()):\n",
    "    class What(O()):\n",
    "        derp = 5\n",
    "    class Another(O()):\n",
    "        yep = What.derp\n",
    "Yo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ParamManager():\n",
    "    \n",
    "    @staticmethod\n",
    "    def paramsKey(params, *, client=False):\n",
    "        '''return key that identifies params, regardless of whether params is internal on client given'''\n",
    "        return tuple(sorted(dict.items(params)))\n",
    "    \n",
    "    \n",
    "    class file(metaclass=staticclass):\n",
    "        dir = None # don't forget to attach me in the code a level above!\n",
    "        \n",
    "        def iterIndices():\n",
    "            for dot_params in __class__.dir.glob('*.params'):\n",
    "                yield int(dot_params.stem)\n",
    "        \n",
    "        def getFilePath(name, *, i):\n",
    "            return __class__.dir / (str(i) + name)\n",
    "        \n",
    "        def readWrapper(read):\n",
    "            '''wraps io read operations to safely return None if file does not exist'''\n",
    "            @wraps(read)\n",
    "            def read_safely(*a, **k):\n",
    "                try:\n",
    "                    return read(*a, **k)\n",
    "                except FileNotFoundError:\n",
    "                    return None\n",
    "            return read_safely\n",
    "        \n",
    "        io = O(\n",
    "            Params = O(\n",
    "                read = readWrapper( lambda *,i: json.loads(__class__.getFilePath('.params', i=i).read_text()) ),\n",
    "                write = lambda x,*,i: __class__.getFilePath('.params', i=i).write_text(json.dumps(x))\n",
    "            ),\n",
    "            Results = O(\n",
    "                read = readWrapper( lambda *,i: pickle.load(__class__.getFilePath('.results', i=i).read_bytes()) ),\n",
    "                write = lambda x,*,i: __class__.getFilePath('.results', i=i).write_bytes( pickle.dumps(x) )\n",
    "            ),\n",
    "            Extras = O(\n",
    "                read = readWrapper( lambda *,i: pickle.load(__class__.getFilePath('.extras', i=i).read_bytes()) ),\n",
    "                write = lambda x,*,i: __class__.getFilePath('.extras', i=i).write_bytes( pickle.dumps(x) )\n",
    "            ),\n",
    "        )\n",
    "            \n",
    "    class opt(O()):\n",
    "        '''data transformation code:\n",
    "        \n",
    "        client --save--> disk; client --keep--> memory; disk --load--> memory\n",
    "        \n",
    "        load = object raw read from file -> object to be loaded in memory\n",
    "        save = raw object given by client -> object to save to file\n",
    "        keep = raw object given by client -> object to keep in memory\n",
    "        '''\n",
    "        class Params(metaclass=staticclass):\n",
    "            load = I\n",
    "            save = I\n",
    "            keep = I\n",
    "            \n",
    "        class Results(metaclass=staticclass):\n",
    "            load = TODO\n",
    "            save = TODO\n",
    "            keep = TODO\n",
    "            \n",
    "        class Extras(metaclass=staticclass):\n",
    "            load = TODO\n",
    "            save = TODO\n",
    "            keep = TODO\n",
    "            \n",
    "    \n",
    "    def __init__(self, directory):\n",
    "        self.file.dir = directory if isinstance(directory, Path) else Path(directory)\n",
    "        self.opt = O.mycopy(__class__.opt)\n",
    "        self.reload_runs()\n",
    "        \n",
    "        \n",
    "    def reload_runs(self):\n",
    "        indices = sorted(self.file.iterIndices())\n",
    "        m = max(indices) + 1\n",
    "        self.paramsList = [None] * m\n",
    "        self.resultsList = [None]*m if self.opt.Results.load else None\n",
    "        self.extrasList = [None]*m if self.opt.Extras.load else None\n",
    "        \n",
    "        for i in indices:\n",
    "            paramsRead = self.file.io.Params.read(i=i)\n",
    "            self.paramsList[i] = self.opt.Params.load(paramsRead)\n",
    "            \n",
    "            if self.opt.Results.load:\n",
    "                resultsRead = self.file.io.Results.read(i=i)\n",
    "                self.resultsList[i] = self.opt.Results.load(resultsRead)\n",
    "            \n",
    "            if self.opt.Extras.load:\n",
    "                extrasRead = self.file.io.Extras.read(i=i)\n",
    "                self.extrasList[i] = self.opt.Extras.load(extrasRead)\n",
    "                \n",
    "        self.paramsTbl = {self.paramsKey(p): i for i,p in enumerate(self.paramsList) if p is not None}\n",
    "        \n",
    "        \n",
    "    def save_run(params, results, extras):\n",
    "        paramsClient, resultsClient, extrasClient = params, results, extras; del params, results, extras\n",
    "        params = self.opt.Params.keep(paramsClient)\n",
    "        key = self.paramsKey(params)\n",
    "        if key not in self.paramsTbl:\n",
    "            self.paramsList.append(params)\n",
    "            self.paramsTbl[key] = len(self.paramsList)-1\n",
    "        \n",
    "        i = self.paramsTbl[key]\n",
    "        \n",
    "        # save everything to file, overwriting if things were there before\n",
    "        \n",
    "        paramsWrite = self.opt.Params.save(paramsClient)\n",
    "        self.file.io.Params.write(paramsWrite, i=i)\n",
    "                \n",
    "        if self.opt.Results.save:\n",
    "            resultsWrite = self.opt.Results.save(resultsClient)\n",
    "            self.file.io.Results.write(resultsWrite, i=i)\n",
    "            \n",
    "        if self.opt.Extras.save:\n",
    "            extrasWrite = self.opt.Extras.save(extrasClient)\n",
    "            self.file.io.Extras.write(extrasWrite, i=i)\n",
    "            \n",
    "        # save internal version of client data to memory\n",
    "        \n",
    "        if self.opt.Results.keep:\n",
    "            if self.resultsList is None:\n",
    "                self.resultsList = []\n",
    "            if i >= len(self.resultsList):\n",
    "                self.resultsList.extend([None] * (i+1 - len(self.resultsList)))\n",
    "            self.resultsList[i] = self.opt.Results.keep(resultsClient)\n",
    "        \n",
    "        if self.opt.Extras.keep:\n",
    "            if self.extrasList is None:\n",
    "                self.extrasList = []\n",
    "            if i >= len(self.extrasList):\n",
    "                self.extrasList.extend([None] * (i+1 - len(self.extrasList)))\n",
    "            self.extrasList[i] = self.opt.Extras.keep(extrasClient)\n",
    "        \n",
    "        \n",
    "    def get_results(params):\n",
    "        key = self.paramsKey(params, client=True)\n",
    "        if key not in self.paramsTbl:\n",
    "            return None\n",
    "        i = self.paramsTbl[key]\n",
    "        if i >= len(self.resultsList) or self.resultsList[i] is None:\n",
    "            return None\n",
    "        return self.resultsList[i]\n",
    "        \n",
    "        \n",
    "    def get_extras(params):\n",
    "        key = self.paramsKey(params, client=True)\n",
    "        if key not in self.paramsTbl:\n",
    "            return None\n",
    "        i = self.paramsTbl[key]\n",
    "        if i >= len(self.extrasList) or self.extrasList[i] is None:\n",
    "            return None\n",
    "        return self.extrasList[i]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelManager():\n",
    "    def __init__(self, directory):\n",
    "        self.dir = directory\n",
    "        self.next_group_index = ?\n",
    "        self.next_s\n",
    "    \n",
    "    def make_param_manager(self, features, samples):\n",
    "        fset = features if isinstance(features, frozenset) else frozenset(features)\n",
    "        if fset not in self.fTbl: \n",
    "            self.init_features(fset)\n",
    "        stup = samples; assert isinstance(stup, tuple) and len(stup==3)\n",
    "        if stup not in self.sTbl:\n",
    "            self.init_samples(stup)\n",
    "        fs_ids = (self.fTbl[fset], self.sTbl[stup])\n",
    "        if fs_ids not in self.fsSet:\n",
    "            self.init_features_samples_with_ids(*fs_ids)\n",
    "        return ParamManager()\n",
    "        \n",
    "    def init_features(self, fset):\n",
    "        TODO\n",
    "    \n",
    "    def init_samples(self, stup):\n",
    "        TODO\n",
    "        \n",
    "    def init_features_samples_with_ids(fId, sId):\n",
    "        TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OLD\n",
    "\n",
    "class ModelManager():\n",
    "    def __init__(self, directory):\n",
    "        self.dir = directory\n",
    "        self.next_group_index = ?\n",
    "        self.next_s\n",
    "    \n",
    "    def make_param_manager(self, features, samples):\n",
    "        fset = features if isinstance(features, frozenset) else frozenset(features)\n",
    "        if fset not in self.fTbl: \n",
    "            self.init_features(fset)\n",
    "        stup = samples; assert isinstance(stup, tuple) and len(stup==3)\n",
    "        if stup not in self.sTbl:\n",
    "            self.init_samples(stup)\n",
    "        fs_ids = (self.fTbl[fset], self.sTbl[stup])\n",
    "        if fs_ids not in self.fsSet:\n",
    "            self.init_features_samples_with_ids(*fs_ids)\n",
    "        return ParamManager()\n",
    "        \n",
    "    def init_features(self, fset):\n",
    "        TODO\n",
    "    \n",
    "    def init_samples(self, stup):\n",
    "        TODO\n",
    "        \n",
    "    def init_features_samples_with_ids(fId, sId):\n",
    "        TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 6.1, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.01, 'lambda_l2': 0}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.11, 'lambda_l2': 0}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.01}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.11}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 95, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 71.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 6, 'num_leaves': 64, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 6.1, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.01, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.11, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.01}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 95, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 71.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 128, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 6.1, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.01, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.11, 'lambda_l2': 0}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.01}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 95, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 71.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 9, 'num_leaves': 512, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 6.1, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.01, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.11, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.01}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 95, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 71.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 256, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 6.1, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.01, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.11, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.01}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 95, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 71.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 1024, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 6.1, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.01, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.11, 'lambda_l2': 0}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.01}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 95, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 71.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': 12, 'num_leaves': 4096, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 6.1, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.01, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.11, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.01}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 95, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 71.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 256, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 6.1, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.01, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.11, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.01}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 95, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 71.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 1024, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 6.1, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.01, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.11, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.01}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 95, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 71.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 4096, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 6.1, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.01, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0.11, 'lambda_l2': 0}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.01}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 50, 'lambda_l1': 0, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 95, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 100.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 71.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "{'max_depth': -1, 'num_leaves': 16384, 'min_data_in_leaf': 237, 'min_sum_hessian_in_leaf': 140.0, 'lambda_l1': 0.11, 'lambda_l2': 0.11}\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "s = ParamSearch(PSD)\n",
    "search = s.search()\n",
    "cnt = 0\n",
    "for i,p in zip(range(999),search):\n",
    "    print(p)\n",
    "    search.send(i)\n",
    "    cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRATCH TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hi():\n",
    "    for i in range(10):\n",
    "        first = yield i\n",
    "        assert (yield)==None\n",
    "        print(' here', first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 0\n",
      " here 0.0\n",
      "x 1\n",
      " here 0.1\n",
      "x 2\n",
      " here 0.2\n",
      "x 3\n",
      " here 0.3\n",
      "x 4\n",
      " here 0.4\n",
      "x 5\n",
      " here 0.5\n",
      "x 6\n",
      " here 0.6\n",
      "x 7\n",
      " here 0.7\n",
      "x 8\n",
      " here 0.8\n",
      "x 9\n",
      " here 0.9\n"
     ]
    }
   ],
   "source": [
    "h = hi()\n",
    "for x in h:\n",
    "    print('x', x)\n",
    "    h.send(x / 10.)\n",
    "    #print(next(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
