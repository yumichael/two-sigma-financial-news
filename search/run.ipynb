{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *\n",
    "from search.imports import *\n",
    "from search.search import *\n",
    "from search.manager import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pd.read_pickle(the_data/'given/M.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F,P = pd.read_pickle(big_data/'saves/train_5fixedsince+1.32.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Params specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSP(O()):\n",
    "    class Discrete(O()):\n",
    "        stop = {1:.45, 2:.5, 3:.55, 5:.6, 7:.65, 9:.7} #{1:.3, 3:.5, 5:.6, 7:.65}\n",
    "        obo = {0: 0}\n",
    "        enc = {\n",
    "            'learning_rate': [.05],\n",
    "            ('max_depth','num_leaves'):\n",
    "                [(6,1<<6),(8,1<<8),(10,1<<10),(12,1<<12),\n",
    "                 (10,1<<6),(-1,1<<10),(10,1<<8),(-1,1<<14),\n",
    "                 (12,1<<10),(8,1<<6),(-1,1<<12),(12,1<<8),]\n",
    "        }\n",
    "        \n",
    "    class OneByOne(O()):\n",
    "        base = .33\n",
    "        class info(O()):\n",
    "            a = \"main [a]rray data of 3 values, [min mid max]\"\n",
    "            b =  \"[b]ack up value, i.e. default value if array doesn't give better results\"\n",
    "            cast = \"function to apply to values before using to cast to the right dtype\"\n",
    "            lim = \"maximum number of iterations of searching in this hyperparameter\"\n",
    "        class default(O()):\n",
    "            cast = keepSigFig(2)\n",
    "            lim = 0\n",
    "        enc = {#TODO implement 1 sided search e.g. len(a)==2\n",
    "            0: {\n",
    "                'min_data_in_leaf': O(a=[1,60,375], b=120, cast=round, lim=lambda lim: lim),\n",
    "                'min_sum_hessian_in_leaf': O(a=[0,50,200], lim=lambda lim: lim+1),\n",
    "                'lambda_l1': O(a=[0,.02,.2], b=0),\n",
    "                'lambda_l2': O(a=[0,.02,.2], b=0),\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Features/Samples specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import gen_features\n",
    "\n",
    "ho = P.quarter>=2015.5\n",
    "ho.name = None\n",
    "\n",
    "\n",
    "class LSM(O()):\n",
    "    model = O(\n",
    "        time = 'time',\n",
    "        value = 'y',\n",
    "        target = 'target',\n",
    "        weight = 'flat_weight',\n",
    "    )\n",
    "    \n",
    "    metric = KaggleMetric()\n",
    "    search = LSP\n",
    "    \n",
    "    t_offset = 0\n",
    "    num_feats = 10000\n",
    "    num_samps = 100\n",
    "    stop_samps = {2:.4, 3:.46, 4:.51, 5:.55, 6:.59, 7:.62, 8:float('inf')} #{1:.57, 2:.61, 3:.64, 4:float('inf')}\n",
    "    \n",
    "    \n",
    "@inside(LSM)\n",
    "class Step(metaclass=staticclass):\n",
    "    _best = -float('inf')\n",
    "    def func(results, *, t):\n",
    "        t += 1\n",
    "        self = __class__\n",
    "        num_feats, num_samps, stop_samps = LSM.num_feats, LSM.num_samps, LSM.stop_samps\n",
    "\n",
    "        if results is not None and results['score'] > self._best:\n",
    "            self._best = results['score']\n",
    "\n",
    "        ts = t % num_samps\n",
    "        if ts == 0: # if new feature, reset `self._best` score\n",
    "            self._best = -float('inf')\n",
    "        assert 0 not in stop_samps\n",
    "        if ts in stop_samps and stop_samps[ts] > self._best:\n",
    "            t = (t//num_samps + 1) * num_samps # go to next feature if met stop score criterion\n",
    "\n",
    "        if t >= num_feats * num_samps:\n",
    "            return None\n",
    "        return t\n",
    "\n",
    "@inside(LSM)\n",
    "class Features(metaclass=staticclass):\n",
    "    '''features selection groups'''\n",
    "    def func(*, t):\n",
    "        t += LSM.t_offset\n",
    "        num_feats, num_samps = LSM.num_feats, LSM.num_samps\n",
    "        f, q = gen_features(t // num_samps)\n",
    "        return O(Feats=f, Ctor=q)\n",
    "\n",
    "@inside(LSM)\n",
    "class Samples(metaclass=staticclass):\n",
    "    '''sample learning/cv split'''\n",
    "    # O(method='GroupShuffleSplit.2', kwargs=dict(n_splits=<(5)many>, test_size=.5, random_state=44), groups='quarter'),\n",
    "    def ctor2samps(ctor):\n",
    "        a, b = tuple(ctor)\n",
    "        group = P.quarter[~ho]\n",
    "        tr, cv = group.isin(a), group.isin(b)\n",
    "        tr, cv = [F.index[~ho][trcv] for trcv in [tr,cv]]\n",
    "        return ((tr, cv),(cv,tr))\n",
    "    \n",
    "    def func(*, t):\n",
    "        t += LSM.t_offset\n",
    "        group = P.quarter[~ho]\n",
    "        h = frozenset(group)\n",
    "        g = frozenset(random.Random(t).sample(h, len(h)//2))\n",
    "        return O(Samps=__class__.ctor2samps((g,h-g)), Ctor=(g,h-g))\n",
    "\n",
    "@inside(LSM, name='Params')\n",
    "class Params(O()):\n",
    "    '''parameters constant settings'''\n",
    "    data = dict(\n",
    "        objective = 'binary',\n",
    "        num_iterations = 100000,\n",
    "        early_stopping_round = 32,\n",
    "        metric = 'None',\n",
    "        seed = 44,\n",
    "        bagging_seed = 45,\n",
    "        feature_fraction_seed = 46,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIVE TESTING WALK ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @REAL\n",
    "DISPLAY = True\n",
    "\n",
    "DIR = Path(top_dir/'data/search/flat')\n",
    "DIR.mkdir(exist_ok=True)\n",
    "\n",
    "TAG = 'flat'\n",
    "\n",
    "LOG_DIR = DIR/'runs'\n",
    "LOG_DIR.mkdir(exist_ok=True)\n",
    "LOG = logger(file=LOG_DIR/(TAG+'.log'))\n",
    "SEE = LOG\n",
    "\n",
    "import globals as top_imports\n",
    "top_imports.SEE = LOG.logger(display=DISPLAY)\n",
    "#top_imports.SEE = lambda*a,**k:None\n",
    "\n",
    "VERBOSE_EVAL = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from search.LSM import LSM\n",
    "mm = ModelManager(DIR)\n",
    "ms = ModelSearch(specs=LSM, mm=mm, X=F, Y=P, tag=TAG, log=LOG.logger('>>>', display=DISPLAY), verbose_eval=VERBOSE_EVAL)\n",
    "walk = ms.walk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for (fi, si), results in walk:\n",
    "    for a in ['nboost', 'train', 'scores', 'score']:\n",
    "        SEE(f'{a} = {results[a]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
