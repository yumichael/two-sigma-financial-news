{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *\n",
    "from search.imports import *\n",
    "from search.search import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making test variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "ppf = norm.ppf\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_new_vars():\n",
    "    n = 1000\n",
    "    ##################RANDOMIZE#######################\n",
    "    while True:\n",
    "        try:\n",
    "            u = np.random.uniform(size=(5, n))\n",
    "            assert (u!=0).all()\n",
    "            break\n",
    "        except AssertionError:\n",
    "            continue\n",
    "    uu = u.copy()\n",
    "    uu[0][np.random.randint(252, size=n) == 0] = np.nan\n",
    "    uu[1][np.random.randint(173, size=n) == 0] = np.nan\n",
    "    uu[2][np.random.randint(81, size=n) == 0] = np.nan\n",
    "    uu[3][np.random.randint(27, size=n) == 0] = np.nan\n",
    "    #################ENDRANDOM######################\n",
    "    F = pd.DataFrame({'hax': np.arange(n)})\n",
    "    F['time'] = F.hax // 10\n",
    "    F['assetCodeId'] = F.hax % 10\n",
    "    F['quarter'] = F.hax // 100\n",
    "    P = F.copy()\n",
    "    F['alex'] = ppf(u[0]*5%.99+eps)*ppf(u[1]*7%.99+eps)\n",
    "    F['bob'] = ppf(.5+.49*uu[2]*np.sin(F.assetCodeId.values**10))*np.exp(uu[3])\n",
    "    F['carol'] = -np.log(u[0]) + 4 * np.sin(1/uu[1])\n",
    "    F['dean'] = u[1] + 2 * uu[2] - np.exp(-uu[3])\n",
    "    F['edgar'] = ppf( (uu[2]**2-2*u[1]+(u[0]-u[3])**3-.5*u[1]**2) % .99 + eps )\n",
    "    P['y'] = (ppf((u[0]+u[1])/2) + ppf((u[2]+u[3])/2) + .2*ppf(u[4])) * 1e-1\n",
    "    P['universe'] = (~np.isnan(uu[0])).astype(float)\n",
    "    return F, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F, P = make_new_vars()\n",
    "#Path('lighttest.pkl').write_bytes(pickle.dumps((F, P)))\n",
    "F, P = pickle.loads((top_dir/'search/lighttest.pkl').read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P['target'] = P.y>0\n",
    "P['upDown'] = (P.target*2-1)\n",
    "P['upDown1'] = P.upDown*P.universe.astype(int)\n",
    "P['absVal'] = np.abs(P.y)\n",
    "P['absVal1'] = P.absVal*P.universe\n",
    "P['weight'] = P.absVal#.qtl()\n",
    "P['weight1'] = P.weight*P.universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pathlib.Path"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSP(O()):\n",
    "    class Discrete(O()):\n",
    "        stop = {1: 1., 2: 2.2}\n",
    "        obo = {0: 0}\n",
    "        enc = {\n",
    "            'learning_rate': [.05],\n",
    "            ('max_depth','num_leaves'):\n",
    "                [(3,1<<3),(6,1<<6),(-1,1<<9)]\n",
    "        }\n",
    "        \n",
    "    class OneByOne(O()):\n",
    "        class info(O()):\n",
    "            a = \"main [a]rray data of 3 values, [min mid max]\"\n",
    "            b =  \"[b]ack up value, i.e. default value if array doesn't give better results\"\n",
    "            cast = \"function to apply to values before using to cast to the right dtype\"\n",
    "            lim = \"maximum number of iterations of searching in this hyperparameter\"\n",
    "        class default(O()):\n",
    "            cast = keepSigFig(2)\n",
    "            lim = 0\n",
    "        enc = {\n",
    "            0: {\n",
    "                'min_data_in_leaf': O(a=[1,6,37], cast=round, lim=lambda lim: lim+0),\n",
    "                'min_sum_hessian_in_leaf': O(a=[0,5,20], b=0),\n",
    "                'lambda_l1': O(a=[0,.02,.2], b=0),\n",
    "                'lambda_l2': O(a=[0,.02,.2], b=0),\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "class LSM(O()):\n",
    "    model = O(\n",
    "        time = 'time',\n",
    "        value = 'y',\n",
    "        target = 'target',\n",
    "        weight = 'weight1',\n",
    "    )\n",
    "    \n",
    "    metric = KaggleMetric()\n",
    "    search = LPS\n",
    "    \n",
    "    num_feats = 3\n",
    "    num_samps = 10\n",
    "    \n",
    "@inside(LSM)\n",
    "class Step(metaclass=staticclass):\n",
    "    best = -float('inf')\n",
    "    stop = {1: 1.5, 2: 3., 3: float('inf')}\n",
    "    def func(results, *, t):\n",
    "        t += 1\n",
    "        self, stop = __class__, __class__.stop\n",
    "        num_feats, num_samps = LSM.num_feats, LSM.num_samps\n",
    "\n",
    "        if results is not None and results['score'] > self.best:\n",
    "            self.best = results['score']\n",
    "\n",
    "        ts = t % num_samps\n",
    "        if ts == 0: # if new feature, reset `self.best` score\n",
    "            self.best = -float('inf')\n",
    "\n",
    "        if ts in stop and stop[ts] > self.best:\n",
    "            t = (t//num_samps + 1) * num_samps # go to next feature if met stop score criterion\n",
    "\n",
    "        if t >= num_feats * num_samps:\n",
    "            return None\n",
    "        return t\n",
    "    \n",
    "@inside(LSM)\n",
    "class Features(metaclass=staticclass):\n",
    "    '''features selection groups'''\n",
    "    data = [\n",
    "        ['alex', 'bob', 'carol'],\n",
    "        ['bob', 'dean', 'edgar'],\n",
    "        ['alex', 'carol', 'edgar']\n",
    "    ]\n",
    "    def func(*, t):\n",
    "        num_feats, num_samps = LSM.num_feats, LSM.num_samps\n",
    "        return O(Feats=__class__.data[t // num_samps])\n",
    "\n",
    "ho = P.quarter >= 8\n",
    "\n",
    "@inside(LSM)\n",
    "class Samples(metaclass=staticclass):\n",
    "    '''sample learning/cv split'''\n",
    "#         enc = [\n",
    "#             O(method='group.2', groups='quarter', data=[\n",
    "#                 [0, 1, 2, 3, 4],\n",
    "#                 [5, 6, 7, 8, 9]\n",
    "#             ]),\n",
    "#         ]\n",
    "    # O(method='GroupShuffleSplit.2', kwargs=dict(n_splits=<(5)many>, test_size=.5, random_state=44), groups='quarter'),\n",
    "    def func(*, t):\n",
    "        group = P.quarter[~ho]\n",
    "        h = frzset(group)\n",
    "        g = frzset(random.Random(t).sample(h,len(h)//2))\n",
    "        tr, cv = group.isin(g), group.isin(h-g)\n",
    "        tr, cv = [F.index[~ho][trcv] for trcv in [tr,cv]]\n",
    "        return O(Samps=((tr, cv),(cv,tr)), Ctor=(g,h-g))\n",
    "\n",
    "@inside(LSM, name='Params')\n",
    "class Params(O()):\n",
    "    '''parameters constant settings'''\n",
    "    data = dict(\n",
    "        objective = 'binary',\n",
    "        num_iterations = 100000,\n",
    "        early_stopping_round = 32,\n",
    "        metric = 'None',\n",
    "        seed = 44,\n",
    "        bagging_seed = 45,\n",
    "        feature_fraction_seed = 46,\n",
    "    )\n",
    "# @TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG = lambda*a,**k: print('>>>', *a, **k)\n",
    "SEE = print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm = ModelManager('/big/data/search/test')\n",
    "ms = ModelSearch(specs=LSM, mm=mm, X=F, Y=P)\n",
    "walk = ms.walk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (fi, si), results in walk:\n",
    "    for a in ['nboost', 'train', 'scores', 'score']:\n",
    "        SEE(f'{a} = {results[a]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
